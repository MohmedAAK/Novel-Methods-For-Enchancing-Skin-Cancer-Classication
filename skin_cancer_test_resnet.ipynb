{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "skin_cancer_test_resnet.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MohmedAAK/skin_cancer/blob/master/skin_cancer_test_resnet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nhDSyO2FZG2o",
        "colab_type": "code",
        "outputId": "ef846285-beef-474a-f9f2-19616be20575",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        }
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np \n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "from urllib.request import urlopen,urlretrieve\n",
        "from PIL import Image\n",
        "from tqdm import tqdm_notebook\n",
        "from sklearn.utils import shuffle\n",
        "import cv2\n",
        "\n",
        "from  tensorflow.keras.models import load_model\n",
        "from sklearn.datasets import load_files   \n",
        "from  keras.utils import np_utils\n",
        "from glob import glob\n",
        "from  tensorflow.keras import applications\n",
        "from  tensorflow.keras.preprocessing.image import ImageDataGenerator \n",
        "from  tensorflow.keras import optimizers\n",
        "from  tensorflow.keras.models import Sequential,Model,load_model\n",
        "from  tensorflow.keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D,GlobalAveragePooling2D\n",
        "from  tensorflow.keras.callbacks import TensorBoard,ReduceLROnPlateau,ModelCheckpoint"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BUhTgbWuS7jt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "import tensorflow.keras.backend as backend\n",
        "import tensorflow.keras.layers as layers\n",
        "import tensorflow.keras.models as models\n",
        "import tensorflow.keras.utils as utils\n",
        "\n",
        "_KERAS_BACKEND = None\n",
        "_KERAS_LAYERS = None\n",
        "_KERAS_MODELS = None\n",
        "_KERAS_UTILS = None\n",
        "\n",
        "\n",
        "def get_submodules_from_kwargs(kwargs):\n",
        "    #backend = kwargs.get('backend', _KERAS_BACKEND)\n",
        "    #layers = kwargs.get('layers', _KERAS_LAYERS)\n",
        "    #models = kwargs.get('models', _KERAS_MODELS)\n",
        "    #utils = kwargs.get('utils', _KERAS_UTILS)\n",
        "    #for key in kwargs.keys():\n",
        "     #   if key not in ['backend', 'layers', 'models', 'utils']:\n",
        "      #      raise TypeError('Invalid keyword argument: %s', key)\n",
        "    return backend, layers, models, utils\n",
        "\n",
        "\n",
        "def correct_pad(backend, inputs, kernel_size):\n",
        "    \"\"\"Returns a tuple for zero-padding for 2D convolution with downsampling.\n",
        "    # Arguments\n",
        "        input_size: An integer or tuple/list of 2 integers.\n",
        "        kernel_size: An integer or tuple/list of 2 integers.\n",
        "    # Returns\n",
        "        A tuple.\n",
        "    \"\"\"\n",
        "    img_dim = 2 if backend.image_data_format() == 'channels_first' else 1\n",
        "    input_size = backend.int_shape(inputs)[img_dim:(img_dim + 2)]\n",
        "\n",
        "    if isinstance(kernel_size, int):\n",
        "        kernel_size = (kernel_size, kernel_size)\n",
        "\n",
        "    if input_size[0] is None:\n",
        "        adjust = (1, 1)\n",
        "    else:\n",
        "        adjust = (1 - input_size[0] % 2, 1 - input_size[1] % 2)\n",
        "\n",
        "    correct = (kernel_size[0] // 2, kernel_size[1] // 2)\n",
        "\n",
        "    return ((correct[0] - adjust[0], correct[0]),\n",
        "            (correct[1] - adjust[1], correct[1]))\n",
        "\n",
        "__version__ = '1.0.8'\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zF_uNzemTahi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "import tensorflow as tf\n",
        "import json\n",
        "import warnings\n",
        "import numpy as np\n",
        "import tensorflow.keras.backend as backend\n",
        "import tensorflow.keras.layers as layers\n",
        "import tensorflow.keras.models as models\n",
        "import tensorflow.keras.utils as utils\n",
        "from . import get_submodules_from_kwargs\n",
        "\n",
        "CLASS_INDEX = None\n",
        "CLASS_INDEX_PATH = ('https://storage.googleapis.com/download.tensorflow.org/'\n",
        "                    'data/imagenet_class_index.json')\n",
        "\n",
        "\n",
        "def _preprocess_numpy_input(x, data_format, mode, **kwargs):\n",
        "    \"\"\"Preprocesses a Numpy array encoding a batch of images.\n",
        "    # Arguments\n",
        "        x: Input array, 3D or 4D.\n",
        "        data_format: Data format of the image array.\n",
        "        mode: One of \"caffe\", \"tf\" or \"torch\".\n",
        "            - caffe: will convert the images from RGB to BGR,\n",
        "                then will zero-center each color channel with\n",
        "                respect to the ImageNet dataset,\n",
        "                without scaling.\n",
        "            - tf: will scale pixels between -1 and 1,\n",
        "                sample-wise.\n",
        "            - torch: will scale pixels between 0 and 1 and then\n",
        "                will normalize each channel with respect to the\n",
        "                ImageNet dataset.\n",
        "    # Returns\n",
        "        Preprocessed Numpy array.\n",
        "    \"\"\"\n",
        "  \n",
        "    if not issubclass(x.dtype.type, np.floating):\n",
        "        x = x.astype(backend.floatx(), copy=False)\n",
        "\n",
        "    if mode == 'tf':\n",
        "        x /= 127.5\n",
        "        x -= 1.\n",
        "        return x\n",
        "\n",
        "    if mode == 'torch':\n",
        "        x /= 255.\n",
        "        mean = [0.485, 0.456, 0.406]\n",
        "        std = [0.229, 0.224, 0.225]\n",
        "    else:\n",
        "        if data_format == 'channels_first':\n",
        "            # 'RGB'->'BGR'\n",
        "            if x.ndim == 3:\n",
        "                x = x[::-1, ...]\n",
        "            else:\n",
        "                x = x[:, ::-1, ...]\n",
        "        else:\n",
        "            # 'RGB'->'BGR'\n",
        "            x = x[..., ::-1]\n",
        "        mean = [103.939, 116.779, 123.68]\n",
        "        std = None\n",
        "\n",
        "    # Zero-center by mean pixel\n",
        "    if data_format == 'channels_first':\n",
        "        if x.ndim == 3:\n",
        "            x[0, :, :] -= mean[0]\n",
        "            x[1, :, :] -= mean[1]\n",
        "            x[2, :, :] -= mean[2]\n",
        "            if std is not None:\n",
        "                x[0, :, :] /= std[0]\n",
        "                x[1, :, :] /= std[1]\n",
        "                x[2, :, :] /= std[2]\n",
        "        else:\n",
        "            x[:, 0, :, :] -= mean[0]\n",
        "            x[:, 1, :, :] -= mean[1]\n",
        "            x[:, 2, :, :] -= mean[2]\n",
        "            if std is not None:\n",
        "                x[:, 0, :, :] /= std[0]\n",
        "                x[:, 1, :, :] /= std[1]\n",
        "                x[:, 2, :, :] /= std[2]\n",
        "    else:\n",
        "        x[..., 0] -= mean[0]\n",
        "        x[..., 1] -= mean[1]\n",
        "        x[..., 2] -= mean[2]\n",
        "        if std is not None:\n",
        "            x[..., 0] /= std[0]\n",
        "            x[..., 1] /= std[1]\n",
        "            x[..., 2] /= std[2]\n",
        "    return x\n",
        "\n",
        "\n",
        "def _preprocess_symbolic_input(x, data_format, mode, **kwargs):\n",
        "    \"\"\"Preprocesses a tensor encoding a batch of images.\n",
        "    # Arguments\n",
        "        x: Input tensor, 3D or 4D.\n",
        "        data_format: Data format of the image tensor.\n",
        "        mode: One of \"caffe\", \"tf\" or \"torch\".\n",
        "            - caffe: will convert the images from RGB to BGR,\n",
        "                then will zero-center each color channel with\n",
        "                respect to the ImageNet dataset,\n",
        "                without scaling.\n",
        "            - tf: will scale pixels between -1 and 1,\n",
        "                sample-wise.\n",
        "            - torch: will scale pixels between 0 and 1 and then\n",
        "                will normalize each channel with respect to the\n",
        "                ImageNet dataset.\n",
        "    # Returns\n",
        "        Preprocessed tensor.\n",
        "    \"\"\"\n",
        "\n",
        "\n",
        "    if mode == 'tf':\n",
        "        x /= 127.5\n",
        "        x -= 1.\n",
        "        return x\n",
        "\n",
        "    if mode == 'torch':\n",
        "        x /= 255.\n",
        "        mean = [0.485, 0.456, 0.406]\n",
        "        std = [0.229, 0.224, 0.225]\n",
        "    else:\n",
        "        if data_format == 'channels_first':\n",
        "            # 'RGB'->'BGR'\n",
        "            if backend.ndim(x) == 3:\n",
        "                x = x[::-1, ...]\n",
        "            else:\n",
        "                x = x[:, ::-1, ...]\n",
        "        else:\n",
        "            # 'RGB'->'BGR'\n",
        "            x = x[..., ::-1]\n",
        "        mean = [103.939, 116.779, 123.68]\n",
        "        std = None\n",
        "\n",
        "    mean_tensor = backend.constant(-np.array(mean))\n",
        "\n",
        "    # Zero-center by mean pixel\n",
        "    if backend.dtype(x) != backend.dtype(mean_tensor):\n",
        "        x = backend.bias_add(\n",
        "            x, backend.cast(mean_tensor, backend.dtype(x)),\n",
        "            data_format=data_format)\n",
        "    else:\n",
        "        x = backend.bias_add(x, mean_tensor, data_format)\n",
        "    if std is not None:\n",
        "        x /= std\n",
        "    return x\n",
        "\n",
        "\n",
        "def preprocess_input(x, data_format=None, mode='caffe', **kwargs):\n",
        "    \"\"\"Preprocesses a tensor or Numpy array encoding a batch of images.\n",
        "    # Arguments\n",
        "        x: Input Numpy or symbolic tensor, 3D or 4D.\n",
        "            The preprocessed data is written over the input data\n",
        "            if the data types are compatible. To avoid this\n",
        "            behaviour, `numpy.copy(x)` can be used.\n",
        "        data_format: Data format of the image tensor/array.\n",
        "        mode: One of \"caffe\", \"tf\" or \"torch\".\n",
        "            - caffe: will convert the images from RGB to BGR,\n",
        "                then will zero-center each color channel with\n",
        "                respect to the ImageNet dataset,\n",
        "                without scaling.\n",
        "            - tf: will scale pixels between -1 and 1,\n",
        "                sample-wise.\n",
        "            - torch: will scale pixels between 0 and 1 and then\n",
        "                will normalize each channel with respect to the\n",
        "                ImageNet dataset.\n",
        "    # Returns\n",
        "        Preprocessed tensor or Numpy array.\n",
        "    # Raises\n",
        "        ValueError: In case of unknown `data_format` argument.\n",
        "    \"\"\"\n",
        "    \n",
        "\n",
        "    if data_format is None:\n",
        "        data_format = backend.image_data_format()\n",
        "    if data_format not in {'channels_first', 'channels_last'}:\n",
        "        raise ValueError('Unknown data_format ' + str(data_format))\n",
        "\n",
        "    if isinstance(x, np.ndarray):\n",
        "        return _preprocess_numpy_input(x, data_format=data_format,\n",
        "                                       mode=mode, **kwargs)\n",
        "    else:\n",
        "        return _preprocess_symbolic_input(x, data_format=data_format,\n",
        "                                          mode=mode, **kwargs)\n",
        "\n",
        "\n",
        "def decode_predictions(preds, top=5, **kwargs):\n",
        "    \"\"\"Decodes the prediction of an ImageNet model.\n",
        "    # Arguments\n",
        "        preds: Numpy tensor encoding a batch of predictions.\n",
        "        top: Integer, how many top-guesses to return.\n",
        "    # Returns\n",
        "        A list of lists of top class prediction tuples\n",
        "        `(class_name, class_description, score)`.\n",
        "        One list of tuples per sample in batch input.\n",
        "    # Raises\n",
        "        ValueError: In case of invalid shape of the `pred` array\n",
        "            (must be 2D).\n",
        "    \"\"\"\n",
        "    global CLASS_INDEX\n",
        "\n",
        "   \n",
        "\n",
        "    if len(preds.shape) != 2 or preds.shape[1] != 1000:\n",
        "        raise ValueError('`decode_predictions` expects '\n",
        "                         'a batch of predictions '\n",
        "                         '(i.e. a 2D array of shape (samples, 1000)). '\n",
        "                         'Found array with shape: ' + str(preds.shape))\n",
        "    if CLASS_INDEX is None:\n",
        "        fpath = utils.get_file(\n",
        "            'imagenet_class_index.json',\n",
        "            CLASS_INDEX_PATH,\n",
        "            cache_subdir='models',\n",
        "            file_hash='c2c37ea517e94d9795004a39431a14cb')\n",
        "        with open(fpath) as f:\n",
        "            CLASS_INDEX = json.load(f)\n",
        "    results = []\n",
        "    for pred in preds:\n",
        "        top_indices = pred.argsort()[-top:][::-1]\n",
        "        result = [tuple(CLASS_INDEX[str(i)]) + (pred[i],) for i in top_indices]\n",
        "        result.sort(key=lambda x: x[2], reverse=True)\n",
        "        results.append(result)\n",
        "    return results\n",
        "\n",
        "\n",
        "def _obtain_input_shape(input_shape,\n",
        "                        default_size,\n",
        "                        min_size,\n",
        "                        data_format,\n",
        "                        require_flatten,\n",
        "                        weights=None):\n",
        "    \"\"\"Internal utility to compute/validate a model's input shape.\n",
        "    # Arguments\n",
        "        input_shape: Either None (will return the default network input shape),\n",
        "            or a user-provided shape to be validated.\n",
        "        default_size: Default input width/height for the model.\n",
        "        min_size: Minimum input width/height accepted by the model.\n",
        "        data_format: Image data format to use.\n",
        "        require_flatten: Whether the model is expected to\n",
        "            be linked to a classifier via a Flatten layer.\n",
        "        weights: One of `None` (random initialization)\n",
        "            or 'imagenet' (pre-training on ImageNet).\n",
        "            If weights='imagenet' input channels must be equal to 3.\n",
        "    # Returns\n",
        "        An integer shape tuple (may include None entries).\n",
        "    # Raises\n",
        "        ValueError: In case of invalid argument values.\n",
        "    \"\"\"\n",
        "    if weights != 'imagenet' and input_shape and len(input_shape) == 3:\n",
        "        if data_format == 'channels_first':\n",
        "            if input_shape[0] not in {1, 3}:\n",
        "                warnings.warn(\n",
        "                    'This model usually expects 1 or 3 input channels. '\n",
        "                    'However, it was passed an input_shape with ' +\n",
        "                    str(input_shape[0]) + ' input channels.')\n",
        "            default_shape = (input_shape[0], default_size, default_size)\n",
        "        else:\n",
        "            if input_shape[-1] not in {1, 3}:\n",
        "                warnings.warn(\n",
        "                    'This model usually expects 1 or 3 input channels. '\n",
        "                    'However, it was passed an input_shape with ' +\n",
        "                    str(input_shape[-1]) + ' input channels.')\n",
        "            default_shape = (default_size, default_size, input_shape[-1])\n",
        "    else:\n",
        "        if data_format == 'channels_first':\n",
        "            default_shape = (3, default_size, default_size)\n",
        "        else:\n",
        "            default_shape = (default_size, default_size, 3)\n",
        "    if weights == 'imagenet' and require_flatten:\n",
        "        if input_shape is not None:\n",
        "            if input_shape != default_shape:\n",
        "                raise ValueError('When setting `include_top=True` '\n",
        "                                 'and loading `imagenet` weights, '\n",
        "                                 '`input_shape` should be ' +\n",
        "                                 str(default_shape) + '.')\n",
        "        return default_shape\n",
        "    if input_shape:\n",
        "        if data_format == 'channels_first':\n",
        "            if input_shape is not None:\n",
        "                if len(input_shape) != 3:\n",
        "                    raise ValueError(\n",
        "                        '`input_shape` must be a tuple of three integers.')\n",
        "                if input_shape[0] != 3 and weights == 'imagenet':\n",
        "                    raise ValueError('The input must have 3 channels; got '\n",
        "                                     '`input_shape=' + str(input_shape) + '`')\n",
        "                if ((input_shape[1] is not None and input_shape[1] < min_size) or\n",
        "                   (input_shape[2] is not None and input_shape[2] < min_size)):\n",
        "                    raise ValueError('Input size must be at least ' +\n",
        "                                     str(min_size) + 'x' + str(min_size) +\n",
        "                                     '; got `input_shape=' +\n",
        "                                     str(input_shape) + '`')\n",
        "        else:\n",
        "            if input_shape is not None:\n",
        "                if len(input_shape) != 3:\n",
        "                    raise ValueError(\n",
        "                        '`input_shape` must be a tuple of three integers.')\n",
        "                if input_shape[-1] != 3 and weights == 'imagenet':\n",
        "                    raise ValueError('The input must have 3 channels; got '\n",
        "                                     '`input_shape=' + str(input_shape) + '`')\n",
        "                if ((input_shape[0] is not None and input_shape[0] < min_size) or\n",
        "                   (input_shape[1] is not None and input_shape[1] < min_size)):\n",
        "                    raise ValueError('Input size must be at least ' +\n",
        "                                     str(min_size) + 'x' + str(min_size) +\n",
        "                                     '; got `input_shape=' +\n",
        "                                     str(input_shape) + '`')\n",
        "    else:\n",
        "        if require_flatten:\n",
        "            input_shape = default_shape\n",
        "        else:\n",
        "            if data_format == 'channels_first':\n",
        "                input_shape = (3, None, None)\n",
        "            else:\n",
        "                input_shape = (None, None, 3)\n",
        "    if require_flatten:\n",
        "        if None in input_shape:\n",
        "            raise ValueError('If `include_top` is True, '\n",
        "                             'you should specify a static `input_shape`. '\n",
        "                             'Got `input_shape=' + str(input_shape) + '`')\n",
        "    return input_shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_vCLgYXlOHvF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"ResNet50 model for Keras.\n",
        "# Reference:\n",
        "- [Deep Residual Learning for Image Recognition](\n",
        "    https://arxiv.org/abs/1512.03385) (CVPR 2016 Best Paper Award)\n",
        "Adapted from code contributed by BigMoyan.\n",
        "\"\"\"\n",
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "import tensorflow as tf\n",
        "import os\n",
        "import warnings\n",
        "import tensorflow.keras.backend as backend\n",
        "import tensorflow.keras.layers as layers\n",
        "import tensorflow.keras.models as models\n",
        "import tensorflow.keras.utils as utils\n",
        "from . import get_submodules_from_kwargs\n",
        "\n",
        "\n",
        "preprocess_input = preprocess_input\n",
        "\n",
        "WEIGHTS_PATH = ('https://github.com/fchollet/deep-learning-models/'\n",
        "                'releases/download/v0.2/'\n",
        "                'resnet50_weights_tf_dim_ordering_tf_kernels.h5')\n",
        "WEIGHTS_PATH_NO_TOP = ('https://github.com/fchollet/deep-learning-models/'\n",
        "                       'releases/download/v0.2/'\n",
        "                       'resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5')\n",
        "\n",
        "\n",
        "def identity_block(input_tensor, kernel_size, filters, stage, block):\n",
        "    \"\"\"The identity block is the block that has no conv layer at shortcut.\n",
        "    # Arguments\n",
        "        input_tensor: input tensor\n",
        "        kernel_size: default 3, the kernel size of\n",
        "            middle conv layer at main path\n",
        "        filters: list of integers, the filters of 3 conv layer at main path\n",
        "        stage: integer, current stage label, used for generating layer names\n",
        "        block: 'a','b'..., current block label, used for generating layer names\n",
        "    # Returns\n",
        "        Output tensor for the block.\n",
        "    \"\"\"\n",
        "    filters1, filters2, filters3 = filters\n",
        "    if tf.keras.backend.image_data_format() == 'channels_last':\n",
        "        bn_axis = 3\n",
        "    else:\n",
        "        bn_axis = 1\n",
        "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
        "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
        "\n",
        "    x = layers.Conv2D(filters1, (1, 1),\n",
        "                      kernel_initializer='he_normal',\n",
        "                      name=conv_name_base + '2a')(input_tensor)\n",
        "    x = layers.BatchNormalization(axis=bn_axis, name=bn_name_base + '2a')(x)\n",
        "    x = layers.Activation('relu')(x)\n",
        "\n",
        "    x = layers.Conv2D(filters2, kernel_size,\n",
        "                      padding='same',\n",
        "                      kernel_initializer='he_normal',\n",
        "                      name=conv_name_base + '2b')(x)\n",
        "    x = layers.BatchNormalization(axis=bn_axis, name=bn_name_base + '2b')(x)\n",
        "    x = layers.Activation('relu')(x)\n",
        "\n",
        "    x = layers.Conv2D(filters3, (1, 1),\n",
        "                      kernel_initializer='he_normal',\n",
        "                      name=conv_name_base + '2c')(x)\n",
        "    x = layers.BatchNormalization(axis=bn_axis, name=bn_name_base + '2c')(x)\n",
        "\n",
        "    x = layers.add([x, input_tensor])\n",
        "    x = layers.Activation('relu')(x)\n",
        "    return x\n",
        "\n",
        "\n",
        "def conv_block(input_tensor,\n",
        "               kernel_size,\n",
        "               filters,\n",
        "               stage,\n",
        "               block,\n",
        "               strides=(2, 2)):\n",
        "    \"\"\"A block that has a conv layer at shortcut.\n",
        "    # Arguments\n",
        "        input_tensor: input tensor\n",
        "        kernel_size: default 3, the kernel size of\n",
        "            middle conv layer at main path\n",
        "        filters: list of integers, the filters of 3 conv layer at main path\n",
        "        stage: integer, current stage label, used for generating layer names\n",
        "        block: 'a','b'..., current block label, used for generating layer names\n",
        "        strides: Strides for the first conv layer in the block.\n",
        "    # Returns\n",
        "        Output tensor for the block.\n",
        "    Note that from stage 3,\n",
        "    the first conv layer at main path is with strides=(2, 2)\n",
        "    And the shortcut should have strides=(2, 2) as well\n",
        "    \"\"\"\n",
        "    filters1, filters2, filters3 = filters\n",
        "    if tf.keras.backend.image_data_format() == 'channels_last':\n",
        "        bn_axis = 3\n",
        "    else:\n",
        "        bn_axis = 1\n",
        "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
        "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
        "\n",
        "    x = layers.Conv2D(filters1, (1, 1), strides=strides,\n",
        "                      kernel_initializer='he_normal',\n",
        "                      name=conv_name_base + '2a')(input_tensor)\n",
        "    x = layers.BatchNormalization(axis=bn_axis, name=bn_name_base + '2a')(x)\n",
        "    x = layers.Activation('relu')(x)\n",
        "\n",
        "    x = layers.Conv2D(filters2, kernel_size, padding='same',\n",
        "                      kernel_initializer='he_normal',\n",
        "                      name=conv_name_base + '2b')(x)\n",
        "    x = layers.BatchNormalization(axis=bn_axis, name=bn_name_base + '2b')(x)\n",
        "    x = layers.Activation('relu')(x)\n",
        "\n",
        "    x = layers.Conv2D(filters3, (1, 1),\n",
        "                      kernel_initializer='he_normal',\n",
        "                      name=conv_name_base + '2c')(x)\n",
        "    x = layers.BatchNormalization(axis=bn_axis, name=bn_name_base + '2c')(x)\n",
        "\n",
        "    shortcut = layers.Conv2D(filters3, (1, 1), strides=strides,\n",
        "                             kernel_initializer='he_normal',\n",
        "                             name=conv_name_base + '1')(input_tensor)\n",
        "    shortcut = layers.BatchNormalization(\n",
        "        axis=bn_axis, name=bn_name_base + '1')(shortcut)\n",
        "\n",
        "    x = layers.add([x, shortcut])\n",
        "    x = layers.Activation('relu')(x)\n",
        "    return x\n",
        "\n",
        "\n",
        "def ResNet50(include_top=True,\n",
        "             weights='imagenet',\n",
        "             input_tensor=None,\n",
        "             input_shape=None,\n",
        "             pooling=None,\n",
        "             classes=1000,\n",
        "             **kwargs):\n",
        "    \"\"\"Instantiates the ResNet50 architecture.\n",
        "    Optionally loads weights pre-trained on ImageNet.\n",
        "    Note that the data format convention used by the model is\n",
        "    the one specified in your Keras config at `~/.keras/keras.json`.\n",
        "    # Arguments\n",
        "        include_top: whether to include the fully-connected\n",
        "            layer at the top of the network.\n",
        "        weights: one of `None` (random initialization),\n",
        "              'imagenet' (pre-training on ImageNet),\n",
        "              or the path to the weights file to be loaded.\n",
        "        input_tensor: optional Keras tensor (i.e. output of `layers.Input()`)\n",
        "            to use as image input for the model.\n",
        "        input_shape: optional shape tuple, only to be specified\n",
        "            if `include_top` is False (otherwise the input shape\n",
        "            has to be `(224, 224, 3)` (with `channels_last` data format)\n",
        "            or `(3, 224, 224)` (with `channels_first` data format).\n",
        "            It should have exactly 3 inputs channels,\n",
        "            and width and height should be no smaller than 32.\n",
        "            E.g. `(200, 200, 3)` would be one valid value.\n",
        "        pooling: Optional pooling mode for feature extraction\n",
        "            when `include_top` is `False`.\n",
        "            - `None` means that the output of the model will be\n",
        "                the 4D tensor output of the\n",
        "                last convolutional block.\n",
        "            - `avg` means that global average pooling\n",
        "                will be applied to the output of the\n",
        "                last convolutional block, and thus\n",
        "                the output of the model will be a 2D tensor.\n",
        "            - `max` means that global max pooling will\n",
        "                be applied.\n",
        "        classes: optional number of classes to classify images\n",
        "            into, only to be specified if `include_top` is True, and\n",
        "            if no `weights` argument is specified.\n",
        "    # Returns\n",
        "        A Keras model instance.\n",
        "    # Raises\n",
        "        ValueError: in case of invalid argument for `weights`,\n",
        "            or invalid input shape.\n",
        "    \"\"\"\n",
        "   \n",
        "\n",
        "    if not (weights in {'imagenet', None} or os.path.exists(weights)):\n",
        "        raise ValueError('The `weights` argument should be either '\n",
        "                         '`None` (random initialization), `imagenet` '\n",
        "                         '(pre-training on ImageNet), '\n",
        "                         'or the path to the weights file to be loaded.')\n",
        "\n",
        "    if weights == 'imagenet' and include_top and classes != 1000:\n",
        "        raise ValueError('If using `weights` as `\"imagenet\"` with `include_top`'\n",
        "                         ' as true, `classes` should be 1000')\n",
        "\n",
        "    # Determine proper input shape\n",
        "    input_shape = _obtain_input_shape(input_shape,\n",
        "                                      default_size=224,\n",
        "                                      min_size=32,\n",
        "                                      data_format=tf.keras.backend.image_data_format(),\n",
        "                                      require_flatten=include_top,\n",
        "                                      weights=weights)\n",
        "\n",
        "    if input_tensor is None:\n",
        "        img_input = layers.Input(shape=input_shape)\n",
        "    else:\n",
        "        if not backend.is_keras_tensor(input_tensor):\n",
        "            img_input = layers.Input(tensor=input_tensor, shape=input_shape)\n",
        "        else:\n",
        "            img_input = input_tensor\n",
        "    if tf.keras.backend.image_data_format() == 'channels_last':\n",
        "        bn_axis = 3\n",
        "    else:\n",
        "        bn_axis = 1\n",
        "\n",
        "    x = layers.ZeroPadding2D(padding=(3, 3), name='conv1_pad')(img_input)\n",
        "    x = layers.Conv2D(64, (7, 7),\n",
        "                      strides=(2, 2),\n",
        "                      padding='valid',\n",
        "                      kernel_initializer='he_normal',\n",
        "                      name='conv1')(x)\n",
        "    x = layers.BatchNormalization(axis=bn_axis, name='bn_conv1')(x)\n",
        "    x = layers.Activation('relu')(x)\n",
        "    x = layers.ZeroPadding2D(padding=(1, 1), name='pool1_pad')(x)\n",
        "    x = layers.MaxPooling2D((3, 3), strides=(2, 2))(x)\n",
        "\n",
        "    x = conv_block(x, 3, [64, 64, 256], stage=2, block='a', strides=(1, 1))\n",
        "    x = identity_block(x, 3, [64, 64, 256], stage=2, block='b')\n",
        "    x = identity_block(x, 3, [64, 64, 256], stage=2, block='c')\n",
        "\n",
        "    x = conv_block(x, 3, [128, 128, 512], stage=3, block='a')\n",
        "    x = identity_block(x, 3, [128, 128, 512], stage=3, block='b')\n",
        "    x = identity_block(x, 3, [128, 128, 512], stage=3, block='c')\n",
        "    x = identity_block(x, 3, [128, 128, 512], stage=3, block='d')\n",
        "\n",
        "    x = conv_block(x, 3, [256, 256, 1024], stage=4, block='a')\n",
        "    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='b')\n",
        "    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='c')\n",
        "    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='d')\n",
        "    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='e')\n",
        "    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='f')\n",
        "\n",
        "    x = conv_block(x, 3, [512, 512, 2048], stage=5, block='a')\n",
        "    x = identity_block(x, 3, [512, 512, 2048], stage=5, block='b')\n",
        "    x = identity_block(x, 3, [512, 512, 2048], stage=5, block='c')\n",
        "\n",
        "    if include_top:\n",
        "        x = layers.GlobalAveragePooling2D(name='avg_pool')(x)\n",
        "        x = layers.Dense(classes, activation='softmax', name='fc1000')(x)\n",
        "    else:\n",
        "        if pooling == 'avg':\n",
        "            x = layers.GlobalAveragePooling2D()(x)\n",
        "        elif pooling == 'max':\n",
        "            x = layers.GlobalMaxPooling2D()(x)\n",
        "        else:\n",
        "            warnings.warn('The output shape of `ResNet50(include_top=False)` '\n",
        "                          'has been changed since Keras 2.2.0.')\n",
        "\n",
        "    # Ensure that the model takes into account\n",
        "    # any potential predecessors of `input_tensor`.\n",
        "    if input_tensor is not None:\n",
        "        inputs = keras_utils.get_source_inputs(input_tensor)\n",
        "    else:\n",
        "        inputs = img_input\n",
        "    # Create model.\n",
        "    model = models.Model(inputs, x, name='resnet50')\n",
        "\n",
        "    # Load weights.\n",
        "    if weights == 'imagenet':\n",
        "        if include_top:\n",
        "            weights_path = keras_utils.get_file(\n",
        "                'resnet50_weights_tf_dim_ordering_tf_kernels.h5',\n",
        "                WEIGHTS_PATH,\n",
        "                cache_subdir='models',\n",
        "                md5_hash='a7b3fe01876f51b976af0dea6bc144eb')\n",
        "        else:\n",
        "            weights_path = keras_utils.get_file(\n",
        "                'resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5',\n",
        "                WEIGHTS_PATH_NO_TOP,\n",
        "                cache_subdir='models',\n",
        "                md5_hash='a268eb855778b3df3c7506639542a6af')\n",
        "        model.load_weights(weights_path)\n",
        "        if backend.backend() == 'theano':\n",
        "            keras_utils.convert_all_kernels_in_model(model)\n",
        "    elif weights is not None:\n",
        "        model.load_weights(weights)\n",
        "\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "85EIr2N6O15_",
        "colab_type": "code",
        "outputId": "a99117ca-34a2-4fc9-9b03-b6af540d2015",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from keras_applications.imagenet_utils import _obtain_input_shape\n",
        "from keras.applications.inception_v3 import preprocess_input\n",
        "from keras_applications.imagenet_utils import decode_predictions\n",
        "img_height,img_width = 160,160\n",
        "num_classes = 7\n",
        "#If imagenet weights are being loaded, \n",
        "#input must have a static square shape (one of (128, 128), (160, 160), (192, 192), or (224, 224))\n",
        "base_model=ResNet50(weights= None, include_top=False, input_shape= (img_height,img_width,3))\n",
        "#base_model = applications.keras_applications.resnet_common.block1"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:248: UserWarning: The output shape of `ResNet50(include_top=False)` has been changed since Keras 2.2.0.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XHrrGf-1PEGi",
        "colab_type": "code",
        "outputId": "b67391ba-e647-43a3-b211-c8a899417e52",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dropout(0.7)(x)\n",
        "predictions = Dense(num_classes, activation= 'softmax')(x)\n",
        "model = Model(inputs = base_model.input, outputs = predictions)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Large dropout rate: 0.7 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CUdcINSSPJBC",
        "colab_type": "code",
        "outputId": "2a9ea37d-f6fe-4862-c7cf-08414eb9e4c7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "img_width, img_height = 160, 160\n",
        "train_data_dir =( \"/content/drive/My Drive/Skin_cancer_all/skin_cancer\")\n",
        "\n",
        "\n",
        "train_datagen = ImageDataGenerator(rescale=1./255,\n",
        "    validation_split=0.2) # set validation split\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_data_dir,\n",
        "    target_size=(img_width, img_height),\n",
        "    batch_size=8,  \n",
        "    subset='training') # set as training data\n",
        "\n",
        "validation_generator = train_datagen.flow_from_directory(\n",
        "    train_data_dir, # same directory as training data\n",
        "    target_size=(img_width, img_height),\n",
        "    batch_size=8,\n",
        "    subset='validation') # set as validation data"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Found 8015 images belonging to 7 classes.\n",
            "Found 2000 images belonging to 7 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Aes7N2IP4vT",
        "colab_type": "code",
        "outputId": "d3143b64-3d8a-409b-f595-c40eb2f0b42f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.optimizers import adam\n",
        "nb_epochs = 2\n",
        "nb_train_samples = 8015\n",
        "nb_validation_samples = 2000\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "     optimizer='rmsprop',      \n",
        "              metrics=['accuracy'])\n",
        "    # but it used to start model.\n",
        "\n",
        "\n",
        "history=model.fit_generator(train_generator,\n",
        "                    steps_per_epoch=nb_train_samples,\n",
        "                    epochs=nb_epochs\n",
        "                        , validation_data=validation_generator\n",
        "                        , validation_steps=nb_validation_samples)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "8014/8015 [============================>.] - ETA: 0s - loss: 1.4343 - acc: 0.6614Epoch 1/2\n",
            "8015/8015 [==============================] - 4902s 612ms/step - loss: 1.4342 - acc: 0.6614 - val_loss: 2.3165 - val_acc: 0.6705\n",
            "Epoch 2/2\n",
            "8014/8015 [============================>.] - ETA: 0s - loss: 1.1306 - acc: 0.6843Epoch 1/2\n",
            "8015/8015 [==============================] - 2149s 268ms/step - loss: 1.1305 - acc: 0.6843 - val_loss: 186.3717 - val_acc: 0.6705\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WTPcGMpNP6-A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "img_height,img_width = 160,160\n",
        "num_classes = 7\n",
        "#If imagenet weights are being loaded, \n",
        "#input must have a static square shape (one of (128, 128), (160, 160), (192, 192), or (224, 224))\n",
        "base_model_1 = applications.resnet50.ResNet50(weights= None, include_top=False, input_shape= (img_height,img_width,3))\n",
        "#base_model = applications.keras_applications.resnet_common.block1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-JPwh2YbQCh7",
        "colab_type": "code",
        "outputId": "7b8313dc-9dd2-45ce-edc2-2d1f26ebb2a3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "x = base_model_1.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dropout(0.7)(x)\n",
        "predictions = Dense(num_classes, activation= 'softmax')(x)\n",
        "model_1 = Model(inputs = base_model_1.input, outputs = predictions)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Large dropout rate: 0.7 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k7B5XDpqQRCp",
        "colab_type": "code",
        "outputId": "d380ff2a-d302-4357-b8eb-dd0110ec4c39",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.optimizers import adam\n",
        "nb_epochs = 2\n",
        "nb_train_samples = 8015\n",
        "nb_validation_samples = 2000\n",
        "\n",
        "model_1.compile(loss='categorical_crossentropy',\n",
        "     optimizer='rmsprop',      \n",
        "              metrics=['accuracy'])\n",
        "    # but it used to start model.\n",
        "\n",
        "\n",
        "history=model_1.fit_generator(train_generator,\n",
        "                    steps_per_epoch=nb_train_samples,\n",
        "                    epochs=nb_epochs\n",
        "                        , validation_data=validation_generator\n",
        "                        , validation_steps=nb_validation_samples)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "8014/8015 [============================>.] - ETA: 0s - loss: 1.4205 - acc: 0.6612Epoch 1/2\n",
            "8015/8015 [==============================] - 2199s 274ms/step - loss: 1.4203 - acc: 0.6612 - val_loss: 2.2536 - val_acc: 0.6705\n",
            "Epoch 2/2\n",
            "8014/8015 [============================>.] - ETA: 0s - loss: 1.2617 - acc: 0.6802Epoch 1/2\n",
            "8015/8015 [==============================] - 2182s 272ms/step - loss: 1.2620 - acc: 0.6802 - val_loss: 30.0708 - val_acc: 0.6705\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CzcfLKMoMG7b",
        "colab_type": "code",
        "outputId": "efd9f671-b643-47b8-d3fa-49a8037167d9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "nb_epochs=1\n",
        "history=model.fit_generator(train_generator,\n",
        "                    steps_per_epoch=nb_train_samples,\n",
        "                    epochs=nb_epochs\n",
        "                        , validation_data=validation_generator\n",
        "                        , validation_steps=nb_validation_samples)\n",
        "history=model_1.fit_generator(train_generator,\n",
        "                    steps_per_epoch=nb_train_samples,\n",
        "                    epochs=nb_epochs\n",
        "                        , validation_data=validation_generator\n",
        "                        , validation_steps=nb_validation_samples)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5388/8015 [===================>..........] - ETA: 11:07 - loss: 1.0780 - acc: 0.7199"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dObOUZABp-Hk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#resnet 34\n",
        "\n",
        "\"\"\"ResNet50 model for Keras.\n",
        "# Reference:\n",
        "- [Deep Residual Learning for Image Recognition](\n",
        "    https://arxiv.org/abs/1512.03385) (CVPR 2016 Best Paper Award)\n",
        "Adapted from code contributed by BigMoyan.\n",
        "\"\"\"\n",
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "import tensorflow as tf\n",
        "import os\n",
        "import warnings\n",
        "import tensorflow.keras.backend as backend\n",
        "import tensorflow.keras.layers as layers\n",
        "import tensorflow.keras.models as models\n",
        "import tensorflow.keras.utils as utils\n",
        "from . import get_submodules_from_kwargs\n",
        "from keras_applications.imagenet_utils import _obtain_input_shape as _ob\n",
        "\n",
        "preprocess_input = preprocess_input\n",
        "\n",
        "WEIGHTS_PATH = ('https://github.com/fchollet/deep-learning-models/'\n",
        "                'releases/download/v0.2/'\n",
        "                'resnet50_weights_tf_dim_ordering_tf_kernels.h5')\n",
        "WEIGHTS_PATH_NO_TOP = ('https://github.com/fchollet/deep-learning-models/'\n",
        "                       'releases/download/v0.2/'\n",
        "                       'resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5')\n",
        "\n",
        "\n",
        "def identity_block(input_tensor, kernel_size, filters, stage, block):\n",
        "    \"\"\"The identity block is the block that has no conv layer at shortcut.\n",
        "    # Arguments\n",
        "        input_tensor: input tensor\n",
        "        kernel_size: default 3, the kernel size of\n",
        "            middle conv layer at main path\n",
        "        filters: list of integers, the filters of 3 conv layer at main path\n",
        "        stage: integer, current stage label, used for generating layer names\n",
        "        block: 'a','b'..., current block label, used for generating layer names\n",
        "    # Returns\n",
        "        Output tensor for the block.\n",
        "    \"\"\"\n",
        "    filters1, filters2 = filters\n",
        "    if tf.keras.backend.image_data_format() == 'channels_last':\n",
        "        bn_axis = 3\n",
        "    else:\n",
        "        bn_axis = 1\n",
        "  \n",
        "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
        "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
        "\n",
        "   \n",
        "    x = layers.Conv2D(filters1, (1, 1),\n",
        "                      kernel_initializer='he_normal',\n",
        "                      name=conv_name_base + '2a')(input_tensor)\n",
        "    x = layers.BatchNormalization(axis=3, name=bn_name_base + '2a')(x)\n",
        "    x = layers.Activation('relu')(x)\n",
        "  \n",
        "    x = layers.Conv2D(filters2, kernel_size,\n",
        "                      padding='same',\n",
        "                      kernel_initializer='he_normal',\n",
        "                      name=conv_name_base + '2b')(x)\n",
        "    x = layers.BatchNormalization(axis=3, name=bn_name_base + '2b')(x)\n",
        "   \n",
        "    #x = layers.Activation('relu')(x)\n",
        "    \"\"\" x = layers.Conv2D(filters3, (1, 1),\n",
        "                      kernel_initializer='he_normal',\n",
        "                      name=conv_name_base + '2c')(x)\n",
        "    x = layers.BatchNormalization(axis=bn_axis, name=bn_name_base + '2c')(x)\n",
        "    \"\"\"\n",
        "    x = layers.add([x, input_tensor])\n",
        "    x = layers.Activation('relu')(x)\n",
        "   \n",
        "    return x\n",
        "\n",
        "\n",
        "def conv_block(input_tensor,\n",
        "               kernel_size,\n",
        "               filters,\n",
        "               stage,\n",
        "               block,\n",
        "               strides=(2, 2)):\n",
        "    \"\"\"A block that has a conv layer at shortcut.\n",
        "    # Arguments\n",
        "        input_tensor: input tensor\n",
        "        kernel_size: default 3, the kernel size of\n",
        "            middle conv layer at main path\n",
        "        filters: list of integers, the filters of 3 conv layer at main path\n",
        "        stage: integer, current stage label, used for generating layer names\n",
        "        block: 'a','b'..., current block label, used for generating layer names\n",
        "        strides: Strides for the first conv layer in the block.\n",
        "    # Returns\n",
        "        Output tensor for the block.\n",
        "    Note that from stage 3,\n",
        "    the first conv layer at main path is with strides=(2, 2)\n",
        "    And the shortcut should have strides=(2, 2) as well\n",
        "    \"\"\"\n",
        "    filters1, filters2 = filters\n",
        "    if tf.keras.backend.image_data_format() == 'channels_last':\n",
        "        bn_axis = 3\n",
        "    else:\n",
        "        bn_axis = 1\n",
        "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
        "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
        "\n",
        "    x = layers.Conv2D(filters1, (3,3), strides=strides,\n",
        "                      kernel_initializer='he_normal',\n",
        "                      name=conv_name_base + '2a')(input_tensor)\n",
        "    x = layers.BatchNormalization(axis=3, name=bn_name_base + '2a')(x)\n",
        "    x = layers.Activation('relu')(x)\n",
        "\n",
        "    x = layers.Conv2D(filters2, kernel_size, padding='same',\n",
        "                      kernel_initializer='he_normal',\n",
        "                      name=conv_name_base + '2b')(x)\n",
        "    x = layers.BatchNormalization(axis=3, name=bn_name_base + '2b')(x)\n",
        "    #x = layers.Activation('relu')(x)\n",
        "\n",
        "    \"\"\" x = layers.Conv2D(filters3, (1, 1),\n",
        "                      kernel_initializer='he_normal',\n",
        "                      name=conv_name_base + '2c')(x)\n",
        "    x = layers.BatchNormalization(axis=bn_axis, name=bn_name_base + '2c')(x)\n",
        "    \"\"\"\n",
        "    shortcut = layers.Conv2D(filters2, (3, 3), strides=strides,\n",
        "                             kernel_initializer='he_normal',\n",
        "                             name=conv_name_base + '1')(input_tensor)\n",
        "    shortcut = layers.BatchNormalization(\n",
        "        axis=3, name=bn_name_base + '1')(shortcut)\n",
        "\n",
        "    x = layers.add([x, shortcut])\n",
        "    x = layers.Activation('relu')(x)\n",
        "    return x\n",
        "\n",
        "\n",
        "def ResNet34(include_top=True,\n",
        "             weights='imagenet',\n",
        "             input_tensor=None,\n",
        "             input_shape=None,\n",
        "             pooling=None,\n",
        "             classes=1000,\n",
        "             **kwargs):\n",
        "  \n",
        "   \n",
        "\n",
        "    if not (weights in {'imagenet', None} or os.path.exists(weights)):\n",
        "        raise ValueError('The `weights` argument should be either '\n",
        "                         '`None` (random initialization), `imagenet` '\n",
        "                         '(pre-training on ImageNet), '\n",
        "                         'or the path to the weights file to be loaded.')\n",
        "\n",
        "    if weights == 'imagenet' and include_top and classes != 1000:\n",
        "        raise ValueError('If using `weights` as `\"imagenet\"` with `include_top`'\n",
        "                         ' as true, `classes` should be 1000')\n",
        "\n",
        "    # Determine proper input shape\n",
        "    input_shape = _obtain_input_shape(input_shape,\n",
        "                                      default_size=224,\n",
        "                                      min_size=34,\n",
        "                                      data_format=tf.keras.backend.image_data_format(),\n",
        "                                      require_flatten=include_top,\n",
        "                                      weights=weights)\n",
        "    print(input_shape)\n",
        "    if input_tensor is None:\n",
        "        img_input = layers.Input(shape=input_shape)\n",
        "    else:\n",
        "        if not backend.is_keras_tensor(input_tensor):\n",
        "            img_input = layers.Input(tensor=input_tensor, shape=input_shape)\n",
        "        else:\n",
        "            img_input = input_tensor\n",
        "    if tf.keras.backend.image_data_format() == 'channels_last':\n",
        "        bn_axis = 3\n",
        "    else:\n",
        "        bn_axis = 1\n",
        "    \n",
        "    x = layers.ZeroPadding2D(padding=(3, 3), name='conv1_pad')(img_input)\n",
        "    x = layers.Conv2D(64, (7, 7),\n",
        "                      strides=(2, 2),\n",
        "                      padding='valid',\n",
        "                      kernel_initializer='he_normal',\n",
        "                      name='conv1')(x)\n",
        "    x = layers.BatchNormalization(axis=3, name='bn_conv1')(x)\n",
        "    x = layers.Activation('relu')(x)\n",
        "    x = layers.ZeroPadding2D(padding=(1, 1), name='pool1_pad')(x)\n",
        "    x = layers.MaxPooling2D((3, 3), strides=(2, 2))(x)\n",
        "\n",
        "    \n",
        "    x = conv_block(x, 3, [64, 64], stage=2, block='a', strides=(1, 1))\n",
        "    print(backend.int_shape(x))\n",
        "    x = identity_block(x, 3, [64, 64], stage=2, block='b')\n",
        "  \n",
        "    x = identity_block(x, 3, [64, 64], stage=2, block='c')\n",
        "   \n",
        "    x = conv_block(x, 3, [128, 128], stage=3, block='a')\n",
        "    x = identity_block(x, 3, [128, 128], stage=3, block='b')\n",
        "    x = identity_block(x, 3, [128, 128], stage=3, block='c')\n",
        "    x = identity_block(x, 3, [128, 128], stage=3, block='d')\n",
        "   \n",
        "    x = conv_block(x, 3, [256, 256], stage=4, block='a')\n",
        "    x = identity_block(x, 3, [256, 256], stage=4, block='b')\n",
        "    x = identity_block(x, 3, [256, 256], stage=4, block='c')\n",
        "    x = identity_block(x, 3, [256, 256], stage=4, block='d')\n",
        "    x = identity_block(x, 3, [256, 256], stage=4, block='e')\n",
        "    x = identity_block(x, 3, [256, 256], stage=4, block='f')\n",
        "\n",
        "    x = conv_block(x, 3, [512, 512], stage=5, block='a')\n",
        "    x = identity_block(x, 3, [512, 512], stage=5, block='b')\n",
        "    x = identity_block(x, 3, [512, 512], stage=5, block='c')\n",
        "    print(backend.int_shape(x))\n",
        "    if include_top:\n",
        "        x = layers.GlobalAveragePooling2D(name='avg_pool')(x)\n",
        "        x = layers.Dense(classes, activation='softmax', name='fc1000')(x)\n",
        "    else:\n",
        "        if pooling == 'avg':\n",
        "            x = layers.GlobalAveragePooling2D()(x)\n",
        "        elif pooling == 'max':\n",
        "            x = layers.GlobalMaxPooling2D()(x)\n",
        "        else:\n",
        "            warnings.warn('The output shape of `ResNet50(include_top=False)` '\n",
        "                          'has been changed since Keras 2.2.0.')\n",
        "    \n",
        "    # Ensure that the model takes into account\n",
        "    # any potential predecessors of `input_tensor`.\n",
        "    if input_tensor is not None:\n",
        "        inputs = keras_utils.get_source_inputs(input_tensor)\n",
        "    else:\n",
        "        inputs = img_input\n",
        "    # Create model.\n",
        "    model = models.Model(inputs, x, name='resnet50')\n",
        "   \n",
        "    # Load weights.\n",
        "    if weights == 'imagenet':\n",
        "        if include_top:\n",
        "            weights_path = keras_utils.get_file(\n",
        "                'resnet50_weights_tf_dim_ordering_tf_kernels.h5',\n",
        "                WEIGHTS_PATH,\n",
        "                cache_subdir='models',\n",
        "                md5_hash='a7b3fe01876f51b976af0dea6bc144eb')\n",
        "        else:\n",
        "            weights_path = keras_utils.get_file(\n",
        "                'resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5',\n",
        "                WEIGHTS_PATH_NO_TOP,\n",
        "                cache_subdir='models',\n",
        "                md5_hash='a268eb855778b3df3c7506639542a6af')\n",
        "        model.load_weights(weights_path)\n",
        "        if backend.backend() == 'theano':\n",
        "            keras_utils.convert_all_kernels_in_model(model)\n",
        "    elif weights is not None:\n",
        "        model.load_weights(weights)\n",
        "\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z8oWYTEYt7OG",
        "colab_type": "code",
        "outputId": "40f7d630-e433-4afa-8413-7dd7a1c74a9f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158
        }
      },
      "source": [
        "from keras_applications.imagenet_utils import _obtain_input_shape\n",
        "from keras.applications.inception_v3 import preprocess_input\n",
        "from keras_applications.imagenet_utils import decode_predictions\n",
        "img_height,img_width = 288,288\n",
        "num_classes = 7\n",
        "#If imagenet weights are being loaded, \n",
        "#input must have a static square shape (one of (128, 128), (160, 160), (192, 192), or (224, 224))\n",
        "base_model=ResNet34(weights= None, include_top=False, input_shape= (img_height,img_width,3))\n",
        "#base_model = applications.keras_applications.resnet_common.block1"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(288, 288, 3)\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "(None, 70, 70, 64)\n",
            "(None, 7, 7, 512)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:217: UserWarning: The output shape of `ResNet50(include_top=False)` has been changed since Keras 2.2.0.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uWkwdlott8R5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(17, activation= 'tanh')(x)\n",
        "x = Dropout(0.5)(x)\n",
        "x = Dense(17, activation= 'tanh')(x)\n",
        "x = Dropout(0.5)(x)\n",
        "predictions = Dense(num_classes, activation= 'softmax')(x)\n",
        "model = Model(inputs = base_model.input, outputs = predictions)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bl3Byzu-t8ki",
        "colab_type": "code",
        "outputId": "92263d4f-f234-4722-ed8f-7daaf0e98dfd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "img_width, img_height = 288, 288\n",
        "train_data_dir =( \"/content/drive/My Drive/Skin_cancer_all/skin_cancer\")\n",
        "\n",
        "\n",
        "train_datagen = ImageDataGenerator(rescale=1./255,\n",
        "    validation_split=0.1) # set validation split\n",
        "train_datagen1 = ImageDataGenerator(rescale=1./255,horizontal_flip=True)\n",
        "test_generator = train_datagen1.flow_from_directory(\n",
        "    train_data_dir,\n",
        "    target_size=(img_width, img_height),\n",
        "    batch_size=32,  \n",
        "    \n",
        "    class_mode=\"sparse\") # set as training data\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_data_dir,\n",
        "    target_size=(img_width, img_height),\n",
        "    batch_size=32,  \n",
        "   \n",
        "    class_mode=\"sparse\",\n",
        "    subset='training') # set as training data\n",
        "\n",
        "validation_generator = train_datagen.flow_from_directory(\n",
        "    train_data_dir, # same directory as training data\n",
        "    target_size=(img_width, img_height),\n",
        "    batch_size=32,\n",
        "     \n",
        "      class_mode=\"sparse\",\n",
        "    subset='validation') # set as validation data"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Found 10015 images belonging to 7 classes.\n",
            "Found 9017 images belonging to 7 classes.\n",
            "Found 998 images belonging to 7 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f4Iry0ZyaDHD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.load_weights(\"/content/drive/My Drive/Colab Notebooks/skin_cancer_all_model_resnet34_weights_26_epoch_edited_batch_size_32_val_loss_better_val_acc_72_acc_96.h5\")\n",
        "#skin_cancer_all_model_resnet34_weights_26_epoch_edited_batch_size_32_val_loss_better_val_acc_72_acc_96"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UQrlOaHkasNq",
        "colab_type": "code",
        "outputId": "c2ace1f6-c3d2-42bd-e05c-123abf9607c6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "\n",
        "acc = model.evaluate_generator(train_generator, steps=2, verbose=1)\n",
        "print(acc)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2/2 [==============================] - 1s 272ms/step - loss: 21.9589 - acc: 0.0000e+00\n",
            "[21.958894729614258, 0.0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gxJ_f4y_t8yI",
        "colab_type": "code",
        "outputId": "b554a866-5470-4a75-c498-7105eac4e393",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 234
        }
      },
      "source": [
        "\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.optimizers import adam\n",
        "nb_epochs = 10\n",
        "nb_train_samples = 300\n",
        "nb_validation_samples = 40\n",
        "\n",
        "model.compile(loss='sparse_categorical_crossentropy',\n",
        "     optimizer='rmsprop', metrics=['accuracy'])\n",
        "    # but it used to start model.\n",
        "epochs_to_wait_for_improve=6\n",
        "early_stopping_callback = EarlyStopping(monitor='val_loss', patience=epochs_to_wait_for_improve)\n",
        "checkpoint_callback = ModelCheckpoint('resnet34_with_2drop_out.h5', monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
        "history=model.fit_generator(train_generator,\n",
        "                    steps_per_epoch=nb_train_samples,\n",
        "                    epochs=nb_epochs\n",
        "                        , validation_data=validation_generator\n",
        "                        , validation_steps=nb_validation_samples\n",
        "                        ,callbacks=[early_stopping_callback, checkpoint_callback])"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-77-e60c15a83530>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclear_cache\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mEarlyStopping\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModelCheckpoint\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0madam\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HklsZM1vPgLM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.load_weights(\"/content/drive/My Drive/Colab Notebooks/skin_cancer_all_model_resnet34_2drop_2denes_weights_acc_80_val_acc_70.h5\")\n",
        "model.compile(loss='sparse_categorical_crossentropy',\n",
        "     optimizer='rmsprop',      \n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZEzeKkgIxQoH",
        "colab_type": "code",
        "outputId": "8f86cf65-baf7-46c0-d0a0-c54b69b26de7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "\n",
        "\n",
        "acc = model.evaluate_generator(train_generator, steps=10, verbose=1)\n",
        "print(acc)\n",
        "acc = model.evaluate_generator(validation_generator, steps=10, verbose=1)\n",
        "print(acc)\n",
        "acc = model.evaluate_generator(test_generator, steps=10, verbose=1)\n",
        "print(acc)\n"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10/10 [==============================] - 3s 282ms/step - loss: 0.7534 - acc: 0.8031\n",
            "[0.7534050554037094, 0.803125]\n",
            "10/10 [==============================] - 3s 280ms/step - loss: 1.2901 - acc: 0.7156\n",
            "[1.2900558292865754, 0.715625]\n",
            "10/10 [==============================] - 3s 278ms/step - loss: 0.7555 - acc: 0.8125\n",
            "[0.7554945617914199, 0.8125]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p551OsdHaGcP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "a2f1b0de-68c4-44f2-d409-3845ed07132f"
      },
      "source": [
        "\n",
        "\n",
        "acc = model.evaluate_generator(train_generator, steps=10, verbose=1)\n",
        "print(acc)\n",
        "acc = model.evaluate_generator(validation_generator, steps=10, verbose=1)\n",
        "print(acc)\n",
        "acc = model.evaluate_generator(test_generator, steps=10, verbose=1)\n",
        "print(acc)\n"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10/10 [==============================] - 2s 177ms/step - loss: 0.8714 - acc: 0.7281\n",
            "[0.871381688117981, 0.728125]\n",
            "10/10 [==============================] - 2s 185ms/step - loss: 1.0115 - acc: 0.6969\n",
            "[1.0114582777023315, 0.696875]\n",
            "10/10 [==============================] - 2s 192ms/step - loss: 0.9834 - acc: 0.7031\n",
            "[0.9834308385848999, 0.703125]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AlkrJaUJxWgA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save_weights( 'skin_cancer_all_model_resnet34-3block_2drop_2denes_weights_acc_80_val_acc_74_without_overfitting.h5')\n",
        "model.save('skin_cancer_all_model_structure_resnet34-3block_2drop_2denes_acc_80_val_acc_74.h5_without_overfitting')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H0od9TBWE1fZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nb_epochs = 10\n",
        "nb_train_samples = 300\n",
        "nb_validation_samples = 40\n",
        "epochs_to_wait_for_improve=6\n",
        "early_stopping_callback = EarlyStopping(monitor='val_loss', patience=epochs_to_wait_for_improve)\n",
        "checkpoint_callback = ModelCheckpoint('resnet34_with_2drop_out.h5', monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
        "history=model.fit_generator(train_generator,\n",
        "                    steps_per_epoch=nb_train_samples,\n",
        "                          epochs=nb_epochs\n",
        "                        , validation_data=validation_generator\n",
        "                        , validation_steps=nb_validation_samples\n",
        "                        , callbacks=[early_stopping_callback, checkpoint_callback])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vnj1e-_cx049",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save_weights('skin_cancer_all_model_resnet34_weights_26_epoch_edited_batch_size_32_val_loss_better_val_acc_74_acc_98_val_loss_2.6.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JvEe9eZ54Kkh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(history.history)\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MI77AFxWbbEq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#resnet 34-3 blocks\n",
        "\n",
        "\"\"\"ResNet50 model for Keras.\n",
        "# Reference:\n",
        "- [Deep Residual Learning for Image Recognition](\n",
        "    https://arxiv.org/abs/1512.03385) (CVPR 2016 Best Paper Award)\n",
        "Adapted from code contributed by BigMoyan.\n",
        "\"\"\"\n",
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "import tensorflow as tf\n",
        "import os\n",
        "import warnings\n",
        "import tensorflow.keras.backend as backend\n",
        "import tensorflow.keras.layers as layers\n",
        "import tensorflow.keras.models as models\n",
        "import tensorflow.keras.utils as utils\n",
        "from . import get_submodules_from_kwargs\n",
        "from keras_applications.imagenet_utils import _obtain_input_shape as _ob\n",
        "\n",
        "preprocess_input = preprocess_input\n",
        "\n",
        "WEIGHTS_PATH = ('https://github.com/fchollet/deep-learning-models/'\n",
        "                'releases/download/v0.2/'\n",
        "                'resnet50_weights_tf_dim_ordering_tf_kernels.h5')\n",
        "WEIGHTS_PATH_NO_TOP = ('https://github.com/fchollet/deep-learning-models/'\n",
        "                       'releases/download/v0.2/'\n",
        "                       'resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5')\n",
        "\n",
        "\n",
        "def identity_block(input_tensor, kernel_size, filters, stage, block):\n",
        "    \"\"\"The identity block is the block that has no conv layer at shortcut.\n",
        "    # Arguments\n",
        "        input_tensor: input tensor\n",
        "        kernel_size: default 3, the kernel size of\n",
        "            middle conv layer at main path\n",
        "        filters: list of integers, the filters of 3 conv layer at main path\n",
        "        stage: integer, current stage label, used for generating layer names\n",
        "        block: 'a','b'..., current block label, used for generating layer names\n",
        "    # Returns\n",
        "        Output tensor for the block.\n",
        "    \"\"\"\n",
        "    filters1, filters2 = filters\n",
        "    if tf.keras.backend.image_data_format() == 'channels_last':\n",
        "        bn_axis = 3\n",
        "    else:\n",
        "        bn_axis = 1\n",
        "  \n",
        "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
        "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
        "\n",
        "   \n",
        "    x = layers.Conv2D(filters1, (1, 1),\n",
        "                      kernel_initializer='he_normal',\n",
        "                      name=conv_name_base + '2a')(input_tensor)\n",
        "    x = layers.BatchNormalization(axis=3, name=bn_name_base + '2a')(x)\n",
        "    x = layers.Activation('relu')(x)\n",
        "  \n",
        "    x = layers.Conv2D(filters2, kernel_size,\n",
        "                      padding='same',\n",
        "                      kernel_initializer='he_normal',\n",
        "                      name=conv_name_base + '2b')(x)\n",
        "    x = layers.BatchNormalization(axis=3, name=bn_name_base + '2b')(x)\n",
        "   \n",
        "    #x = layers.Activation('relu')(x)\n",
        "    \"\"\" x = layers.Conv2D(filters3, (1, 1),\n",
        "                      kernel_initializer='he_normal',\n",
        "                      name=conv_name_base + '2c')(x)\n",
        "    x = layers.BatchNormalization(axis=bn_axis, name=bn_name_base + '2c')(x)\n",
        "    \"\"\"\n",
        "    x = layers.add([x, input_tensor])\n",
        "    x = layers.Activation('relu')(x)\n",
        "   \n",
        "    return x\n",
        "\n",
        "\n",
        "def conv_block(input_tensor,\n",
        "               kernel_size,\n",
        "               filters,\n",
        "               stage,\n",
        "               block,\n",
        "               strides=(2, 2)):\n",
        "    \"\"\"A block that has a conv layer at shortcut.\n",
        "    # Arguments\n",
        "        input_tensor: input tensor\n",
        "        kernel_size: default 3, the kernel size of\n",
        "            middle conv layer at main path\n",
        "        filters: list of integers, the filters of 3 conv layer at main path\n",
        "        stage: integer, current stage label, used for generating layer names\n",
        "        block: 'a','b'..., current block label, used for generating layer names\n",
        "        strides: Strides for the first conv layer in the block.\n",
        "    # Returns\n",
        "        Output tensor for the block.\n",
        "    Note that from stage 3,\n",
        "    the first conv layer at main path is with strides=(2, 2)\n",
        "    And the shortcut should have strides=(2, 2) as well\n",
        "    \"\"\"\n",
        "    filters1, filters2 = filters\n",
        "    if tf.keras.backend.image_data_format() == 'channels_last':\n",
        "        bn_axis = 3\n",
        "    else:\n",
        "        bn_axis = 1\n",
        "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
        "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
        "\n",
        "    x = layers.Conv2D(filters1, (3,3), strides=strides,\n",
        "                      kernel_initializer='he_normal',\n",
        "                      name=conv_name_base + '2a')(input_tensor)\n",
        "    x = layers.BatchNormalization(axis=3, name=bn_name_base + '2a')(x)\n",
        "    x = layers.Activation('relu')(x)\n",
        "\n",
        "    x = layers.Conv2D(filters2, kernel_size, padding='same',\n",
        "                      kernel_initializer='he_normal',\n",
        "                      name=conv_name_base + '2b')(x)\n",
        "    x = layers.BatchNormalization(axis=3, name=bn_name_base + '2b')(x)\n",
        "    #x = layers.Activation('relu')(x)\n",
        "\n",
        "    \"\"\" x = layers.Conv2D(filters3, (1, 1),\n",
        "                      kernel_initializer='he_normal',\n",
        "                      name=conv_name_base + '2c')(x)\n",
        "    x = layers.BatchNormalization(axis=bn_axis, name=bn_name_base + '2c')(x)\n",
        "    \"\"\"\n",
        "    shortcut = layers.Conv2D(filters2, (3, 3), strides=strides,\n",
        "                             kernel_initializer='he_normal',\n",
        "                             name=conv_name_base + '1')(input_tensor)\n",
        "    shortcut = layers.BatchNormalization(\n",
        "        axis=3, name=bn_name_base + '1')(shortcut)\n",
        "\n",
        "    x = layers.add([x, shortcut])\n",
        "    x = layers.Activation('relu')(x)\n",
        "    return x\n",
        "\n",
        "\n",
        "def ResNet34(include_top=True,\n",
        "             weights='imagenet',\n",
        "             input_tensor=None,\n",
        "             input_shape=None,\n",
        "             pooling=None,\n",
        "             classes=1000,\n",
        "             **kwargs):\n",
        "  \n",
        "   \n",
        "\n",
        "    if not (weights in {'imagenet', None} or os.path.exists(weights)):\n",
        "        raise ValueError('The `weights` argument should be either '\n",
        "                         '`None` (random initialization), `imagenet` '\n",
        "                         '(pre-training on ImageNet), '\n",
        "                         'or the path to the weights file to be loaded.')\n",
        "\n",
        "    if weights == 'imagenet' and include_top and classes != 1000:\n",
        "        raise ValueError('If using `weights` as `\"imagenet\"` with `include_top`'\n",
        "                         ' as true, `classes` should be 1000')\n",
        "\n",
        "    # Determine proper input shape\n",
        "    input_shape = _obtain_input_shape(input_shape,\n",
        "                                      default_size=224,\n",
        "                                      min_size=34,\n",
        "                                      data_format=tf.keras.backend.image_data_format(),\n",
        "                                      require_flatten=include_top,\n",
        "                                      weights=weights)\n",
        "    print(input_shape)\n",
        "    if input_tensor is None:\n",
        "        img_input = layers.Input(shape=input_shape)\n",
        "    else:\n",
        "        if not backend.is_keras_tensor(input_tensor):\n",
        "            img_input = layers.Input(tensor=input_tensor, shape=input_shape)\n",
        "        else:\n",
        "            img_input = input_tensor\n",
        "    if tf.keras.backend.image_data_format() == 'channels_last':\n",
        "        bn_axis = 3\n",
        "    else:\n",
        "        bn_axis = 1\n",
        "    \n",
        "    x = layers.ZeroPadding2D(padding=(3, 3), name='conv1_pad')(img_input)\n",
        "    x = layers.Conv2D(64, (7, 7),\n",
        "                      strides=(2, 2),\n",
        "                      padding='valid',\n",
        "                      kernel_initializer='he_normal',\n",
        "                      name='conv1')(x)\n",
        "    x = layers.BatchNormalization(axis=3, name='bn_conv1')(x)\n",
        "    x = layers.Activation('relu')(x)\n",
        "    x = layers.ZeroPadding2D(padding=(1, 1), name='pool1_pad')(x)\n",
        "    x = layers.MaxPooling2D((3, 3), strides=(2, 2))(x)\n",
        "\n",
        "    \n",
        "    x = conv_block(x, 3, [64, 64], stage=2, block='a', strides=(1, 1))\n",
        "    print(backend.int_shape(x))\n",
        "    x = identity_block(x, 3, [64, 64], stage=2, block='b')\n",
        "  \n",
        "    x = identity_block(x, 3, [64, 64], stage=2, block='c')\n",
        "   \n",
        "    x = conv_block(x, 3, [128, 128], stage=3, block='a')\n",
        "    x = identity_block(x, 3, [128, 128], stage=3, block='b')\n",
        "    x = identity_block(x, 3, [128, 128], stage=3, block='c')\n",
        "    #x = identity_block(x, 3, [128, 128], stage=3, block='d')\n",
        "   \n",
        "    x = conv_block(x, 3, [256, 256], stage=4, block='a')\n",
        "    x = identity_block(x, 3, [256, 256], stage=4, block='b')\n",
        "    x = identity_block(x, 3, [256, 256], stage=4, block='c')\n",
        "    x = identity_block(x, 3, [256, 256], stage=4, block='d')\n",
        "    x = identity_block(x, 3, [256, 256], stage=4, block='e')\n",
        "    #x = identity_block(x, 3, [256, 256], stage=4, block='f')\n",
        "\n",
        "    x = conv_block(x, 3, [512, 512], stage=5, block='a')\n",
        "    x = identity_block(x, 3, [512, 512], stage=5, block='b')\n",
        "    #x = identity_block(x, 3, [512, 512], stage=5, block='c')\n",
        "    print(backend.int_shape(x))\n",
        "    if include_top:\n",
        "        x = layers.GlobalAveragePooling2D(name='avg_pool')(x)\n",
        "        x = layers.Dense(classes, activation='softmax', name='fc1000')(x)\n",
        "    else:\n",
        "        if pooling == 'avg':\n",
        "            x = layers.GlobalAveragePooling2D()(x)\n",
        "        elif pooling == 'max':\n",
        "            x = layers.GlobalMaxPooling2D()(x)\n",
        "        else:\n",
        "            warnings.warn('The output shape of `ResNet50(include_top=False)` '\n",
        "                          'has been changed since Keras 2.2.0.')\n",
        "    \n",
        "    # Ensure that the model takes into account\n",
        "    # any potential predecessors of `input_tensor`.\n",
        "    if input_tensor is not None:\n",
        "        inputs = keras_utils.get_source_inputs(input_tensor)\n",
        "    else:\n",
        "        inputs = img_input\n",
        "    # Create model.\n",
        "    model = models.Model(inputs, x, name='resnet50')\n",
        "   \n",
        "    # Load weights.\n",
        "    if weights == 'imagenet':\n",
        "        if include_top:\n",
        "            weights_path = keras_utils.get_file(\n",
        "                'resnet50_weights_tf_dim_ordering_tf_kernels.h5',\n",
        "                WEIGHTS_PATH,\n",
        "                cache_subdir='models',\n",
        "                md5_hash='a7b3fe01876f51b976af0dea6bc144eb')\n",
        "        else:\n",
        "            weights_path = keras_utils.get_file(\n",
        "                'resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5',\n",
        "                WEIGHTS_PATH_NO_TOP,\n",
        "                cache_subdir='models',\n",
        "                md5_hash='a268eb855778b3df3c7506639542a6af')\n",
        "        model.load_weights(weights_path)\n",
        "        if backend.backend() == 'theano':\n",
        "            keras_utils.convert_all_kernels_in_model(model)\n",
        "    elif weights is not None:\n",
        "        model.load_weights(weights)\n",
        "\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r7LdTsshb-as",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "outputId": "29bcf23b-3f6f-44b9-9dc0-e381962b096d"
      },
      "source": [
        "from keras_applications.imagenet_utils import _obtain_input_shape\n",
        "from keras.applications.inception_v3 import preprocess_input\n",
        "from keras_applications.imagenet_utils import decode_predictions\n",
        "img_height,img_width = 288,288\n",
        "num_classes = 7\n",
        "#If imagenet weights are being loaded, \n",
        "#input must have a static square shape (one of (128, 128), (160, 160), (192, 192), or (224, 224))\n",
        "base_model=ResNet34(weights= None, include_top=False, input_shape= (img_height,img_width,3))\n",
        "#base_model = applications.keras_applications.resnet_common.block1\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dropout(0.1)(x)\n",
        "x = Dense(64, activation= 'tanh')(x)\n",
        "x = Dense(32, activation= 'tanh')(x)\n",
        "x = Dropout(0.5)(x)\n",
        "predictions = Dense(num_classes, activation= 'softmax')(x)\n",
        "model = Model(inputs = base_model.input, outputs = predictions)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(288, 288, 3)\n",
            "(None, 70, 70, 64)\n",
            "(None, 7, 7, 512)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:217: UserWarning: The output shape of `ResNet50(include_top=False)` has been changed since Keras 2.2.0.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "asi5Yl_kcKPA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "outputId": "6ffd474b-ed22-431f-a63e-cd7f14c12191"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "img_width, img_height = 288, 288\n",
        "train_data_dir =( \"/content/drive/My Drive/Skin_cancer_all/skin_cancer\")\n",
        "\n",
        "\n",
        "train_datagen = ImageDataGenerator(rescale=1/255,\n",
        "    validation_split=0.19,horizontal_flip=False) # set validation split\n",
        "train_datagen1 = ImageDataGenerator(rescale=1/255,horizontal_flip=False)\n",
        "test_generator = train_datagen1.flow_from_directory(\n",
        "    train_data_dir,\n",
        "    target_size=(img_width, img_height),\n",
        "    batch_size=32,  \n",
        "    \n",
        "    class_mode=\"sparse\") # set as training data\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_data_dir,\n",
        "    target_size=(img_width, img_height),\n",
        "    batch_size=32,  \n",
        "    \n",
        "    class_mode=\"sparse\",\n",
        "    subset='training') # set as training data\n",
        "\n",
        "validation_generator = train_datagen.flow_from_directory(\n",
        "    train_data_dir, # same directory as training data\n",
        "    target_size=(img_width, img_height),\n",
        "    batch_size=32,\n",
        "     \n",
        "      class_mode=\"sparse\",\n",
        "    subset='validation') # set as validation data"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Found 10015 images belonging to 7 classes.\n",
            "Found 8117 images belonging to 7 classes.\n",
            "Found 1898 images belonging to 7 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RzpcV3cacwaz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        },
        "outputId": "c1d82e41-525f-4e03-dc79-6411cd2f0b6f"
      },
      "source": [
        "\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.optimizers import adam\n",
        "nb_epochs = 10\n",
        "nb_train_samples = 255\n",
        "nb_validation_samples = 60\n",
        "\n",
        "#model.compile(loss='sparse_categorical_crossentropy',\n",
        " #    optimizer='rmsprop', metrics=['accuracy'])\n",
        "    # but it used to start model.\n",
        "epochs_to_wait_for_improve=3\n",
        "early_stopping_callback = EarlyStopping(monitor='val_loss', patience=epochs_to_wait_for_improve)\n",
        "checkpoint_callback = ModelCheckpoint('resnet34_with_2drop_out.h5', monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
        "history=model.fit_generator(train_generator,\n",
        "                    steps_per_epoch=nb_train_samples,\n",
        "                    epochs=nb_epochs\n",
        "                        , validation_data=validation_generator\n",
        "                        , validation_steps=nb_validation_samples\n",
        "                        ,callbacks=[early_stopping_callback, checkpoint_callback])"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "254/255 [============================>.] - ETA: 0s - loss: 0.4566 - acc: 0.8504Epoch 1/10\n",
            " 59/255 [=====>........................] - ETA: 37s - loss: 0.7064 - acc: 0.7775\n",
            "Epoch 00001: val_loss improved from inf to 0.70444, saving model to resnet34_with_2drop_out.h5\n",
            "255/255 [==============================] - 65s 254ms/step - loss: 0.4566 - acc: 0.8504 - val_loss: 0.7044 - val_acc: 0.7777\n",
            "Epoch 2/10\n",
            "254/255 [============================>.] - ETA: 0s - loss: 0.4220 - acc: 0.8600Epoch 1/10\n",
            " 59/255 [=====>........................] - ETA: 37s - loss: 0.9406 - acc: 0.6827\n",
            "Epoch 00002: val_loss did not improve from 0.70444\n",
            "255/255 [==============================] - 63s 246ms/step - loss: 0.4227 - acc: 0.8599 - val_loss: 0.9267 - val_acc: 0.6844\n",
            "Epoch 3/10\n",
            "254/255 [============================>.] - ETA: 0s - loss: 0.3819 - acc: 0.8737Epoch 1/10\n",
            " 59/255 [=====>........................] - ETA: 38s - loss: 0.9192 - acc: 0.7606\n",
            "Epoch 00003: val_loss did not improve from 0.70444\n",
            "255/255 [==============================] - 63s 248ms/step - loss: 0.3813 - acc: 0.8741 - val_loss: 0.9131 - val_acc: 0.7613\n",
            "Epoch 4/10\n",
            "254/255 [============================>.] - ETA: 0s - loss: 0.3571 - acc: 0.8860Epoch 1/10\n",
            " 59/255 [=====>........................] - ETA: 38s - loss: 1.0896 - acc: 0.7256\n",
            "Epoch 00004: val_loss did not improve from 0.70444\n",
            "255/255 [==============================] - 63s 246ms/step - loss: 0.3563 - acc: 0.8864 - val_loss: 1.0844 - val_acc: 0.7255\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kd66B9vtANf5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "dac6666e-1a72-489d-92bc-0e998405a9c2"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "acc = model.evaluate_generator(train_generator, steps=10, verbose=1)\n",
        "print(acc)\n",
        "acc = model.evaluate_generator(validation_generator, steps=10, verbose=1)\n",
        "print(acc)\n",
        "acc = model.evaluate_generator(test_generator, steps=10, verbose=1)\n",
        "print(acc)\n"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10/10 [==============================] - 3s 258ms/step - loss: 0.3758 - acc: 0.8687\n",
            "[0.37578956335783004, 0.86875]\n",
            "10/10 [==============================] - 2s 182ms/step - loss: 0.7431 - acc: 0.7563\n",
            "[0.7431276679039002, 0.75625]\n",
            "10/10 [==============================] - 2s 185ms/step - loss: 0.5026 - acc: 0.8406\n",
            "[0.5026028215885162, 0.840625]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}