{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "skin_cancer_test_resnet.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MohmedAAK/skin_cancer/blob/master/skin_cancer_test_resnet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nhDSyO2FZG2o",
        "colab_type": "code",
        "outputId": "72005c88-5ea7-40a2-ab23-50ddbacde0a8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        }
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np \n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "from urllib.request import urlopen,urlretrieve\n",
        "from PIL import Image\n",
        "from tqdm import tqdm_notebook\n",
        "from sklearn.utils import shuffle\n",
        "import cv2\n",
        "\n",
        "from  tensorflow.keras.models import load_model\n",
        "from sklearn.datasets import load_files   \n",
        "from  keras.utils import np_utils\n",
        "from glob import glob\n",
        "from  tensorflow.keras import applications\n",
        "from  tensorflow.keras.preprocessing.image import ImageDataGenerator \n",
        "from  tensorflow.keras import optimizers\n",
        "from  tensorflow.keras.models import Sequential,Model,load_model\n",
        "from  tensorflow.keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D,GlobalAveragePooling2D\n",
        "from  tensorflow.keras.callbacks import TensorBoard,ReduceLROnPlateau,ModelCheckpoint"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BUhTgbWuS7jt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "import tensorflow.keras.backend as backend\n",
        "import tensorflow.keras.layers as layers\n",
        "import tensorflow.keras.models as models\n",
        "import tensorflow.keras.utils as utils\n",
        "\n",
        "_KERAS_BACKEND = None\n",
        "_KERAS_LAYERS = None\n",
        "_KERAS_MODELS = None\n",
        "_KERAS_UTILS = None\n",
        "\n",
        "\n",
        "def get_submodules_from_kwargs(kwargs):\n",
        "    #backend = kwargs.get('backend', _KERAS_BACKEND)\n",
        "    #layers = kwargs.get('layers', _KERAS_LAYERS)\n",
        "    #models = kwargs.get('models', _KERAS_MODELS)\n",
        "    #utils = kwargs.get('utils', _KERAS_UTILS)\n",
        "    #for key in kwargs.keys():\n",
        "     #   if key not in ['backend', 'layers', 'models', 'utils']:\n",
        "      #      raise TypeError('Invalid keyword argument: %s', key)\n",
        "    return backend, layers, models, utils\n",
        "\n",
        "\n",
        "def correct_pad(backend, inputs, kernel_size):\n",
        "    \"\"\"Returns a tuple for zero-padding for 2D convolution with downsampling.\n",
        "    # Arguments\n",
        "        input_size: An integer or tuple/list of 2 integers.\n",
        "        kernel_size: An integer or tuple/list of 2 integers.\n",
        "    # Returns\n",
        "        A tuple.\n",
        "    \"\"\"\n",
        "    img_dim = 2 if backend.image_data_format() == 'channels_first' else 1\n",
        "    input_size = backend.int_shape(inputs)[img_dim:(img_dim + 2)]\n",
        "\n",
        "    if isinstance(kernel_size, int):\n",
        "        kernel_size = (kernel_size, kernel_size)\n",
        "\n",
        "    if input_size[0] is None:\n",
        "        adjust = (1, 1)\n",
        "    else:\n",
        "        adjust = (1 - input_size[0] % 2, 1 - input_size[1] % 2)\n",
        "\n",
        "    correct = (kernel_size[0] // 2, kernel_size[1] // 2)\n",
        "\n",
        "    return ((correct[0] - adjust[0], correct[0]),\n",
        "            (correct[1] - adjust[1], correct[1]))\n",
        "\n",
        "__version__ = '1.0.8'\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zF_uNzemTahi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "import tensorflow as tf\n",
        "import json\n",
        "import warnings\n",
        "import numpy as np\n",
        "import tensorflow.keras.backend as backend\n",
        "import tensorflow.keras.layers as layers\n",
        "import tensorflow.keras.models as models\n",
        "import tensorflow.keras.utils as utils\n",
        "from . import get_submodules_from_kwargs\n",
        "\n",
        "CLASS_INDEX = None\n",
        "CLASS_INDEX_PATH = ('https://storage.googleapis.com/download.tensorflow.org/'\n",
        "                    'data/imagenet_class_index.json')\n",
        "\n",
        "\n",
        "def _preprocess_numpy_input(x, data_format, mode, **kwargs):\n",
        "    \"\"\"Preprocesses a Numpy array encoding a batch of images.\n",
        "    # Arguments\n",
        "        x: Input array, 3D or 4D.\n",
        "        data_format: Data format of the image array.\n",
        "        mode: One of \"caffe\", \"tf\" or \"torch\".\n",
        "            - caffe: will convert the images from RGB to BGR,\n",
        "                then will zero-center each color channel with\n",
        "                respect to the ImageNet dataset,\n",
        "                without scaling.\n",
        "            - tf: will scale pixels between -1 and 1,\n",
        "                sample-wise.\n",
        "            - torch: will scale pixels between 0 and 1 and then\n",
        "                will normalize each channel with respect to the\n",
        "                ImageNet dataset.\n",
        "    # Returns\n",
        "        Preprocessed Numpy array.\n",
        "    \"\"\"\n",
        "  \n",
        "    if not issubclass(x.dtype.type, np.floating):\n",
        "        x = x.astype(backend.floatx(), copy=False)\n",
        "\n",
        "    if mode == 'tf':\n",
        "        x /= 127.5\n",
        "        x -= 1.\n",
        "        return x\n",
        "\n",
        "    if mode == 'torch':\n",
        "        x /= 255.\n",
        "        mean = [0.485, 0.456, 0.406]\n",
        "        std = [0.229, 0.224, 0.225]\n",
        "    else:\n",
        "        if data_format == 'channels_first':\n",
        "            # 'RGB'->'BGR'\n",
        "            if x.ndim == 3:\n",
        "                x = x[::-1, ...]\n",
        "            else:\n",
        "                x = x[:, ::-1, ...]\n",
        "        else:\n",
        "            # 'RGB'->'BGR'\n",
        "            x = x[..., ::-1]\n",
        "        mean = [103.939, 116.779, 123.68]\n",
        "        std = None\n",
        "\n",
        "    # Zero-center by mean pixel\n",
        "    if data_format == 'channels_first':\n",
        "        if x.ndim == 3:\n",
        "            x[0, :, :] -= mean[0]\n",
        "            x[1, :, :] -= mean[1]\n",
        "            x[2, :, :] -= mean[2]\n",
        "            if std is not None:\n",
        "                x[0, :, :] /= std[0]\n",
        "                x[1, :, :] /= std[1]\n",
        "                x[2, :, :] /= std[2]\n",
        "        else:\n",
        "            x[:, 0, :, :] -= mean[0]\n",
        "            x[:, 1, :, :] -= mean[1]\n",
        "            x[:, 2, :, :] -= mean[2]\n",
        "            if std is not None:\n",
        "                x[:, 0, :, :] /= std[0]\n",
        "                x[:, 1, :, :] /= std[1]\n",
        "                x[:, 2, :, :] /= std[2]\n",
        "    else:\n",
        "        x[..., 0] -= mean[0]\n",
        "        x[..., 1] -= mean[1]\n",
        "        x[..., 2] -= mean[2]\n",
        "        if std is not None:\n",
        "            x[..., 0] /= std[0]\n",
        "            x[..., 1] /= std[1]\n",
        "            x[..., 2] /= std[2]\n",
        "    return x\n",
        "\n",
        "\n",
        "def _preprocess_symbolic_input(x, data_format, mode, **kwargs):\n",
        "    \"\"\"Preprocesses a tensor encoding a batch of images.\n",
        "    # Arguments\n",
        "        x: Input tensor, 3D or 4D.\n",
        "        data_format: Data format of the image tensor.\n",
        "        mode: One of \"caffe\", \"tf\" or \"torch\".\n",
        "            - caffe: will convert the images from RGB to BGR,\n",
        "                then will zero-center each color channel with\n",
        "                respect to the ImageNet dataset,\n",
        "                without scaling.\n",
        "            - tf: will scale pixels between -1 and 1,\n",
        "                sample-wise.\n",
        "            - torch: will scale pixels between 0 and 1 and then\n",
        "                will normalize each channel with respect to the\n",
        "                ImageNet dataset.\n",
        "    # Returns\n",
        "        Preprocessed tensor.\n",
        "    \"\"\"\n",
        "\n",
        "\n",
        "    if mode == 'tf':\n",
        "        x /= 127.5\n",
        "        x -= 1.\n",
        "        return x\n",
        "\n",
        "    if mode == 'torch':\n",
        "        x /= 255.\n",
        "        mean = [0.485, 0.456, 0.406]\n",
        "        std = [0.229, 0.224, 0.225]\n",
        "    else:\n",
        "        if data_format == 'channels_first':\n",
        "            # 'RGB'->'BGR'\n",
        "            if backend.ndim(x) == 3:\n",
        "                x = x[::-1, ...]\n",
        "            else:\n",
        "                x = x[:, ::-1, ...]\n",
        "        else:\n",
        "            # 'RGB'->'BGR'\n",
        "            x = x[..., ::-1]\n",
        "        mean = [103.939, 116.779, 123.68]\n",
        "        std = None\n",
        "\n",
        "    mean_tensor = backend.constant(-np.array(mean))\n",
        "\n",
        "    # Zero-center by mean pixel\n",
        "    if backend.dtype(x) != backend.dtype(mean_tensor):\n",
        "        x = backend.bias_add(\n",
        "            x, backend.cast(mean_tensor, backend.dtype(x)),\n",
        "            data_format=data_format)\n",
        "    else:\n",
        "        x = backend.bias_add(x, mean_tensor, data_format)\n",
        "    if std is not None:\n",
        "        x /= std\n",
        "    return x\n",
        "\n",
        "\n",
        "def preprocess_input(x, data_format=None, mode='caffe', **kwargs):\n",
        "    \"\"\"Preprocesses a tensor or Numpy array encoding a batch of images.\n",
        "    # Arguments\n",
        "        x: Input Numpy or symbolic tensor, 3D or 4D.\n",
        "            The preprocessed data is written over the input data\n",
        "            if the data types are compatible. To avoid this\n",
        "            behaviour, `numpy.copy(x)` can be used.\n",
        "        data_format: Data format of the image tensor/array.\n",
        "        mode: One of \"caffe\", \"tf\" or \"torch\".\n",
        "            - caffe: will convert the images from RGB to BGR,\n",
        "                then will zero-center each color channel with\n",
        "                respect to the ImageNet dataset,\n",
        "                without scaling.\n",
        "            - tf: will scale pixels between -1 and 1,\n",
        "                sample-wise.\n",
        "            - torch: will scale pixels between 0 and 1 and then\n",
        "                will normalize each channel with respect to the\n",
        "                ImageNet dataset.\n",
        "    # Returns\n",
        "        Preprocessed tensor or Numpy array.\n",
        "    # Raises\n",
        "        ValueError: In case of unknown `data_format` argument.\n",
        "    \"\"\"\n",
        "    \n",
        "\n",
        "    if data_format is None:\n",
        "        data_format = backend.image_data_format()\n",
        "    if data_format not in {'channels_first', 'channels_last'}:\n",
        "        raise ValueError('Unknown data_format ' + str(data_format))\n",
        "\n",
        "    if isinstance(x, np.ndarray):\n",
        "        return _preprocess_numpy_input(x, data_format=data_format,\n",
        "                                       mode=mode, **kwargs)\n",
        "    else:\n",
        "        return _preprocess_symbolic_input(x, data_format=data_format,\n",
        "                                          mode=mode, **kwargs)\n",
        "\n",
        "\n",
        "def decode_predictions(preds, top=5, **kwargs):\n",
        "    \"\"\"Decodes the prediction of an ImageNet model.\n",
        "    # Arguments\n",
        "        preds: Numpy tensor encoding a batch of predictions.\n",
        "        top: Integer, how many top-guesses to return.\n",
        "    # Returns\n",
        "        A list of lists of top class prediction tuples\n",
        "        `(class_name, class_description, score)`.\n",
        "        One list of tuples per sample in batch input.\n",
        "    # Raises\n",
        "        ValueError: In case of invalid shape of the `pred` array\n",
        "            (must be 2D).\n",
        "    \"\"\"\n",
        "    global CLASS_INDEX\n",
        "\n",
        "   \n",
        "\n",
        "    if len(preds.shape) != 2 or preds.shape[1] != 1000:\n",
        "        raise ValueError('`decode_predictions` expects '\n",
        "                         'a batch of predictions '\n",
        "                         '(i.e. a 2D array of shape (samples, 1000)). '\n",
        "                         'Found array with shape: ' + str(preds.shape))\n",
        "    if CLASS_INDEX is None:\n",
        "        fpath = utils.get_file(\n",
        "            'imagenet_class_index.json',\n",
        "            CLASS_INDEX_PATH,\n",
        "            cache_subdir='models',\n",
        "            file_hash='c2c37ea517e94d9795004a39431a14cb')\n",
        "        with open(fpath) as f:\n",
        "            CLASS_INDEX = json.load(f)\n",
        "    results = []\n",
        "    for pred in preds:\n",
        "        top_indices = pred.argsort()[-top:][::-1]\n",
        "        result = [tuple(CLASS_INDEX[str(i)]) + (pred[i],) for i in top_indices]\n",
        "        result.sort(key=lambda x: x[2], reverse=True)\n",
        "        results.append(result)\n",
        "    return results\n",
        "\n",
        "\n",
        "def _obtain_input_shape(input_shape,\n",
        "                        default_size,\n",
        "                        min_size,\n",
        "                        data_format,\n",
        "                        require_flatten,\n",
        "                        weights=None):\n",
        "    \"\"\"Internal utility to compute/validate a model's input shape.\n",
        "    # Arguments\n",
        "        input_shape: Either None (will return the default network input shape),\n",
        "            or a user-provided shape to be validated.\n",
        "        default_size: Default input width/height for the model.\n",
        "        min_size: Minimum input width/height accepted by the model.\n",
        "        data_format: Image data format to use.\n",
        "        require_flatten: Whether the model is expected to\n",
        "            be linked to a classifier via a Flatten layer.\n",
        "        weights: One of `None` (random initialization)\n",
        "            or 'imagenet' (pre-training on ImageNet).\n",
        "            If weights='imagenet' input channels must be equal to 3.\n",
        "    # Returns\n",
        "        An integer shape tuple (may include None entries).\n",
        "    # Raises\n",
        "        ValueError: In case of invalid argument values.\n",
        "    \"\"\"\n",
        "    if weights != 'imagenet' and input_shape and len(input_shape) == 3:\n",
        "        if data_format == 'channels_first':\n",
        "            if input_shape[0] not in {1, 3}:\n",
        "                warnings.warn(\n",
        "                    'This model usually expects 1 or 3 input channels. '\n",
        "                    'However, it was passed an input_shape with ' +\n",
        "                    str(input_shape[0]) + ' input channels.')\n",
        "            default_shape = (input_shape[0], default_size, default_size)\n",
        "        else:\n",
        "            if input_shape[-1] not in {1, 3}:\n",
        "                warnings.warn(\n",
        "                    'This model usually expects 1 or 3 input channels. '\n",
        "                    'However, it was passed an input_shape with ' +\n",
        "                    str(input_shape[-1]) + ' input channels.')\n",
        "            default_shape = (default_size, default_size, input_shape[-1])\n",
        "    else:\n",
        "        if data_format == 'channels_first':\n",
        "            default_shape = (3, default_size, default_size)\n",
        "        else:\n",
        "            default_shape = (default_size, default_size, 3)\n",
        "    if weights == 'imagenet' and require_flatten:\n",
        "        if input_shape is not None:\n",
        "            if input_shape != default_shape:\n",
        "                raise ValueError('When setting `include_top=True` '\n",
        "                                 'and loading `imagenet` weights, '\n",
        "                                 '`input_shape` should be ' +\n",
        "                                 str(default_shape) + '.')\n",
        "        return default_shape\n",
        "    if input_shape:\n",
        "        if data_format == 'channels_first':\n",
        "            if input_shape is not None:\n",
        "                if len(input_shape) != 3:\n",
        "                    raise ValueError(\n",
        "                        '`input_shape` must be a tuple of three integers.')\n",
        "                if input_shape[0] != 3 and weights == 'imagenet':\n",
        "                    raise ValueError('The input must have 3 channels; got '\n",
        "                                     '`input_shape=' + str(input_shape) + '`')\n",
        "                if ((input_shape[1] is not None and input_shape[1] < min_size) or\n",
        "                   (input_shape[2] is not None and input_shape[2] < min_size)):\n",
        "                    raise ValueError('Input size must be at least ' +\n",
        "                                     str(min_size) + 'x' + str(min_size) +\n",
        "                                     '; got `input_shape=' +\n",
        "                                     str(input_shape) + '`')\n",
        "        else:\n",
        "            if input_shape is not None:\n",
        "                if len(input_shape) != 3:\n",
        "                    raise ValueError(\n",
        "                        '`input_shape` must be a tuple of three integers.')\n",
        "                if input_shape[-1] != 3 and weights == 'imagenet':\n",
        "                    raise ValueError('The input must have 3 channels; got '\n",
        "                                     '`input_shape=' + str(input_shape) + '`')\n",
        "                if ((input_shape[0] is not None and input_shape[0] < min_size) or\n",
        "                   (input_shape[1] is not None and input_shape[1] < min_size)):\n",
        "                    raise ValueError('Input size must be at least ' +\n",
        "                                     str(min_size) + 'x' + str(min_size) +\n",
        "                                     '; got `input_shape=' +\n",
        "                                     str(input_shape) + '`')\n",
        "    else:\n",
        "        if require_flatten:\n",
        "            input_shape = default_shape\n",
        "        else:\n",
        "            if data_format == 'channels_first':\n",
        "                input_shape = (3, None, None)\n",
        "            else:\n",
        "                input_shape = (None, None, 3)\n",
        "    if require_flatten:\n",
        "        if None in input_shape:\n",
        "            raise ValueError('If `include_top` is True, '\n",
        "                             'you should specify a static `input_shape`. '\n",
        "                             'Got `input_shape=' + str(input_shape) + '`')\n",
        "    return input_shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_vCLgYXlOHvF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"ResNet50 model for Keras.\n",
        "# Reference:\n",
        "- [Deep Residual Learning for Image Recognition](\n",
        "    https://arxiv.org/abs/1512.03385) (CVPR 2016 Best Paper Award)\n",
        "Adapted from code contributed by BigMoyan.\n",
        "\"\"\"\n",
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "import tensorflow as tf\n",
        "import os\n",
        "import warnings\n",
        "import tensorflow.keras.backend as backend\n",
        "import tensorflow.keras.layers as layers\n",
        "import tensorflow.keras.models as models\n",
        "import tensorflow.keras.utils as utils\n",
        "from . import get_submodules_from_kwargs\n",
        "\n",
        "\n",
        "preprocess_input = preprocess_input\n",
        "\n",
        "WEIGHTS_PATH = ('https://github.com/fchollet/deep-learning-models/'\n",
        "                'releases/download/v0.2/'\n",
        "                'resnet50_weights_tf_dim_ordering_tf_kernels.h5')\n",
        "WEIGHTS_PATH_NO_TOP = ('https://github.com/fchollet/deep-learning-models/'\n",
        "                       'releases/download/v0.2/'\n",
        "                       'resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5')\n",
        "\n",
        "\n",
        "def identity_block(input_tensor, kernel_size, filters, stage, block):\n",
        "    \"\"\"The identity block is the block that has no conv layer at shortcut.\n",
        "    # Arguments\n",
        "        input_tensor: input tensor\n",
        "        kernel_size: default 3, the kernel size of\n",
        "            middle conv layer at main path\n",
        "        filters: list of integers, the filters of 3 conv layer at main path\n",
        "        stage: integer, current stage label, used for generating layer names\n",
        "        block: 'a','b'..., current block label, used for generating layer names\n",
        "    # Returns\n",
        "        Output tensor for the block.\n",
        "    \"\"\"\n",
        "    filters1, filters2, filters3 = filters\n",
        "    if tf.keras.backend.image_data_format() == 'channels_last':\n",
        "        bn_axis = 3\n",
        "    else:\n",
        "        bn_axis = 1\n",
        "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
        "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
        "\n",
        "    x = layers.Conv2D(filters1, (1, 1),\n",
        "                      kernel_initializer='he_normal',\n",
        "                      name=conv_name_base + '2a')(input_tensor)\n",
        "    x = layers.BatchNormalization(axis=bn_axis, name=bn_name_base + '2a')(x)\n",
        "    x = layers.Activation('relu')(x)\n",
        "\n",
        "    x = layers.Conv2D(filters2, kernel_size,\n",
        "                      padding='same',\n",
        "                      kernel_initializer='he_normal',\n",
        "                      name=conv_name_base + '2b')(x)\n",
        "    x = layers.BatchNormalization(axis=bn_axis, name=bn_name_base + '2b')(x)\n",
        "    x = layers.Activation('relu')(x)\n",
        "\n",
        "    x = layers.Conv2D(filters3, (1, 1),\n",
        "                      kernel_initializer='he_normal',\n",
        "                      name=conv_name_base + '2c')(x)\n",
        "    x = layers.BatchNormalization(axis=bn_axis, name=bn_name_base + '2c')(x)\n",
        "\n",
        "    x = layers.add([x, input_tensor])\n",
        "    x = layers.Activation('relu')(x)\n",
        "    return x\n",
        "\n",
        "\n",
        "def conv_block(input_tensor,\n",
        "               kernel_size,\n",
        "               filters,\n",
        "               stage,\n",
        "               block,\n",
        "               strides=(2, 2)):\n",
        "    \"\"\"A block that has a conv layer at shortcut.\n",
        "    # Arguments\n",
        "        input_tensor: input tensor\n",
        "        kernel_size: default 3, the kernel size of\n",
        "            middle conv layer at main path\n",
        "        filters: list of integers, the filters of 3 conv layer at main path\n",
        "        stage: integer, current stage label, used for generating layer names\n",
        "        block: 'a','b'..., current block label, used for generating layer names\n",
        "        strides: Strides for the first conv layer in the block.\n",
        "    # Returns\n",
        "        Output tensor for the block.\n",
        "    Note that from stage 3,\n",
        "    the first conv layer at main path is with strides=(2, 2)\n",
        "    And the shortcut should have strides=(2, 2) as well\n",
        "    \"\"\"\n",
        "    filters1, filters2, filters3 = filters\n",
        "    if tf.keras.backend.image_data_format() == 'channels_last':\n",
        "        bn_axis = 3\n",
        "    else:\n",
        "        bn_axis = 1\n",
        "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
        "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
        "\n",
        "    x = layers.Conv2D(filters1, (1, 1), strides=strides,\n",
        "                      kernel_initializer='he_normal',\n",
        "                      name=conv_name_base + '2a')(input_tensor)\n",
        "    x = layers.BatchNormalization(axis=bn_axis, name=bn_name_base + '2a')(x)\n",
        "    x = layers.Activation('relu')(x)\n",
        "\n",
        "    x = layers.Conv2D(filters2, kernel_size, padding='same',\n",
        "                      kernel_initializer='he_normal',\n",
        "                      name=conv_name_base + '2b')(x)\n",
        "    x = layers.BatchNormalization(axis=bn_axis, name=bn_name_base + '2b')(x)\n",
        "    x = layers.Activation('relu')(x)\n",
        "\n",
        "    x = layers.Conv2D(filters3, (1, 1),\n",
        "                      kernel_initializer='he_normal',\n",
        "                      name=conv_name_base + '2c')(x)\n",
        "    x = layers.BatchNormalization(axis=bn_axis, name=bn_name_base + '2c')(x)\n",
        "\n",
        "    shortcut = layers.Conv2D(filters3, (1, 1), strides=strides,\n",
        "                             kernel_initializer='he_normal',\n",
        "                             name=conv_name_base + '1')(input_tensor)\n",
        "    shortcut = layers.BatchNormalization(\n",
        "        axis=bn_axis, name=bn_name_base + '1')(shortcut)\n",
        "\n",
        "    x = layers.add([x, shortcut])\n",
        "    x = layers.Activation('relu')(x)\n",
        "    return x\n",
        "\n",
        "\n",
        "def ResNet50(include_top=True,\n",
        "             weights='imagenet',\n",
        "             input_tensor=None,\n",
        "             input_shape=None,\n",
        "             pooling=None,\n",
        "             classes=1000,\n",
        "             **kwargs):\n",
        "    \"\"\"Instantiates the ResNet50 architecture.\n",
        "    Optionally loads weights pre-trained on ImageNet.\n",
        "    Note that the data format convention used by the model is\n",
        "    the one specified in your Keras config at `~/.keras/keras.json`.\n",
        "    # Arguments\n",
        "        include_top: whether to include the fully-connected\n",
        "            layer at the top of the network.\n",
        "        weights: one of `None` (random initialization),\n",
        "              'imagenet' (pre-training on ImageNet),\n",
        "              or the path to the weights file to be loaded.\n",
        "        input_tensor: optional Keras tensor (i.e. output of `layers.Input()`)\n",
        "            to use as image input for the model.\n",
        "        input_shape: optional shape tuple, only to be specified\n",
        "            if `include_top` is False (otherwise the input shape\n",
        "            has to be `(224, 224, 3)` (with `channels_last` data format)\n",
        "            or `(3, 224, 224)` (with `channels_first` data format).\n",
        "            It should have exactly 3 inputs channels,\n",
        "            and width and height should be no smaller than 32.\n",
        "            E.g. `(200, 200, 3)` would be one valid value.\n",
        "        pooling: Optional pooling mode for feature extraction\n",
        "            when `include_top` is `False`.\n",
        "            - `None` means that the output of the model will be\n",
        "                the 4D tensor output of the\n",
        "                last convolutional block.\n",
        "            - `avg` means that global average pooling\n",
        "                will be applied to the output of the\n",
        "                last convolutional block, and thus\n",
        "                the output of the model will be a 2D tensor.\n",
        "            - `max` means that global max pooling will\n",
        "                be applied.\n",
        "        classes: optional number of classes to classify images\n",
        "            into, only to be specified if `include_top` is True, and\n",
        "            if no `weights` argument is specified.\n",
        "    # Returns\n",
        "        A Keras model instance.\n",
        "    # Raises\n",
        "        ValueError: in case of invalid argument for `weights`,\n",
        "            or invalid input shape.\n",
        "    \"\"\"\n",
        "   \n",
        "\n",
        "    if not (weights in {'imagenet', None} or os.path.exists(weights)):\n",
        "        raise ValueError('The `weights` argument should be either '\n",
        "                         '`None` (random initialization), `imagenet` '\n",
        "                         '(pre-training on ImageNet), '\n",
        "                         'or the path to the weights file to be loaded.')\n",
        "\n",
        "    if weights == 'imagenet' and include_top and classes != 1000:\n",
        "        raise ValueError('If using `weights` as `\"imagenet\"` with `include_top`'\n",
        "                         ' as true, `classes` should be 1000')\n",
        "\n",
        "    # Determine proper input shape\n",
        "    input_shape = _obtain_input_shape(input_shape,\n",
        "                                      default_size=224,\n",
        "                                      min_size=32,\n",
        "                                      data_format=tf.keras.backend.image_data_format(),\n",
        "                                      require_flatten=include_top,\n",
        "                                      weights=weights)\n",
        "\n",
        "    if input_tensor is None:\n",
        "        img_input = layers.Input(shape=input_shape)\n",
        "    else:\n",
        "        if not backend.is_keras_tensor(input_tensor):\n",
        "            img_input = layers.Input(tensor=input_tensor, shape=input_shape)\n",
        "        else:\n",
        "            img_input = input_tensor\n",
        "    if tf.keras.backend.image_data_format() == 'channels_last':\n",
        "        bn_axis = 3\n",
        "    else:\n",
        "        bn_axis = 1\n",
        "\n",
        "    x = layers.ZeroPadding2D(padding=(3, 3), name='conv1_pad')(img_input)\n",
        "    x = layers.Conv2D(64, (7, 7),\n",
        "                      strides=(2, 2),\n",
        "                      padding='valid',\n",
        "                      kernel_initializer='he_normal',\n",
        "                      name='conv1')(x)\n",
        "    x = layers.BatchNormalization(axis=bn_axis, name='bn_conv1')(x)\n",
        "    x = layers.Activation('relu')(x)\n",
        "    x = layers.ZeroPadding2D(padding=(1, 1), name='pool1_pad')(x)\n",
        "    x = layers.MaxPooling2D((3, 3), strides=(2, 2))(x)\n",
        "\n",
        "    x = conv_block(x, 3, [64, 64, 256], stage=2, block='a', strides=(1, 1))\n",
        "    x = identity_block(x, 3, [64, 64, 256], stage=2, block='b')\n",
        "    x = identity_block(x, 3, [64, 64, 256], stage=2, block='c')\n",
        "\n",
        "    x = conv_block(x, 3, [128, 128, 512], stage=3, block='a')\n",
        "    x = identity_block(x, 3, [128, 128, 512], stage=3, block='b')\n",
        "    x = identity_block(x, 3, [128, 128, 512], stage=3, block='c')\n",
        "    x = identity_block(x, 3, [128, 128, 512], stage=3, block='d')\n",
        "\n",
        "    x = conv_block(x, 3, [256, 256, 1024], stage=4, block='a')\n",
        "    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='b')\n",
        "    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='c')\n",
        "    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='d')\n",
        "    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='e')\n",
        "    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='f')\n",
        "\n",
        "    x = conv_block(x, 3, [512, 512, 2048], stage=5, block='a')\n",
        "    x = identity_block(x, 3, [512, 512, 2048], stage=5, block='b')\n",
        "    x = identity_block(x, 3, [512, 512, 2048], stage=5, block='c')\n",
        "\n",
        "    if include_top:\n",
        "        x = layers.GlobalAveragePooling2D(name='avg_pool')(x)\n",
        "        x = layers.Dense(classes, activation='softmax', name='fc1000')(x)\n",
        "    else:\n",
        "        if pooling == 'avg':\n",
        "            x = layers.GlobalAveragePooling2D()(x)\n",
        "        elif pooling == 'max':\n",
        "            x = layers.GlobalMaxPooling2D()(x)\n",
        "        else:\n",
        "            warnings.warn('The output shape of `ResNet50(include_top=False)` '\n",
        "                          'has been changed since Keras 2.2.0.')\n",
        "\n",
        "    # Ensure that the model takes into account\n",
        "    # any potential predecessors of `input_tensor`.\n",
        "    if input_tensor is not None:\n",
        "        inputs = keras_utils.get_source_inputs(input_tensor)\n",
        "    else:\n",
        "        inputs = img_input\n",
        "    # Create model.\n",
        "    model = models.Model(inputs, x, name='resnet50')\n",
        "\n",
        "    # Load weights.\n",
        "    if weights == 'imagenet':\n",
        "        if include_top:\n",
        "            weights_path = keras_utils.get_file(\n",
        "                'resnet50_weights_tf_dim_ordering_tf_kernels.h5',\n",
        "                WEIGHTS_PATH,\n",
        "                cache_subdir='models',\n",
        "                md5_hash='a7b3fe01876f51b976af0dea6bc144eb')\n",
        "        else:\n",
        "            weights_path = keras_utils.get_file(\n",
        "                'resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5',\n",
        "                WEIGHTS_PATH_NO_TOP,\n",
        "                cache_subdir='models',\n",
        "                md5_hash='a268eb855778b3df3c7506639542a6af')\n",
        "        model.load_weights(weights_path)\n",
        "        if backend.backend() == 'theano':\n",
        "            keras_utils.convert_all_kernels_in_model(model)\n",
        "    elif weights is not None:\n",
        "        model.load_weights(weights)\n",
        "\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "85EIr2N6O15_",
        "colab_type": "code",
        "outputId": "a99117ca-34a2-4fc9-9b03-b6af540d2015",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from keras_applications.imagenet_utils import _obtain_input_shape\n",
        "from keras.applications.inception_v3 import preprocess_input\n",
        "from keras_applications.imagenet_utils import decode_predictions\n",
        "img_height,img_width = 160,160\n",
        "num_classes = 7\n",
        "#If imagenet weights are being loaded, \n",
        "#input must have a static square shape (one of (128, 128), (160, 160), (192, 192), or (224, 224))\n",
        "base_model=ResNet50(weights= None, include_top=False, input_shape= (img_height,img_width,3))\n",
        "#base_model = applications.keras_applications.resnet_common.block1"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:248: UserWarning: The output shape of `ResNet50(include_top=False)` has been changed since Keras 2.2.0.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XHrrGf-1PEGi",
        "colab_type": "code",
        "outputId": "b67391ba-e647-43a3-b211-c8a899417e52",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dropout(0.7)(x)\n",
        "predictions = Dense(num_classes, activation= 'softmax')(x)\n",
        "model = Model(inputs = base_model.input, outputs = predictions)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Large dropout rate: 0.7 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CUdcINSSPJBC",
        "colab_type": "code",
        "outputId": "2a9ea37d-f6fe-4862-c7cf-08414eb9e4c7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "img_width, img_height = 160, 160\n",
        "train_data_dir =( \"/content/drive/My Drive/Skin_cancer_all/skin_cancer\")\n",
        "\n",
        "\n",
        "train_datagen = ImageDataGenerator(rescale=1./255,\n",
        "    validation_split=0.2) # set validation split\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_data_dir,\n",
        "    target_size=(img_width, img_height),\n",
        "    batch_size=8,  \n",
        "    subset='training') # set as training data\n",
        "\n",
        "validation_generator = train_datagen.flow_from_directory(\n",
        "    train_data_dir, # same directory as training data\n",
        "    target_size=(img_width, img_height),\n",
        "    batch_size=8,\n",
        "    subset='validation') # set as validation data"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Found 8015 images belonging to 7 classes.\n",
            "Found 2000 images belonging to 7 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Aes7N2IP4vT",
        "colab_type": "code",
        "outputId": "d3143b64-3d8a-409b-f595-c40eb2f0b42f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.optimizers import adam\n",
        "nb_epochs = 2\n",
        "nb_train_samples = 8015\n",
        "nb_validation_samples = 2000\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "     optimizer='rmsprop',      \n",
        "              metrics=['accuracy'])\n",
        "    # but it used to start model.\n",
        "\n",
        "\n",
        "history=model.fit_generator(train_generator,\n",
        "                    steps_per_epoch=nb_train_samples,\n",
        "                    epochs=nb_epochs\n",
        "                        , validation_data=validation_generator\n",
        "                        , validation_steps=nb_validation_samples)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "8014/8015 [============================>.] - ETA: 0s - loss: 1.4343 - acc: 0.6614Epoch 1/2\n",
            "8015/8015 [==============================] - 4902s 612ms/step - loss: 1.4342 - acc: 0.6614 - val_loss: 2.3165 - val_acc: 0.6705\n",
            "Epoch 2/2\n",
            "8014/8015 [============================>.] - ETA: 0s - loss: 1.1306 - acc: 0.6843Epoch 1/2\n",
            "8015/8015 [==============================] - 2149s 268ms/step - loss: 1.1305 - acc: 0.6843 - val_loss: 186.3717 - val_acc: 0.6705\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WTPcGMpNP6-A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "img_height,img_width = 160,160\n",
        "num_classes = 7\n",
        "#If imagenet weights are being loaded, \n",
        "#input must have a static square shape (one of (128, 128), (160, 160), (192, 192), or (224, 224))\n",
        "base_model_1 = applications.resnet50.ResNet50(weights= None, include_top=False, input_shape= (img_height,img_width,3))\n",
        "#base_model = applications.keras_applications.resnet_common.block1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-JPwh2YbQCh7",
        "colab_type": "code",
        "outputId": "7b8313dc-9dd2-45ce-edc2-2d1f26ebb2a3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "x = base_model_1.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dropout(0.7)(x)\n",
        "predictions = Dense(num_classes, activation= 'softmax')(x)\n",
        "model_1 = Model(inputs = base_model_1.input, outputs = predictions)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Large dropout rate: 0.7 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k7B5XDpqQRCp",
        "colab_type": "code",
        "outputId": "d380ff2a-d302-4357-b8eb-dd0110ec4c39",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.optimizers import adam\n",
        "nb_epochs = 2\n",
        "nb_train_samples = 8015\n",
        "nb_validation_samples = 2000\n",
        "\n",
        "model_1.compile(loss='categorical_crossentropy',\n",
        "     optimizer='rmsprop',      \n",
        "              metrics=['accuracy'])\n",
        "    # but it used to start model.\n",
        "\n",
        "\n",
        "history=model_1.fit_generator(train_generator,\n",
        "                    steps_per_epoch=nb_train_samples,\n",
        "                    epochs=nb_epochs\n",
        "                        , validation_data=validation_generator\n",
        "                        , validation_steps=nb_validation_samples)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "8014/8015 [============================>.] - ETA: 0s - loss: 1.4205 - acc: 0.6612Epoch 1/2\n",
            "8015/8015 [==============================] - 2199s 274ms/step - loss: 1.4203 - acc: 0.6612 - val_loss: 2.2536 - val_acc: 0.6705\n",
            "Epoch 2/2\n",
            "8014/8015 [============================>.] - ETA: 0s - loss: 1.2617 - acc: 0.6802Epoch 1/2\n",
            "8015/8015 [==============================] - 2182s 272ms/step - loss: 1.2620 - acc: 0.6802 - val_loss: 30.0708 - val_acc: 0.6705\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CzcfLKMoMG7b",
        "colab_type": "code",
        "outputId": "efd9f671-b643-47b8-d3fa-49a8037167d9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "nb_epochs=1\n",
        "history=model.fit_generator(train_generator,\n",
        "                    steps_per_epoch=nb_train_samples,\n",
        "                    epochs=nb_epochs\n",
        "                        , validation_data=validation_generator\n",
        "                        , validation_steps=nb_validation_samples)\n",
        "history=model_1.fit_generator(train_generator,\n",
        "                    steps_per_epoch=nb_train_samples,\n",
        "                    epochs=nb_epochs\n",
        "                        , validation_data=validation_generator\n",
        "                        , validation_steps=nb_validation_samples)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5388/8015 [===================>..........] - ETA: 11:07 - loss: 1.0780 - acc: 0.7199"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dObOUZABp-Hk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#resnet 34\n",
        "\n",
        "\"\"\"ResNet50 model for Keras.\n",
        "# Reference:\n",
        "- [Deep Residual Learning for Image Recognition](\n",
        "    https://arxiv.org/abs/1512.03385) (CVPR 2016 Best Paper Award)\n",
        "Adapted from code contributed by BigMoyan.\n",
        "\"\"\"\n",
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "import tensorflow as tf\n",
        "import os\n",
        "import warnings\n",
        "import tensorflow.keras.backend as backend\n",
        "import tensorflow.keras.layers as layers\n",
        "import tensorflow.keras.models as models\n",
        "import tensorflow.keras.utils as utils\n",
        "from . import get_submodules_from_kwargs\n",
        "from keras_applications.imagenet_utils import _obtain_input_shape as _ob\n",
        "\n",
        "preprocess_input = preprocess_input\n",
        "\n",
        "WEIGHTS_PATH = ('https://github.com/fchollet/deep-learning-models/'\n",
        "                'releases/download/v0.2/'\n",
        "                'resnet50_weights_tf_dim_ordering_tf_kernels.h5')\n",
        "WEIGHTS_PATH_NO_TOP = ('https://github.com/fchollet/deep-learning-models/'\n",
        "                       'releases/download/v0.2/'\n",
        "                       'resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5')\n",
        "\n",
        "\n",
        "def identity_block(input_tensor, kernel_size, filters, stage, block):\n",
        "    \"\"\"The identity block is the block that has no conv layer at shortcut.\n",
        "    # Arguments\n",
        "        input_tensor: input tensor\n",
        "        kernel_size: default 3, the kernel size of\n",
        "            middle conv layer at main path\n",
        "        filters: list of integers, the filters of 3 conv layer at main path\n",
        "        stage: integer, current stage label, used for generating layer names\n",
        "        block: 'a','b'..., current block label, used for generating layer names\n",
        "    # Returns\n",
        "        Output tensor for the block.\n",
        "    \"\"\"\n",
        "    filters1, filters2 = filters\n",
        "    if tf.keras.backend.image_data_format() == 'channels_last':\n",
        "        bn_axis = 3\n",
        "    else:\n",
        "        bn_axis = 1\n",
        "  \n",
        "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
        "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
        "\n",
        "   \n",
        "    x = layers.Conv2D(filters1, (1, 1),\n",
        "                      kernel_initializer='he_normal',\n",
        "                      name=conv_name_base + '2a')(input_tensor)\n",
        "    x = layers.BatchNormalization(axis=3, name=bn_name_base + '2a')(x)\n",
        "    x = layers.Activation('relu')(x)\n",
        "  \n",
        "    x = layers.Conv2D(filters2, kernel_size,\n",
        "                      padding='same',\n",
        "                      kernel_initializer='he_normal',\n",
        "                      name=conv_name_base + '2b')(x)\n",
        "    x = layers.BatchNormalization(axis=3, name=bn_name_base + '2b')(x)\n",
        "   \n",
        "    #x = layers.Activation('relu')(x)\n",
        "    \"\"\" x = layers.Conv2D(filters3, (1, 1),\n",
        "                      kernel_initializer='he_normal',\n",
        "                      name=conv_name_base + '2c')(x)\n",
        "    x = layers.BatchNormalization(axis=bn_axis, name=bn_name_base + '2c')(x)\n",
        "    \"\"\"\n",
        "    x = layers.add([x, input_tensor])\n",
        "    x = layers.Activation('relu')(x)\n",
        "   \n",
        "    return x\n",
        "\n",
        "\n",
        "def conv_block(input_tensor,\n",
        "               kernel_size,\n",
        "               filters,\n",
        "               stage,\n",
        "               block,\n",
        "               strides=(2, 2)):\n",
        "    \"\"\"A block that has a conv layer at shortcut.\n",
        "    # Arguments\n",
        "        input_tensor: input tensor\n",
        "        kernel_size: default 3, the kernel size of\n",
        "            middle conv layer at main path\n",
        "        filters: list of integers, the filters of 3 conv layer at main path\n",
        "        stage: integer, current stage label, used for generating layer names\n",
        "        block: 'a','b'..., current block label, used for generating layer names\n",
        "        strides: Strides for the first conv layer in the block.\n",
        "    # Returns\n",
        "        Output tensor for the block.\n",
        "    Note that from stage 3,\n",
        "    the first conv layer at main path is with strides=(2, 2)\n",
        "    And the shortcut should have strides=(2, 2) as well\n",
        "    \"\"\"\n",
        "    filters1, filters2 = filters\n",
        "    if tf.keras.backend.image_data_format() == 'channels_last':\n",
        "        bn_axis = 3\n",
        "    else:\n",
        "        bn_axis = 1\n",
        "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
        "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
        "\n",
        "    x = layers.Conv2D(filters1, (3,3), strides=strides,\n",
        "                      kernel_initializer='he_normal',\n",
        "                      name=conv_name_base + '2a')(input_tensor)\n",
        "    x = layers.BatchNormalization(axis=3, name=bn_name_base + '2a')(x)\n",
        "    x = layers.Activation('relu')(x)\n",
        "\n",
        "    x = layers.Conv2D(filters2, kernel_size, padding='same',\n",
        "                      kernel_initializer='he_normal',\n",
        "                      name=conv_name_base + '2b')(x)\n",
        "    x = layers.BatchNormalization(axis=3, name=bn_name_base + '2b')(x)\n",
        "    #x = layers.Activation('relu')(x)\n",
        "\n",
        "    \"\"\" x = layers.Conv2D(filters3, (1, 1),\n",
        "                      kernel_initializer='he_normal',\n",
        "                      name=conv_name_base + '2c')(x)\n",
        "    x = layers.BatchNormalization(axis=bn_axis, name=bn_name_base + '2c')(x)\n",
        "    \"\"\"\n",
        "    shortcut = layers.Conv2D(filters2, (3, 3), strides=strides,\n",
        "                             kernel_initializer='he_normal',\n",
        "                             name=conv_name_base + '1')(input_tensor)\n",
        "    shortcut = layers.BatchNormalization(\n",
        "        axis=3, name=bn_name_base + '1')(shortcut)\n",
        "\n",
        "    x = layers.add([x, shortcut])\n",
        "    x = layers.Activation('relu')(x)\n",
        "    return x\n",
        "\n",
        "\n",
        "def ResNet34(include_top=True,\n",
        "             weights='imagenet',\n",
        "             input_tensor=None,\n",
        "             input_shape=None,\n",
        "             pooling=None,\n",
        "             classes=1000,\n",
        "             **kwargs):\n",
        "  \n",
        "   \n",
        "\n",
        "    if not (weights in {'imagenet', None} or os.path.exists(weights)):\n",
        "        raise ValueError('The `weights` argument should be either '\n",
        "                         '`None` (random initialization), `imagenet` '\n",
        "                         '(pre-training on ImageNet), '\n",
        "                         'or the path to the weights file to be loaded.')\n",
        "\n",
        "    if weights == 'imagenet' and include_top and classes != 1000:\n",
        "        raise ValueError('If using `weights` as `\"imagenet\"` with `include_top`'\n",
        "                         ' as true, `classes` should be 1000')\n",
        "\n",
        "    # Determine proper input shape\n",
        "    input_shape = _obtain_input_shape(input_shape,\n",
        "                                      default_size=224,\n",
        "                                      min_size=34,\n",
        "                                      data_format=tf.keras.backend.image_data_format(),\n",
        "                                      require_flatten=include_top,\n",
        "                                      weights=weights)\n",
        "    print(input_shape)\n",
        "    if input_tensor is None:\n",
        "        img_input = layers.Input(shape=input_shape)\n",
        "    else:\n",
        "        if not backend.is_keras_tensor(input_tensor):\n",
        "            img_input = layers.Input(tensor=input_tensor, shape=input_shape)\n",
        "        else:\n",
        "            img_input = input_tensor\n",
        "    if tf.keras.backend.image_data_format() == 'channels_last':\n",
        "        bn_axis = 3\n",
        "    else:\n",
        "        bn_axis = 1\n",
        "    \n",
        "    x = layers.ZeroPadding2D(padding=(3, 3), name='conv1_pad')(img_input)\n",
        "    x = layers.Conv2D(64, (7, 7),\n",
        "                      strides=(2, 2),\n",
        "                      padding='valid',\n",
        "                      kernel_initializer='he_normal',\n",
        "                      name='conv1')(x)\n",
        "    x = layers.BatchNormalization(axis=3, name='bn_conv1')(x)\n",
        "    x = layers.Activation('relu')(x)\n",
        "    x = layers.ZeroPadding2D(padding=(1, 1), name='pool1_pad')(x)\n",
        "    x = layers.MaxPooling2D((3, 3), strides=(2, 2))(x)\n",
        "\n",
        "    \n",
        "    x = conv_block(x, 3, [64, 64], stage=2, block='a', strides=(1, 1))\n",
        "    print(backend.int_shape(x))\n",
        "    x = identity_block(x, 3, [64, 64], stage=2, block='b')\n",
        "  \n",
        "    x = identity_block(x, 3, [64, 64], stage=2, block='c')\n",
        "   \n",
        "    x = conv_block(x, 3, [128, 128], stage=3, block='a')\n",
        "    x = identity_block(x, 3, [128, 128], stage=3, block='b')\n",
        "    x = identity_block(x, 3, [128, 128], stage=3, block='c')\n",
        "    x = identity_block(x, 3, [128, 128], stage=3, block='d')\n",
        "   \n",
        "    x = conv_block(x, 3, [256, 256], stage=4, block='a')\n",
        "    x = identity_block(x, 3, [256, 256], stage=4, block='b')\n",
        "    x = identity_block(x, 3, [256, 256], stage=4, block='c')\n",
        "    x = identity_block(x, 3, [256, 256], stage=4, block='d')\n",
        "    x = identity_block(x, 3, [256, 256], stage=4, block='e')\n",
        "    x = identity_block(x, 3, [256, 256], stage=4, block='f')\n",
        "\n",
        "    x = conv_block(x, 3, [512, 512], stage=5, block='a')\n",
        "    x = identity_block(x, 3, [512, 512], stage=5, block='b')\n",
        "    x = identity_block(x, 3, [512, 512], stage=5, block='c')\n",
        "\n",
        "    if include_top:\n",
        "        x = layers.GlobalAveragePooling2D(name='avg_pool')(x)\n",
        "        x = layers.Dense(classes, activation='softmax', name='fc1000')(x)\n",
        "    else:\n",
        "        if pooling == 'avg':\n",
        "            x = layers.GlobalAveragePooling2D()(x)\n",
        "        elif pooling == 'max':\n",
        "            x = layers.GlobalMaxPooling2D()(x)\n",
        "        else:\n",
        "            warnings.warn('The output shape of `ResNet50(include_top=False)` '\n",
        "                          'has been changed since Keras 2.2.0.')\n",
        "    \n",
        "    # Ensure that the model takes into account\n",
        "    # any potential predecessors of `input_tensor`.\n",
        "    if input_tensor is not None:\n",
        "        inputs = keras_utils.get_source_inputs(input_tensor)\n",
        "    else:\n",
        "        inputs = img_input\n",
        "    # Create model.\n",
        "    model = models.Model(inputs, x, name='resnet50')\n",
        "   \n",
        "    # Load weights.\n",
        "    if weights == 'imagenet':\n",
        "        if include_top:\n",
        "            weights_path = keras_utils.get_file(\n",
        "                'resnet50_weights_tf_dim_ordering_tf_kernels.h5',\n",
        "                WEIGHTS_PATH,\n",
        "                cache_subdir='models',\n",
        "                md5_hash='a7b3fe01876f51b976af0dea6bc144eb')\n",
        "        else:\n",
        "            weights_path = keras_utils.get_file(\n",
        "                'resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5',\n",
        "                WEIGHTS_PATH_NO_TOP,\n",
        "                cache_subdir='models',\n",
        "                md5_hash='a268eb855778b3df3c7506639542a6af')\n",
        "        model.load_weights(weights_path)\n",
        "        if backend.backend() == 'theano':\n",
        "            keras_utils.convert_all_kernels_in_model(model)\n",
        "    elif weights is not None:\n",
        "        model.load_weights(weights)\n",
        "\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z8oWYTEYt7OG",
        "colab_type": "code",
        "outputId": "b1da04cb-c22a-4251-ba99-30a6758f28dd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        }
      },
      "source": [
        "from keras_applications.imagenet_utils import _obtain_input_shape\n",
        "from keras.applications.inception_v3 import preprocess_input\n",
        "from keras_applications.imagenet_utils import decode_predictions\n",
        "img_height,img_width = 224,224\n",
        "num_classes = 7\n",
        "#If imagenet weights are being loaded, \n",
        "#input must have a static square shape (one of (128, 128), (160, 160), (192, 192), or (224, 224))\n",
        "base_model=ResNet34(weights= None, include_top=False, input_shape= (img_height,img_width,3))\n",
        "#base_model = applications.keras_applications.resnet_common.block1"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(224, 224, 3)\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "(None, 54, 54, 64)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:217: UserWarning: The output shape of `ResNet50(include_top=False)` has been changed since Keras 2.2.0.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uWkwdlott8R5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dropout(0.3)(x)\n",
        "predictions = Dense(num_classes, activation= 'softmax')(x)\n",
        "model = Model(inputs = base_model.input, outputs = predictions)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bl3Byzu-t8ki",
        "colab_type": "code",
        "outputId": "704aed70-6188-4268-bfdc-c6d31e54f103",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "img_width, img_height = 224, 224\n",
        "train_data_dir =( \"/content/drive/My Drive/Skin_cancer_all/skin_cancer\")\n",
        "\n",
        "\n",
        "train_datagen = ImageDataGenerator(rescale=1./255,\n",
        "    validation_split=0.1) # set validation split\n",
        "train_datagen1 = ImageDataGenerator(rescale=1./255)\n",
        "test_generator = train_datagen1.flow_from_directory(\n",
        "    train_data_dir,\n",
        "    target_size=(img_width, img_height),\n",
        "    batch_size=32,  \n",
        "    \n",
        "    class_mode=\"sparse\") # set as training data\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_data_dir,\n",
        "    target_size=(img_width, img_height),\n",
        "    batch_size=32,  \n",
        "   \n",
        "    class_mode=\"sparse\",\n",
        "    subset='training') # set as training data\n",
        "\n",
        "validation_generator = train_datagen.flow_from_directory(\n",
        "    train_data_dir, # same directory as training data\n",
        "    target_size=(img_width, img_height),\n",
        "    batch_size=32,\n",
        "     \n",
        "      class_mode=\"sparse\",\n",
        "    subset='validation') # set as validation data"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Found 10015 images belonging to 7 classes.\n",
            "Found 9017 images belonging to 7 classes.\n",
            "Found 998 images belonging to 7 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f4Iry0ZyaDHD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.load_weights(\"/content/drive/My Drive/Colab Notebooks/skin_cancer_all_model_resnet34_weights_26_epoch_edited_batch_size_32_val_loss_better_val_acc_72_acc_96.h5\")\n",
        "#skin_cancer_all_model_resnet34_weights_26_epoch_edited_batch_size_32_val_loss_better_val_acc_72_acc_96"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UQrlOaHkasNq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "c2ace1f6-c3d2-42bd-e05c-123abf9607c6"
      },
      "source": [
        "\n",
        "acc = model.evaluate_generator(train_generator, steps=2, verbose=1)\n",
        "print(acc)"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2/2 [==============================] - 1s 272ms/step - loss: 21.9589 - acc: 0.0000e+00\n",
            "[21.958894729614258, 0.0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gxJ_f4y_t8yI",
        "colab_type": "code",
        "outputId": "589efff9-6b7e-4a07-9602-57c38462c420",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 537
        }
      },
      "source": [
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.optimizers import adam\n",
        "nb_epochs = 10\n",
        "nb_train_samples = 282\n",
        "nb_validation_samples = 32\n",
        "\n",
        "model.compile(loss='sparse_categorical_crossentropy',\n",
        "     optimizer='rmsprop',      \n",
        "              metrics=['accuracy'])\n",
        "    # but it used to start model.\n",
        "\n",
        "\n",
        "history=model.fit_generator(train_generator,\n",
        "                    steps_per_epoch=nb_train_samples,\n",
        "                    epochs=nb_epochs\n",
        "                        , validation_data=validation_generator\n",
        "                        , validation_steps=nb_validation_samples)\n",
        "\n"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "281/282 [============================>.] - ETA: 0s - loss: 0.7300 - acc: 0.7432Epoch 1/10\n",
            "282/282 [==============================] - 135s 477ms/step - loss: 0.7289 - acc: 0.7436 - val_loss: 1.0437 - val_acc: 0.6563\n",
            "Epoch 2/10\n",
            "281/282 [============================>.] - ETA: 0s - loss: 0.4560 - acc: 0.8472Epoch 1/10\n",
            "282/282 [==============================] - 119s 423ms/step - loss: 0.4569 - acc: 0.8468 - val_loss: 0.9798 - val_acc: 0.7395\n",
            "Epoch 3/10\n",
            "281/282 [============================>.] - ETA: 0s - loss: 0.3703 - acc: 0.8881Epoch 1/10\n",
            "282/282 [==============================] - 119s 424ms/step - loss: 0.3696 - acc: 0.8884 - val_loss: 1.1495 - val_acc: 0.7525\n",
            "Epoch 4/10\n",
            "281/282 [============================>.] - ETA: 0s - loss: 0.2764 - acc: 0.9073Epoch 1/10\n",
            "282/282 [==============================] - 119s 423ms/step - loss: 0.2760 - acc: 0.9075 - val_loss: 1.0616 - val_acc: 0.7445\n",
            "Epoch 5/10\n",
            "281/282 [============================>.] - ETA: 0s - loss: 0.2800 - acc: 0.9188Epoch 1/10\n",
            "282/282 [==============================] - 120s 425ms/step - loss: 0.2798 - acc: 0.9188 - val_loss: 1.1473 - val_acc: 0.7315\n",
            "Epoch 6/10\n",
            "281/282 [============================>.] - ETA: 0s - loss: 0.2125 - acc: 0.9352Epoch 1/10\n",
            "282/282 [==============================] - 120s 424ms/step - loss: 0.2122 - acc: 0.9353 - val_loss: 1.6867 - val_acc: 0.7365\n",
            "Epoch 7/10\n",
            "281/282 [============================>.] - ETA: 0s - loss: 0.1992 - acc: 0.9408Epoch 1/10\n",
            "282/282 [==============================] - 120s 424ms/step - loss: 0.1987 - acc: 0.9409 - val_loss: 1.4381 - val_acc: 0.7244\n",
            "Epoch 8/10\n",
            "281/282 [============================>.] - ETA: 0s - loss: 0.1636 - acc: 0.9497Epoch 1/10\n",
            "282/282 [==============================] - 120s 425ms/step - loss: 0.1633 - acc: 0.9498 - val_loss: 1.8554 - val_acc: 0.7094\n",
            "Epoch 9/10\n",
            "281/282 [============================>.] - ETA: 0s - loss: 0.1655 - acc: 0.9537Epoch 1/10\n",
            "282/282 [==============================] - 119s 424ms/step - loss: 0.1651 - acc: 0.9538 - val_loss: 1.8867 - val_acc: 0.7415\n",
            "Epoch 10/10\n",
            "281/282 [============================>.] - ETA: 0s - loss: 0.1394 - acc: 0.9557Epoch 1/10\n",
            "282/282 [==============================] - 120s 424ms/step - loss: 0.1395 - acc: 0.9556 - val_loss: 1.6470 - val_acc: 0.7605\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZEzeKkgIxQoH",
        "colab_type": "code",
        "outputId": "3b94befa-a9f4-4311-9c57-46eca0bcaf7c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        }
      },
      "source": [
        "print(history.history)\n",
        "\n",
        "acc = model.evaluate_generator(validation_generator, steps=2, verbose=1)\n",
        "print(acc)"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'loss': [0.7290316781078062, 0.45691766834872466, 0.3694730017975004, 0.2758866420861185, 0.2799995188428106, 0.2123241148152848, 0.19877684715582894, 0.16320782035400827, 0.16518887682957623, 0.13958478639135938], 'acc': [0.7435954, 0.84684485, 0.888433, 0.907508, 0.91882, 0.93534434, 0.9408894, 0.94976157, 0.953754, 0.95563936], 'val_loss': [1.04366285353899, 0.9797699134796858, 1.1495070699602365, 1.0616078115999699, 1.1472830474376678, 1.6866516638547182, 1.4380706353113055, 1.855421232059598, 1.8866893332451582, 1.647033809684217], 'val_acc': [0.65631264, 0.73947895, 0.752505, 0.74448895, 0.73146296, 0.73647296, 0.7244489, 0.70941883, 0.741483, 0.76052105]}\n",
            "2/2 [==============================] - 1s 321ms/step - loss: 1.8911 - acc: 0.7188\n",
            "[1.8911299109458923, 0.71875]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AlkrJaUJxWgA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save_weights( 'skin_cancer_all_model_resnet34_weights_acc_95_val_acc_76.h5')\n",
        "model.save('skin_cancer_all_model_structure_resnet34_acc_95_val_acc_76.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H0od9TBWE1fZ",
        "colab_type": "code",
        "outputId": "c2b39523-3f54-400a-8240-cd1efd35022f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "nb_epochs = 1\n",
        "nb_train_samples = 282\n",
        "nb_validation_samples = 32\n",
        "history=model.fit_generator(train_generator,\n",
        "                    steps_per_epoch=nb_train_samples,\n",
        "                    epochs=nb_epochs\n",
        "                        , validation_data=validation_generator\n",
        "                        , validation_steps=nb_validation_samples)"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "282/282 [==============================] - 120s 425ms/step - loss: 0.1122 - acc: 0.9806 - val_loss: 2.6200 - val_acc: 0.7495\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vnj1e-_cx049",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save_weights('skin_cancer_all_model_resnet34_weights_26_epoch_edited_batch_size_32_val_loss_better_val_acc_74_acc_98_val_loss_2.6.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JvEe9eZ54Kkh",
        "colab_type": "code",
        "outputId": "da2d64cb-19b8-4fcc-c88e-d15973821832",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "print(history.history)\n",
        "model.summary()"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'loss': [2.817171125787215, 1.4259222610634552, 1.072560700398037, 0.8403421549589463, 0.8251934163813335, 0.6488625191631847, 0.6325585156055137, 0.6577039843444716, 0.5559635928219977, 0.7734540214851147], 'acc': [0.686592, 0.72485304, 0.7547965, 0.7615615, 0.7821892, 0.81213266, 0.8183431, 0.8329821, 0.8399689, 0.8537207], 'val_loss': [1.3058596444316208, 5.411523418704746, 7.667882208988885, 12.239189090527361, 4.936793148430297, 5.427366109273862, 6.413986823445157, 4.095213151973439, 4.758233310349169, 4.377757560023383], 'val_acc': [0.6723447, 0.6713427, 0.6713427, 0.6713427, 0.6713427, 0.67034066, 0.6713427, 0.6713427, 0.6713427, 0.6713427]}\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv1_pad (ZeroPadding2D)       (None, 230, 230, 3)  0           input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1 (Conv2D)                  (None, 112, 112, 64) 9472        conv1_pad[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "bn_conv1 (BatchNormalization)   (None, 112, 112, 64) 256         conv1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 112, 112, 64) 0           bn_conv1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "pool1_pad (ZeroPadding2D)       (None, 114, 114, 64) 0           activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D)    (None, 56, 56, 64)   0           pool1_pad[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2a (Conv2D)         (None, 54, 54, 64)   36928       max_pooling2d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2a (BatchNormalizati (None, 54, 54, 64)   256         res2a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 54, 54, 64)   0           bn2a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2b (Conv2D)         (None, 54, 54, 64)   36928       activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch1 (Conv2D)          (None, 54, 54, 64)   36928       max_pooling2d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2b (BatchNormalizati (None, 54, 54, 64)   256         res2a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch1 (BatchNormalizatio (None, 54, 54, 64)   256         res2a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add (Add)                       (None, 54, 54, 64)   0           bn2a_branch2b[0][0]              \n",
            "                                                                 bn2a_branch1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 54, 54, 64)   0           add[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2a (Conv2D)         (None, 54, 54, 64)   4160        activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2a (BatchNormalizati (None, 54, 54, 64)   256         res2b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 54, 54, 64)   0           bn2b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2b (Conv2D)         (None, 54, 54, 64)   36928       activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2b (BatchNormalizati (None, 54, 54, 64)   256         res2b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_1 (Add)                     (None, 54, 54, 64)   0           bn2b_branch2b[0][0]              \n",
            "                                                                 activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 54, 54, 64)   0           add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2a (Conv2D)         (None, 54, 54, 64)   4160        activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2a (BatchNormalizati (None, 54, 54, 64)   256         res2c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 54, 54, 64)   0           bn2c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2b (Conv2D)         (None, 54, 54, 64)   36928       activation_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2b (BatchNormalizati (None, 54, 54, 64)   256         res2c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_2 (Add)                     (None, 54, 54, 64)   0           bn2c_branch2b[0][0]              \n",
            "                                                                 activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 54, 54, 64)   0           add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2a (Conv2D)         (None, 26, 26, 128)  73856       activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2a (BatchNormalizati (None, 26, 26, 128)  512         res3a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 26, 26, 128)  0           bn3a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2b (Conv2D)         (None, 26, 26, 128)  147584      activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch1 (Conv2D)          (None, 26, 26, 128)  73856       activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2b (BatchNormalizati (None, 26, 26, 128)  512         res3a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch1 (BatchNormalizatio (None, 26, 26, 128)  512         res3a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_3 (Add)                     (None, 26, 26, 128)  0           bn3a_branch2b[0][0]              \n",
            "                                                                 bn3a_branch1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 26, 26, 128)  0           add_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2a (Conv2D)         (None, 26, 26, 128)  16512       activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2a (BatchNormalizati (None, 26, 26, 128)  512         res3b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 26, 26, 128)  0           bn3b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2b (Conv2D)         (None, 26, 26, 128)  147584      activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2b (BatchNormalizati (None, 26, 26, 128)  512         res3b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_4 (Add)                     (None, 26, 26, 128)  0           bn3b_branch2b[0][0]              \n",
            "                                                                 activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 26, 26, 128)  0           add_4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2a (Conv2D)         (None, 26, 26, 128)  16512       activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2a (BatchNormalizati (None, 26, 26, 128)  512         res3c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 26, 26, 128)  0           bn3c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2b (Conv2D)         (None, 26, 26, 128)  147584      activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2b (BatchNormalizati (None, 26, 26, 128)  512         res3c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_5 (Add)                     (None, 26, 26, 128)  0           bn3c_branch2b[0][0]              \n",
            "                                                                 activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 26, 26, 128)  0           add_5[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2a (Conv2D)         (None, 26, 26, 128)  16512       activation_12[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2a (BatchNormalizati (None, 26, 26, 128)  512         res3d_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 26, 26, 128)  0           bn3d_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2b (Conv2D)         (None, 26, 26, 128)  147584      activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2b (BatchNormalizati (None, 26, 26, 128)  512         res3d_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_6 (Add)                     (None, 26, 26, 128)  0           bn3d_branch2b[0][0]              \n",
            "                                                                 activation_12[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 26, 26, 128)  0           add_6[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2a (Conv2D)         (None, 12, 12, 256)  295168      activation_14[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2a (BatchNormalizati (None, 12, 12, 256)  1024        res4a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 12, 12, 256)  0           bn4a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2b (Conv2D)         (None, 12, 12, 256)  590080      activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch1 (Conv2D)          (None, 12, 12, 256)  295168      activation_14[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2b (BatchNormalizati (None, 12, 12, 256)  1024        res4a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch1 (BatchNormalizatio (None, 12, 12, 256)  1024        res4a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_7 (Add)                     (None, 12, 12, 256)  0           bn4a_branch2b[0][0]              \n",
            "                                                                 bn4a_branch1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 12, 12, 256)  0           add_7[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2a (Conv2D)         (None, 12, 12, 256)  65792       activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2a (BatchNormalizati (None, 12, 12, 256)  1024        res4b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 12, 12, 256)  0           bn4b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2b (Conv2D)         (None, 12, 12, 256)  590080      activation_17[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2b (BatchNormalizati (None, 12, 12, 256)  1024        res4b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_8 (Add)                     (None, 12, 12, 256)  0           bn4b_branch2b[0][0]              \n",
            "                                                                 activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 12, 12, 256)  0           add_8[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2a (Conv2D)         (None, 12, 12, 256)  65792       activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2a (BatchNormalizati (None, 12, 12, 256)  1024        res4c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 12, 12, 256)  0           bn4c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2b (Conv2D)         (None, 12, 12, 256)  590080      activation_19[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2b (BatchNormalizati (None, 12, 12, 256)  1024        res4c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_9 (Add)                     (None, 12, 12, 256)  0           bn4c_branch2b[0][0]              \n",
            "                                                                 activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 12, 12, 256)  0           add_9[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2a (Conv2D)         (None, 12, 12, 256)  65792       activation_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2a (BatchNormalizati (None, 12, 12, 256)  1024        res4d_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 12, 12, 256)  0           bn4d_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2b (Conv2D)         (None, 12, 12, 256)  590080      activation_21[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2b (BatchNormalizati (None, 12, 12, 256)  1024        res4d_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_10 (Add)                    (None, 12, 12, 256)  0           bn4d_branch2b[0][0]              \n",
            "                                                                 activation_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, 12, 12, 256)  0           add_10[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2a (Conv2D)         (None, 12, 12, 256)  65792       activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2a (BatchNormalizati (None, 12, 12, 256)  1024        res4e_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, 12, 12, 256)  0           bn4e_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2b (Conv2D)         (None, 12, 12, 256)  590080      activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2b (BatchNormalizati (None, 12, 12, 256)  1024        res4e_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_11 (Add)                    (None, 12, 12, 256)  0           bn4e_branch2b[0][0]              \n",
            "                                                                 activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, 12, 12, 256)  0           add_11[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2a (Conv2D)         (None, 12, 12, 256)  65792       activation_24[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2a (BatchNormalizati (None, 12, 12, 256)  1024        res4f_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_25 (Activation)      (None, 12, 12, 256)  0           bn4f_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2b (Conv2D)         (None, 12, 12, 256)  590080      activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2b (BatchNormalizati (None, 12, 12, 256)  1024        res4f_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_12 (Add)                    (None, 12, 12, 256)  0           bn4f_branch2b[0][0]              \n",
            "                                                                 activation_24[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_26 (Activation)      (None, 12, 12, 256)  0           add_12[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2a (Conv2D)         (None, 5, 5, 512)    1180160     activation_26[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2a (BatchNormalizati (None, 5, 5, 512)    2048        res5a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_27 (Activation)      (None, 5, 5, 512)    0           bn5a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2b (Conv2D)         (None, 5, 5, 512)    2359808     activation_27[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch1 (Conv2D)          (None, 5, 5, 512)    1180160     activation_26[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2b (BatchNormalizati (None, 5, 5, 512)    2048        res5a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch1 (BatchNormalizatio (None, 5, 5, 512)    2048        res5a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_13 (Add)                    (None, 5, 5, 512)    0           bn5a_branch2b[0][0]              \n",
            "                                                                 bn5a_branch1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_28 (Activation)      (None, 5, 5, 512)    0           add_13[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2a (Conv2D)         (None, 5, 5, 512)    262656      activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2a (BatchNormalizati (None, 5, 5, 512)    2048        res5b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_29 (Activation)      (None, 5, 5, 512)    0           bn5b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2b (Conv2D)         (None, 5, 5, 512)    2359808     activation_29[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2b (BatchNormalizati (None, 5, 5, 512)    2048        res5b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_14 (Add)                    (None, 5, 5, 512)    0           bn5b_branch2b[0][0]              \n",
            "                                                                 activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_30 (Activation)      (None, 5, 5, 512)    0           add_14[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2a (Conv2D)         (None, 5, 5, 512)    262656      activation_30[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2a (BatchNormalizati (None, 5, 5, 512)    2048        res5c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_31 (Activation)      (None, 5, 5, 512)    0           bn5c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2b (Conv2D)         (None, 5, 5, 512)    2359808     activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2b (BatchNormalizati (None, 5, 5, 512)    2048        res5c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_15 (Add)                    (None, 5, 5, 512)    0           bn5c_branch2b[0][0]              \n",
            "                                                                 activation_30[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_32 (Activation)      (None, 5, 5, 512)    0           add_15[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling2d (Globa (None, 512)          0           activation_32[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 512)          0           global_average_pooling2d[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 7)            3591        dropout[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 15,452,743\n",
            "Trainable params: 15,435,591\n",
            "Non-trainable params: 17,152\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}