{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "skin_cancer_test_resnet.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MohmedAAK/skin_cancer/blob/master/skin_cancer_test_resnet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nhDSyO2FZG2o",
        "colab_type": "code",
        "outputId": "d91826e1-6459-4d11-a1f5-5bf7e248f3e4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        }
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np \n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "from urllib.request import urlopen,urlretrieve\n",
        "from PIL import Image\n",
        "from tqdm import tqdm_notebook\n",
        "from sklearn.utils import shuffle\n",
        "import cv2\n",
        "\n",
        "from  tensorflow.keras.models import load_model\n",
        "from sklearn.datasets import load_files   \n",
        "from  keras.utils import np_utils\n",
        "from glob import glob\n",
        "from  tensorflow.keras import applications\n",
        "from  tensorflow.keras.preprocessing.image import ImageDataGenerator \n",
        "from  tensorflow.keras import optimizers\n",
        "from  tensorflow.keras.models import Sequential,Model,load_model\n",
        "from  tensorflow.keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D,GlobalAveragePooling2D\n",
        "from  tensorflow.keras.callbacks import TensorBoard,ReduceLROnPlateau,ModelCheckpoint"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BUhTgbWuS7jt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "import tensorflow.keras.backend as backend\n",
        "import tensorflow.keras.layers as layers\n",
        "import tensorflow.keras.models as models\n",
        "import tensorflow.keras.utils as utils\n",
        "\n",
        "_KERAS_BACKEND = None\n",
        "_KERAS_LAYERS = None\n",
        "_KERAS_MODELS = None\n",
        "_KERAS_UTILS = None\n",
        "\n",
        "\n",
        "def get_submodules_from_kwargs(kwargs):\n",
        "    #backend = kwargs.get('backend', _KERAS_BACKEND)\n",
        "    #layers = kwargs.get('layers', _KERAS_LAYERS)\n",
        "    #models = kwargs.get('models', _KERAS_MODELS)\n",
        "    #utils = kwargs.get('utils', _KERAS_UTILS)\n",
        "    #for key in kwargs.keys():\n",
        "     #   if key not in ['backend', 'layers', 'models', 'utils']:\n",
        "      #      raise TypeError('Invalid keyword argument: %s', key)\n",
        "    return backend, layers, models, utils\n",
        "\n",
        "\n",
        "def correct_pad(backend, inputs, kernel_size):\n",
        "    \"\"\"Returns a tuple for zero-padding for 2D convolution with downsampling.\n",
        "    # Arguments\n",
        "        input_size: An integer or tuple/list of 2 integers.\n",
        "        kernel_size: An integer or tuple/list of 2 integers.\n",
        "    # Returns\n",
        "        A tuple.\n",
        "    \"\"\"\n",
        "    img_dim = 2 if backend.image_data_format() == 'channels_first' else 1\n",
        "    input_size = backend.int_shape(inputs)[img_dim:(img_dim + 2)]\n",
        "\n",
        "    if isinstance(kernel_size, int):\n",
        "        kernel_size = (kernel_size, kernel_size)\n",
        "\n",
        "    if input_size[0] is None:\n",
        "        adjust = (1, 1)\n",
        "    else:\n",
        "        adjust = (1 - input_size[0] % 2, 1 - input_size[1] % 2)\n",
        "\n",
        "    correct = (kernel_size[0] // 2, kernel_size[1] // 2)\n",
        "\n",
        "    return ((correct[0] - adjust[0], correct[0]),\n",
        "            (correct[1] - adjust[1], correct[1]))\n",
        "\n",
        "__version__ = '1.0.8'\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zF_uNzemTahi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "import tensorflow as tf\n",
        "import json\n",
        "import warnings\n",
        "import numpy as np\n",
        "import tensorflow.keras.backend as backend\n",
        "import tensorflow.keras.layers as layers\n",
        "import tensorflow.keras.models as models\n",
        "import tensorflow.keras.utils as utils\n",
        "from . import get_submodules_from_kwargs\n",
        "\n",
        "CLASS_INDEX = None\n",
        "CLASS_INDEX_PATH = ('https://storage.googleapis.com/download.tensorflow.org/'\n",
        "                    'data/imagenet_class_index.json')\n",
        "\n",
        "\n",
        "def _preprocess_numpy_input(x, data_format, mode, **kwargs):\n",
        "    \"\"\"Preprocesses a Numpy array encoding a batch of images.\n",
        "    # Arguments\n",
        "        x: Input array, 3D or 4D.\n",
        "        data_format: Data format of the image array.\n",
        "        mode: One of \"caffe\", \"tf\" or \"torch\".\n",
        "            - caffe: will convert the images from RGB to BGR,\n",
        "                then will zero-center each color channel with\n",
        "                respect to the ImageNet dataset,\n",
        "                without scaling.\n",
        "            - tf: will scale pixels between -1 and 1,\n",
        "                sample-wise.\n",
        "            - torch: will scale pixels between 0 and 1 and then\n",
        "                will normalize each channel with respect to the\n",
        "                ImageNet dataset.\n",
        "    # Returns\n",
        "        Preprocessed Numpy array.\n",
        "    \"\"\"\n",
        "  \n",
        "    if not issubclass(x.dtype.type, np.floating):\n",
        "        x = x.astype(backend.floatx(), copy=False)\n",
        "\n",
        "    if mode == 'tf':\n",
        "        x /= 127.5\n",
        "        x -= 1.\n",
        "        return x\n",
        "\n",
        "    if mode == 'torch':\n",
        "        x /= 255.\n",
        "        mean = [0.485, 0.456, 0.406]\n",
        "        std = [0.229, 0.224, 0.225]\n",
        "    else:\n",
        "        if data_format == 'channels_first':\n",
        "            # 'RGB'->'BGR'\n",
        "            if x.ndim == 3:\n",
        "                x = x[::-1, ...]\n",
        "            else:\n",
        "                x = x[:, ::-1, ...]\n",
        "        else:\n",
        "            # 'RGB'->'BGR'\n",
        "            x = x[..., ::-1]\n",
        "        mean = [103.939, 116.779, 123.68]\n",
        "        std = None\n",
        "\n",
        "    # Zero-center by mean pixel\n",
        "    if data_format == 'channels_first':\n",
        "        if x.ndim == 3:\n",
        "            x[0, :, :] -= mean[0]\n",
        "            x[1, :, :] -= mean[1]\n",
        "            x[2, :, :] -= mean[2]\n",
        "            if std is not None:\n",
        "                x[0, :, :] /= std[0]\n",
        "                x[1, :, :] /= std[1]\n",
        "                x[2, :, :] /= std[2]\n",
        "        else:\n",
        "            x[:, 0, :, :] -= mean[0]\n",
        "            x[:, 1, :, :] -= mean[1]\n",
        "            x[:, 2, :, :] -= mean[2]\n",
        "            if std is not None:\n",
        "                x[:, 0, :, :] /= std[0]\n",
        "                x[:, 1, :, :] /= std[1]\n",
        "                x[:, 2, :, :] /= std[2]\n",
        "    else:\n",
        "        x[..., 0] -= mean[0]\n",
        "        x[..., 1] -= mean[1]\n",
        "        x[..., 2] -= mean[2]\n",
        "        if std is not None:\n",
        "            x[..., 0] /= std[0]\n",
        "            x[..., 1] /= std[1]\n",
        "            x[..., 2] /= std[2]\n",
        "    return x\n",
        "\n",
        "\n",
        "def _preprocess_symbolic_input(x, data_format, mode, **kwargs):\n",
        "    \"\"\"Preprocesses a tensor encoding a batch of images.\n",
        "    # Arguments\n",
        "        x: Input tensor, 3D or 4D.\n",
        "        data_format: Data format of the image tensor.\n",
        "        mode: One of \"caffe\", \"tf\" or \"torch\".\n",
        "            - caffe: will convert the images from RGB to BGR,\n",
        "                then will zero-center each color channel with\n",
        "                respect to the ImageNet dataset,\n",
        "                without scaling.\n",
        "            - tf: will scale pixels between -1 and 1,\n",
        "                sample-wise.\n",
        "            - torch: will scale pixels between 0 and 1 and then\n",
        "                will normalize each channel with respect to the\n",
        "                ImageNet dataset.\n",
        "    # Returns\n",
        "        Preprocessed tensor.\n",
        "    \"\"\"\n",
        "\n",
        "\n",
        "    if mode == 'tf':\n",
        "        x /= 127.5\n",
        "        x -= 1.\n",
        "        return x\n",
        "\n",
        "    if mode == 'torch':\n",
        "        x /= 255.\n",
        "        mean = [0.485, 0.456, 0.406]\n",
        "        std = [0.229, 0.224, 0.225]\n",
        "    else:\n",
        "        if data_format == 'channels_first':\n",
        "            # 'RGB'->'BGR'\n",
        "            if backend.ndim(x) == 3:\n",
        "                x = x[::-1, ...]\n",
        "            else:\n",
        "                x = x[:, ::-1, ...]\n",
        "        else:\n",
        "            # 'RGB'->'BGR'\n",
        "            x = x[..., ::-1]\n",
        "        mean = [103.939, 116.779, 123.68]\n",
        "        std = None\n",
        "\n",
        "    mean_tensor = backend.constant(-np.array(mean))\n",
        "\n",
        "    # Zero-center by mean pixel\n",
        "    if backend.dtype(x) != backend.dtype(mean_tensor):\n",
        "        x = backend.bias_add(\n",
        "            x, backend.cast(mean_tensor, backend.dtype(x)),\n",
        "            data_format=data_format)\n",
        "    else:\n",
        "        x = backend.bias_add(x, mean_tensor, data_format)\n",
        "    if std is not None:\n",
        "        x /= std\n",
        "    return x\n",
        "\n",
        "\n",
        "def preprocess_input(x, data_format=None, mode='caffe', **kwargs):\n",
        "    \"\"\"Preprocesses a tensor or Numpy array encoding a batch of images.\n",
        "    # Arguments\n",
        "        x: Input Numpy or symbolic tensor, 3D or 4D.\n",
        "            The preprocessed data is written over the input data\n",
        "            if the data types are compatible. To avoid this\n",
        "            behaviour, `numpy.copy(x)` can be used.\n",
        "        data_format: Data format of the image tensor/array.\n",
        "        mode: One of \"caffe\", \"tf\" or \"torch\".\n",
        "            - caffe: will convert the images from RGB to BGR,\n",
        "                then will zero-center each color channel with\n",
        "                respect to the ImageNet dataset,\n",
        "                without scaling.\n",
        "            - tf: will scale pixels between -1 and 1,\n",
        "                sample-wise.\n",
        "            - torch: will scale pixels between 0 and 1 and then\n",
        "                will normalize each channel with respect to the\n",
        "                ImageNet dataset.\n",
        "    # Returns\n",
        "        Preprocessed tensor or Numpy array.\n",
        "    # Raises\n",
        "        ValueError: In case of unknown `data_format` argument.\n",
        "    \"\"\"\n",
        "    \n",
        "\n",
        "    if data_format is None:\n",
        "        data_format = backend.image_data_format()\n",
        "    if data_format not in {'channels_first', 'channels_last'}:\n",
        "        raise ValueError('Unknown data_format ' + str(data_format))\n",
        "\n",
        "    if isinstance(x, np.ndarray):\n",
        "        return _preprocess_numpy_input(x, data_format=data_format,\n",
        "                                       mode=mode, **kwargs)\n",
        "    else:\n",
        "        return _preprocess_symbolic_input(x, data_format=data_format,\n",
        "                                          mode=mode, **kwargs)\n",
        "\n",
        "\n",
        "def decode_predictions(preds, top=5, **kwargs):\n",
        "    \"\"\"Decodes the prediction of an ImageNet model.\n",
        "    # Arguments\n",
        "        preds: Numpy tensor encoding a batch of predictions.\n",
        "        top: Integer, how many top-guesses to return.\n",
        "    # Returns\n",
        "        A list of lists of top class prediction tuples\n",
        "        `(class_name, class_description, score)`.\n",
        "        One list of tuples per sample in batch input.\n",
        "    # Raises\n",
        "        ValueError: In case of invalid shape of the `pred` array\n",
        "            (must be 2D).\n",
        "    \"\"\"\n",
        "    global CLASS_INDEX\n",
        "\n",
        "   \n",
        "\n",
        "    if len(preds.shape) != 2 or preds.shape[1] != 1000:\n",
        "        raise ValueError('`decode_predictions` expects '\n",
        "                         'a batch of predictions '\n",
        "                         '(i.e. a 2D array of shape (samples, 1000)). '\n",
        "                         'Found array with shape: ' + str(preds.shape))\n",
        "    if CLASS_INDEX is None:\n",
        "        fpath = utils.get_file(\n",
        "            'imagenet_class_index.json',\n",
        "            CLASS_INDEX_PATH,\n",
        "            cache_subdir='models',\n",
        "            file_hash='c2c37ea517e94d9795004a39431a14cb')\n",
        "        with open(fpath) as f:\n",
        "            CLASS_INDEX = json.load(f)\n",
        "    results = []\n",
        "    for pred in preds:\n",
        "        top_indices = pred.argsort()[-top:][::-1]\n",
        "        result = [tuple(CLASS_INDEX[str(i)]) + (pred[i],) for i in top_indices]\n",
        "        result.sort(key=lambda x: x[2], reverse=True)\n",
        "        results.append(result)\n",
        "    return results\n",
        "\n",
        "\n",
        "def _obtain_input_shape(input_shape,\n",
        "                        default_size,\n",
        "                        min_size,\n",
        "                        data_format,\n",
        "                        require_flatten,\n",
        "                        weights=None):\n",
        "    \"\"\"Internal utility to compute/validate a model's input shape.\n",
        "    # Arguments\n",
        "        input_shape: Either None (will return the default network input shape),\n",
        "            or a user-provided shape to be validated.\n",
        "        default_size: Default input width/height for the model.\n",
        "        min_size: Minimum input width/height accepted by the model.\n",
        "        data_format: Image data format to use.\n",
        "        require_flatten: Whether the model is expected to\n",
        "            be linked to a classifier via a Flatten layer.\n",
        "        weights: One of `None` (random initialization)\n",
        "            or 'imagenet' (pre-training on ImageNet).\n",
        "            If weights='imagenet' input channels must be equal to 3.\n",
        "    # Returns\n",
        "        An integer shape tuple (may include None entries).\n",
        "    # Raises\n",
        "        ValueError: In case of invalid argument values.\n",
        "    \"\"\"\n",
        "    if weights != 'imagenet' and input_shape and len(input_shape) == 3:\n",
        "        if data_format == 'channels_first':\n",
        "            if input_shape[0] not in {1, 3}:\n",
        "                warnings.warn(\n",
        "                    'This model usually expects 1 or 3 input channels. '\n",
        "                    'However, it was passed an input_shape with ' +\n",
        "                    str(input_shape[0]) + ' input channels.')\n",
        "            default_shape = (input_shape[0], default_size, default_size)\n",
        "        else:\n",
        "            if input_shape[-1] not in {1, 3}:\n",
        "                warnings.warn(\n",
        "                    'This model usually expects 1 or 3 input channels. '\n",
        "                    'However, it was passed an input_shape with ' +\n",
        "                    str(input_shape[-1]) + ' input channels.')\n",
        "            default_shape = (default_size, default_size, input_shape[-1])\n",
        "    else:\n",
        "        if data_format == 'channels_first':\n",
        "            default_shape = (3, default_size, default_size)\n",
        "        else:\n",
        "            default_shape = (default_size, default_size, 3)\n",
        "    if weights == 'imagenet' and require_flatten:\n",
        "        if input_shape is not None:\n",
        "            if input_shape != default_shape:\n",
        "                raise ValueError('When setting `include_top=True` '\n",
        "                                 'and loading `imagenet` weights, '\n",
        "                                 '`input_shape` should be ' +\n",
        "                                 str(default_shape) + '.')\n",
        "        return default_shape\n",
        "    if input_shape:\n",
        "        if data_format == 'channels_first':\n",
        "            if input_shape is not None:\n",
        "                if len(input_shape) != 3:\n",
        "                    raise ValueError(\n",
        "                        '`input_shape` must be a tuple of three integers.')\n",
        "                if input_shape[0] != 3 and weights == 'imagenet':\n",
        "                    raise ValueError('The input must have 3 channels; got '\n",
        "                                     '`input_shape=' + str(input_shape) + '`')\n",
        "                if ((input_shape[1] is not None and input_shape[1] < min_size) or\n",
        "                   (input_shape[2] is not None and input_shape[2] < min_size)):\n",
        "                    raise ValueError('Input size must be at least ' +\n",
        "                                     str(min_size) + 'x' + str(min_size) +\n",
        "                                     '; got `input_shape=' +\n",
        "                                     str(input_shape) + '`')\n",
        "        else:\n",
        "            if input_shape is not None:\n",
        "                if len(input_shape) != 3:\n",
        "                    raise ValueError(\n",
        "                        '`input_shape` must be a tuple of three integers.')\n",
        "                if input_shape[-1] != 3 and weights == 'imagenet':\n",
        "                    raise ValueError('The input must have 3 channels; got '\n",
        "                                     '`input_shape=' + str(input_shape) + '`')\n",
        "                if ((input_shape[0] is not None and input_shape[0] < min_size) or\n",
        "                   (input_shape[1] is not None and input_shape[1] < min_size)):\n",
        "                    raise ValueError('Input size must be at least ' +\n",
        "                                     str(min_size) + 'x' + str(min_size) +\n",
        "                                     '; got `input_shape=' +\n",
        "                                     str(input_shape) + '`')\n",
        "    else:\n",
        "        if require_flatten:\n",
        "            input_shape = default_shape\n",
        "        else:\n",
        "            if data_format == 'channels_first':\n",
        "                input_shape = (3, None, None)\n",
        "            else:\n",
        "                input_shape = (None, None, 3)\n",
        "    if require_flatten:\n",
        "        if None in input_shape:\n",
        "            raise ValueError('If `include_top` is True, '\n",
        "                             'you should specify a static `input_shape`. '\n",
        "                             'Got `input_shape=' + str(input_shape) + '`')\n",
        "    return input_shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_vCLgYXlOHvF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"ResNet50 model for Keras.\n",
        "# Reference:\n",
        "- [Deep Residual Learning for Image Recognition](\n",
        "    https://arxiv.org/abs/1512.03385) (CVPR 2016 Best Paper Award)\n",
        "Adapted from code contributed by BigMoyan.\n",
        "\"\"\"\n",
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "import tensorflow as tf\n",
        "import os\n",
        "import warnings\n",
        "import tensorflow.keras.backend as backend\n",
        "import tensorflow.keras.layers as layers\n",
        "import tensorflow.keras.models as models\n",
        "import tensorflow.keras.utils as utils\n",
        "from . import get_submodules_from_kwargs\n",
        "\n",
        "\n",
        "preprocess_input = preprocess_input\n",
        "\n",
        "WEIGHTS_PATH = ('https://github.com/fchollet/deep-learning-models/'\n",
        "                'releases/download/v0.2/'\n",
        "                'resnet50_weights_tf_dim_ordering_tf_kernels.h5')\n",
        "WEIGHTS_PATH_NO_TOP = ('https://github.com/fchollet/deep-learning-models/'\n",
        "                       'releases/download/v0.2/'\n",
        "                       'resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5')\n",
        "\n",
        "\n",
        "def identity_block(input_tensor, kernel_size, filters, stage, block):\n",
        "    \"\"\"The identity block is the block that has no conv layer at shortcut.\n",
        "    # Arguments\n",
        "        input_tensor: input tensor\n",
        "        kernel_size: default 3, the kernel size of\n",
        "            middle conv layer at main path\n",
        "        filters: list of integers, the filters of 3 conv layer at main path\n",
        "        stage: integer, current stage label, used for generating layer names\n",
        "        block: 'a','b'..., current block label, used for generating layer names\n",
        "    # Returns\n",
        "        Output tensor for the block.\n",
        "    \"\"\"\n",
        "    filters1, filters2, filters3 = filters\n",
        "    if tf.keras.backend.image_data_format() == 'channels_last':\n",
        "        bn_axis = 3\n",
        "    else:\n",
        "        bn_axis = 1\n",
        "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
        "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
        "\n",
        "    x = layers.Conv2D(filters1, (1, 1),\n",
        "                      kernel_initializer='he_normal',\n",
        "                      name=conv_name_base + '2a')(input_tensor)\n",
        "    x = layers.BatchNormalization(axis=bn_axis, name=bn_name_base + '2a')(x)\n",
        "    x = layers.Activation('relu')(x)\n",
        "\n",
        "    x = layers.Conv2D(filters2, kernel_size,\n",
        "                      padding='same',\n",
        "                      kernel_initializer='he_normal',\n",
        "                      name=conv_name_base + '2b')(x)\n",
        "    x = layers.BatchNormalization(axis=bn_axis, name=bn_name_base + '2b')(x)\n",
        "    x = layers.Activation('relu')(x)\n",
        "\n",
        "    x = layers.Conv2D(filters3, (1, 1),\n",
        "                      kernel_initializer='he_normal',\n",
        "                      name=conv_name_base + '2c')(x)\n",
        "    x = layers.BatchNormalization(axis=bn_axis, name=bn_name_base + '2c')(x)\n",
        "\n",
        "    x = layers.add([x, input_tensor])\n",
        "    x = layers.Activation('relu')(x)\n",
        "    return x\n",
        "\n",
        "\n",
        "def conv_block(input_tensor,\n",
        "               kernel_size,\n",
        "               filters,\n",
        "               stage,\n",
        "               block,\n",
        "               strides=(2, 2)):\n",
        "    \"\"\"A block that has a conv layer at shortcut.\n",
        "    # Arguments\n",
        "        input_tensor: input tensor\n",
        "        kernel_size: default 3, the kernel size of\n",
        "            middle conv layer at main path\n",
        "        filters: list of integers, the filters of 3 conv layer at main path\n",
        "        stage: integer, current stage label, used for generating layer names\n",
        "        block: 'a','b'..., current block label, used for generating layer names\n",
        "        strides: Strides for the first conv layer in the block.\n",
        "    # Returns\n",
        "        Output tensor for the block.\n",
        "    Note that from stage 3,\n",
        "    the first conv layer at main path is with strides=(2, 2)\n",
        "    And the shortcut should have strides=(2, 2) as well\n",
        "    \"\"\"\n",
        "    filters1, filters2, filters3 = filters\n",
        "    if tf.keras.backend.image_data_format() == 'channels_last':\n",
        "        bn_axis = 3\n",
        "    else:\n",
        "        bn_axis = 1\n",
        "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
        "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
        "\n",
        "    x = layers.Conv2D(filters1, (1, 1), strides=strides,\n",
        "                      kernel_initializer='he_normal',\n",
        "                      name=conv_name_base + '2a')(input_tensor)\n",
        "    x = layers.BatchNormalization(axis=bn_axis, name=bn_name_base + '2a')(x)\n",
        "    x = layers.Activation('relu')(x)\n",
        "\n",
        "    x = layers.Conv2D(filters2, kernel_size, padding='same',\n",
        "                      kernel_initializer='he_normal',\n",
        "                      name=conv_name_base + '2b')(x)\n",
        "    x = layers.BatchNormalization(axis=bn_axis, name=bn_name_base + '2b')(x)\n",
        "    x = layers.Activation('relu')(x)\n",
        "\n",
        "    x = layers.Conv2D(filters3, (1, 1),\n",
        "                      kernel_initializer='he_normal',\n",
        "                      name=conv_name_base + '2c')(x)\n",
        "    x = layers.BatchNormalization(axis=bn_axis, name=bn_name_base + '2c')(x)\n",
        "\n",
        "    shortcut = layers.Conv2D(filters3, (1, 1), strides=strides,\n",
        "                             kernel_initializer='he_normal',\n",
        "                             name=conv_name_base + '1')(input_tensor)\n",
        "    shortcut = layers.BatchNormalization(\n",
        "        axis=bn_axis, name=bn_name_base + '1')(shortcut)\n",
        "\n",
        "    x = layers.add([x, shortcut])\n",
        "    x = layers.Activation('relu')(x)\n",
        "    return x\n",
        "\n",
        "\n",
        "def ResNet50(include_top=True,\n",
        "             weights='imagenet',\n",
        "             input_tensor=None,\n",
        "             input_shape=None,\n",
        "             pooling=None,\n",
        "             classes=1000,\n",
        "             **kwargs):\n",
        "    \"\"\"Instantiates the ResNet50 architecture.\n",
        "    Optionally loads weights pre-trained on ImageNet.\n",
        "    Note that the data format convention used by the model is\n",
        "    the one specified in your Keras config at `~/.keras/keras.json`.\n",
        "    # Arguments\n",
        "        include_top: whether to include the fully-connected\n",
        "            layer at the top of the network.\n",
        "        weights: one of `None` (random initialization),\n",
        "              'imagenet' (pre-training on ImageNet),\n",
        "              or the path to the weights file to be loaded.\n",
        "        input_tensor: optional Keras tensor (i.e. output of `layers.Input()`)\n",
        "            to use as image input for the model.\n",
        "        input_shape: optional shape tuple, only to be specified\n",
        "            if `include_top` is False (otherwise the input shape\n",
        "            has to be `(224, 224, 3)` (with `channels_last` data format)\n",
        "            or `(3, 224, 224)` (with `channels_first` data format).\n",
        "            It should have exactly 3 inputs channels,\n",
        "            and width and height should be no smaller than 32.\n",
        "            E.g. `(200, 200, 3)` would be one valid value.\n",
        "        pooling: Optional pooling mode for feature extraction\n",
        "            when `include_top` is `False`.\n",
        "            - `None` means that the output of the model will be\n",
        "                the 4D tensor output of the\n",
        "                last convolutional block.\n",
        "            - `avg` means that global average pooling\n",
        "                will be applied to the output of the\n",
        "                last convolutional block, and thus\n",
        "                the output of the model will be a 2D tensor.\n",
        "            - `max` means that global max pooling will\n",
        "                be applied.\n",
        "        classes: optional number of classes to classify images\n",
        "            into, only to be specified if `include_top` is True, and\n",
        "            if no `weights` argument is specified.\n",
        "    # Returns\n",
        "        A Keras model instance.\n",
        "    # Raises\n",
        "        ValueError: in case of invalid argument for `weights`,\n",
        "            or invalid input shape.\n",
        "    \"\"\"\n",
        "   \n",
        "\n",
        "    if not (weights in {'imagenet', None} or os.path.exists(weights)):\n",
        "        raise ValueError('The `weights` argument should be either '\n",
        "                         '`None` (random initialization), `imagenet` '\n",
        "                         '(pre-training on ImageNet), '\n",
        "                         'or the path to the weights file to be loaded.')\n",
        "\n",
        "    if weights == 'imagenet' and include_top and classes != 1000:\n",
        "        raise ValueError('If using `weights` as `\"imagenet\"` with `include_top`'\n",
        "                         ' as true, `classes` should be 1000')\n",
        "\n",
        "    # Determine proper input shape\n",
        "    input_shape = _obtain_input_shape(input_shape,\n",
        "                                      default_size=224,\n",
        "                                      min_size=32,\n",
        "                                      data_format=tf.keras.backend.image_data_format(),\n",
        "                                      require_flatten=include_top,\n",
        "                                      weights=weights)\n",
        "\n",
        "    if input_tensor is None:\n",
        "        img_input = layers.Input(shape=input_shape)\n",
        "    else:\n",
        "        if not backend.is_keras_tensor(input_tensor):\n",
        "            img_input = layers.Input(tensor=input_tensor, shape=input_shape)\n",
        "        else:\n",
        "            img_input = input_tensor\n",
        "    if tf.keras.backend.image_data_format() == 'channels_last':\n",
        "        bn_axis = 3\n",
        "    else:\n",
        "        bn_axis = 1\n",
        "\n",
        "    x = layers.ZeroPadding2D(padding=(3, 3), name='conv1_pad')(img_input)\n",
        "    x = layers.Conv2D(64, (7, 7),\n",
        "                      strides=(2, 2),\n",
        "                      padding='valid',\n",
        "                      kernel_initializer='he_normal',\n",
        "                      name='conv1')(x)\n",
        "    x = layers.BatchNormalization(axis=bn_axis, name='bn_conv1')(x)\n",
        "    x = layers.Activation('relu')(x)\n",
        "    x = layers.ZeroPadding2D(padding=(1, 1), name='pool1_pad')(x)\n",
        "    x = layers.MaxPooling2D((3, 3), strides=(2, 2))(x)\n",
        "\n",
        "    x = conv_block(x, 3, [64, 64, 256], stage=2, block='a', strides=(1, 1))\n",
        "    x = identity_block(x, 3, [64, 64, 256], stage=2, block='b')\n",
        "    x = identity_block(x, 3, [64, 64, 256], stage=2, block='c')\n",
        "\n",
        "    x = conv_block(x, 3, [128, 128, 512], stage=3, block='a')\n",
        "    x = identity_block(x, 3, [128, 128, 512], stage=3, block='b')\n",
        "    x = identity_block(x, 3, [128, 128, 512], stage=3, block='c')\n",
        "    x = identity_block(x, 3, [128, 128, 512], stage=3, block='d')\n",
        "\n",
        "    x = conv_block(x, 3, [256, 256, 1024], stage=4, block='a')\n",
        "    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='b')\n",
        "    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='c')\n",
        "    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='d')\n",
        "    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='e')\n",
        "    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='f')\n",
        "\n",
        "    x = conv_block(x, 3, [512, 512, 2048], stage=5, block='a')\n",
        "    x = identity_block(x, 3, [512, 512, 2048], stage=5, block='b')\n",
        "    x = identity_block(x, 3, [512, 512, 2048], stage=5, block='c')\n",
        "\n",
        "    if include_top:\n",
        "        x = layers.GlobalAveragePooling2D(name='avg_pool')(x)\n",
        "        x = layers.Dense(classes, activation='softmax', name='fc1000')(x)\n",
        "    else:\n",
        "        if pooling == 'avg':\n",
        "            x = layers.GlobalAveragePooling2D()(x)\n",
        "        elif pooling == 'max':\n",
        "            x = layers.GlobalMaxPooling2D()(x)\n",
        "        else:\n",
        "            warnings.warn('The output shape of `ResNet50(include_top=False)` '\n",
        "                          'has been changed since Keras 2.2.0.')\n",
        "\n",
        "    # Ensure that the model takes into account\n",
        "    # any potential predecessors of `input_tensor`.\n",
        "    if input_tensor is not None:\n",
        "        inputs = keras_utils.get_source_inputs(input_tensor)\n",
        "    else:\n",
        "        inputs = img_input\n",
        "    # Create model.\n",
        "    model = models.Model(inputs, x, name='resnet50')\n",
        "\n",
        "    # Load weights.\n",
        "    if weights == 'imagenet':\n",
        "        if include_top:\n",
        "            weights_path = keras_utils.get_file(\n",
        "                'resnet50_weights_tf_dim_ordering_tf_kernels.h5',\n",
        "                WEIGHTS_PATH,\n",
        "                cache_subdir='models',\n",
        "                md5_hash='a7b3fe01876f51b976af0dea6bc144eb')\n",
        "        else:\n",
        "            weights_path = keras_utils.get_file(\n",
        "                'resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5',\n",
        "                WEIGHTS_PATH_NO_TOP,\n",
        "                cache_subdir='models',\n",
        "                md5_hash='a268eb855778b3df3c7506639542a6af')\n",
        "        model.load_weights(weights_path)\n",
        "        if backend.backend() == 'theano':\n",
        "            keras_utils.convert_all_kernels_in_model(model)\n",
        "    elif weights is not None:\n",
        "        model.load_weights(weights)\n",
        "\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "85EIr2N6O15_",
        "colab_type": "code",
        "outputId": "a99117ca-34a2-4fc9-9b03-b6af540d2015",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from keras_applications.imagenet_utils import _obtain_input_shape\n",
        "from keras.applications.inception_v3 import preprocess_input\n",
        "from keras_applications.imagenet_utils import decode_predictions\n",
        "img_height,img_width = 160,160\n",
        "num_classes = 7\n",
        "#If imagenet weights are being loaded, \n",
        "#input must have a static square shape (one of (128, 128), (160, 160), (192, 192), or (224, 224))\n",
        "base_model=ResNet50(weights= None, include_top=False, input_shape= (img_height,img_width,3))\n",
        "#base_model = applications.keras_applications.resnet_common.block1"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:248: UserWarning: The output shape of `ResNet50(include_top=False)` has been changed since Keras 2.2.0.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XHrrGf-1PEGi",
        "colab_type": "code",
        "outputId": "b67391ba-e647-43a3-b211-c8a899417e52",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dropout(0.7)(x)\n",
        "predictions = Dense(num_classes, activation= 'softmax')(x)\n",
        "model = Model(inputs = base_model.input, outputs = predictions)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Large dropout rate: 0.7 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CUdcINSSPJBC",
        "colab_type": "code",
        "outputId": "2a9ea37d-f6fe-4862-c7cf-08414eb9e4c7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "img_width, img_height = 160, 160\n",
        "train_data_dir =( \"/content/drive/My Drive/Skin_cancer_all/skin_cancer\")\n",
        "\n",
        "\n",
        "train_datagen = ImageDataGenerator(rescale=1./255,\n",
        "    validation_split=0.2) # set validation split\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_data_dir,\n",
        "    target_size=(img_width, img_height),\n",
        "    batch_size=8,  \n",
        "    subset='training') # set as training data\n",
        "\n",
        "validation_generator = train_datagen.flow_from_directory(\n",
        "    train_data_dir, # same directory as training data\n",
        "    target_size=(img_width, img_height),\n",
        "    batch_size=8,\n",
        "    subset='validation') # set as validation data"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Found 8015 images belonging to 7 classes.\n",
            "Found 2000 images belonging to 7 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Aes7N2IP4vT",
        "colab_type": "code",
        "outputId": "d3143b64-3d8a-409b-f595-c40eb2f0b42f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.optimizers import adam\n",
        "nb_epochs = 2\n",
        "nb_train_samples = 8015\n",
        "nb_validation_samples = 2000\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "     optimizer='rmsprop',      \n",
        "              metrics=['accuracy'])\n",
        "    # but it used to start model.\n",
        "\n",
        "\n",
        "history=model.fit_generator(train_generator,\n",
        "                    steps_per_epoch=nb_train_samples,\n",
        "                    epochs=nb_epochs\n",
        "                        , validation_data=validation_generator\n",
        "                        , validation_steps=nb_validation_samples)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "8014/8015 [============================>.] - ETA: 0s - loss: 1.4343 - acc: 0.6614Epoch 1/2\n",
            "8015/8015 [==============================] - 4902s 612ms/step - loss: 1.4342 - acc: 0.6614 - val_loss: 2.3165 - val_acc: 0.6705\n",
            "Epoch 2/2\n",
            "8014/8015 [============================>.] - ETA: 0s - loss: 1.1306 - acc: 0.6843Epoch 1/2\n",
            "8015/8015 [==============================] - 2149s 268ms/step - loss: 1.1305 - acc: 0.6843 - val_loss: 186.3717 - val_acc: 0.6705\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WTPcGMpNP6-A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "img_height,img_width = 160,160\n",
        "num_classes = 7\n",
        "#If imagenet weights are being loaded, \n",
        "#input must have a static square shape (one of (128, 128), (160, 160), (192, 192), or (224, 224))\n",
        "base_model_1 = applications.resnet50.ResNet50(weights= None, include_top=False, input_shape= (img_height,img_width,3))\n",
        "#base_model = applications.keras_applications.resnet_common.block1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-JPwh2YbQCh7",
        "colab_type": "code",
        "outputId": "7b8313dc-9dd2-45ce-edc2-2d1f26ebb2a3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "x = base_model_1.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dropout(0.7)(x)\n",
        "predictions = Dense(num_classes, activation= 'softmax')(x)\n",
        "model_1 = Model(inputs = base_model_1.input, outputs = predictions)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Large dropout rate: 0.7 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k7B5XDpqQRCp",
        "colab_type": "code",
        "outputId": "d380ff2a-d302-4357-b8eb-dd0110ec4c39",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.optimizers import adam\n",
        "nb_epochs = 2\n",
        "nb_train_samples = 8015\n",
        "nb_validation_samples = 2000\n",
        "\n",
        "model_1.compile(loss='categorical_crossentropy',\n",
        "     optimizer='rmsprop',      \n",
        "              metrics=['accuracy'])\n",
        "    # but it used to start model.\n",
        "\n",
        "\n",
        "history=model_1.fit_generator(train_generator,\n",
        "                    steps_per_epoch=nb_train_samples,\n",
        "                    epochs=nb_epochs\n",
        "                        , validation_data=validation_generator\n",
        "                        , validation_steps=nb_validation_samples)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "8014/8015 [============================>.] - ETA: 0s - loss: 1.4205 - acc: 0.6612Epoch 1/2\n",
            "8015/8015 [==============================] - 2199s 274ms/step - loss: 1.4203 - acc: 0.6612 - val_loss: 2.2536 - val_acc: 0.6705\n",
            "Epoch 2/2\n",
            "8014/8015 [============================>.] - ETA: 0s - loss: 1.2617 - acc: 0.6802Epoch 1/2\n",
            "8015/8015 [==============================] - 2182s 272ms/step - loss: 1.2620 - acc: 0.6802 - val_loss: 30.0708 - val_acc: 0.6705\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CzcfLKMoMG7b",
        "colab_type": "code",
        "outputId": "efd9f671-b643-47b8-d3fa-49a8037167d9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "nb_epochs=1\n",
        "history=model.fit_generator(train_generator,\n",
        "                    steps_per_epoch=nb_train_samples,\n",
        "                    epochs=nb_epochs\n",
        "                        , validation_data=validation_generator\n",
        "                        , validation_steps=nb_validation_samples)\n",
        "history=model_1.fit_generator(train_generator,\n",
        "                    steps_per_epoch=nb_train_samples,\n",
        "                    epochs=nb_epochs\n",
        "                        , validation_data=validation_generator\n",
        "                        , validation_steps=nb_validation_samples)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5388/8015 [===================>..........] - ETA: 11:07 - loss: 1.0780 - acc: 0.7199"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dObOUZABp-Hk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#resnet 34\n",
        "\n",
        "\"\"\"ResNet50 model for Keras.\n",
        "# Reference:\n",
        "- [Deep Residual Learning for Image Recognition](\n",
        "    https://arxiv.org/abs/1512.03385) (CVPR 2016 Best Paper Award)\n",
        "Adapted from code contributed by BigMoyan.\n",
        "\"\"\"\n",
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "import tensorflow as tf\n",
        "import os\n",
        "import warnings\n",
        "import tensorflow.keras.backend as backend\n",
        "import tensorflow.keras.layers as layers\n",
        "import tensorflow.keras.models as models\n",
        "import tensorflow.keras.utils as utils\n",
        "from . import get_submodules_from_kwargs\n",
        "from keras_applications.imagenet_utils import _obtain_input_shape as _ob\n",
        "\n",
        "preprocess_input = preprocess_input\n",
        "\n",
        "WEIGHTS_PATH = ('https://github.com/fchollet/deep-learning-models/'\n",
        "                'releases/download/v0.2/'\n",
        "                'resnet50_weights_tf_dim_ordering_tf_kernels.h5')\n",
        "WEIGHTS_PATH_NO_TOP = ('https://github.com/fchollet/deep-learning-models/'\n",
        "                       'releases/download/v0.2/'\n",
        "                       'resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5')\n",
        "\n",
        "\n",
        "def identity_block(input_tensor, kernel_size, filters, stage, block):\n",
        "    \"\"\"The identity block is the block that has no conv layer at shortcut.\n",
        "    # Arguments\n",
        "        input_tensor: input tensor\n",
        "        kernel_size: default 3, the kernel size of\n",
        "            middle conv layer at main path\n",
        "        filters: list of integers, the filters of 3 conv layer at main path\n",
        "        stage: integer, current stage label, used for generating layer names\n",
        "        block: 'a','b'..., current block label, used for generating layer names\n",
        "    # Returns\n",
        "        Output tensor for the block.\n",
        "    \"\"\"\n",
        "    filters1, filters2 = filters\n",
        "    if tf.keras.backend.image_data_format() == 'channels_last':\n",
        "        bn_axis = 3\n",
        "    else:\n",
        "        bn_axis = 1\n",
        "  \n",
        "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
        "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
        "\n",
        "   \n",
        "    x = layers.Conv2D(filters1, (1, 1),\n",
        "                      kernel_initializer='he_normal',\n",
        "                      name=conv_name_base + '2a')(input_tensor)\n",
        "    x = layers.BatchNormalization(axis=3, name=bn_name_base + '2a')(x)\n",
        "    x = layers.Activation('relu')(x)\n",
        "  \n",
        "    x = layers.Conv2D(filters2, kernel_size,\n",
        "                      padding='same',\n",
        "                      kernel_initializer='he_normal',\n",
        "                      name=conv_name_base + '2b')(x)\n",
        "    x = layers.BatchNormalization(axis=3, name=bn_name_base + '2b')(x)\n",
        "   \n",
        "    #x = layers.Activation('relu')(x)\n",
        "    \"\"\" x = layers.Conv2D(filters3, (1, 1),\n",
        "                      kernel_initializer='he_normal',\n",
        "                      name=conv_name_base + '2c')(x)\n",
        "    x = layers.BatchNormalization(axis=bn_axis, name=bn_name_base + '2c')(x)\n",
        "    \"\"\"\n",
        "    x = layers.add([x, input_tensor])\n",
        "    x = layers.Activation('relu')(x)\n",
        "   \n",
        "    return x\n",
        "\n",
        "\n",
        "def conv_block(input_tensor,\n",
        "               kernel_size,\n",
        "               filters,\n",
        "               stage,\n",
        "               block,\n",
        "               strides=(2, 2)):\n",
        "    \"\"\"A block that has a conv layer at shortcut.\n",
        "    # Arguments\n",
        "        input_tensor: input tensor\n",
        "        kernel_size: default 3, the kernel size of\n",
        "            middle conv layer at main path\n",
        "        filters: list of integers, the filters of 3 conv layer at main path\n",
        "        stage: integer, current stage label, used for generating layer names\n",
        "        block: 'a','b'..., current block label, used for generating layer names\n",
        "        strides: Strides for the first conv layer in the block.\n",
        "    # Returns\n",
        "        Output tensor for the block.\n",
        "    Note that from stage 3,\n",
        "    the first conv layer at main path is with strides=(2, 2)\n",
        "    And the shortcut should have strides=(2, 2) as well\n",
        "    \"\"\"\n",
        "    filters1, filters2 = filters\n",
        "    if tf.keras.backend.image_data_format() == 'channels_last':\n",
        "        bn_axis = 3\n",
        "    else:\n",
        "        bn_axis = 1\n",
        "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
        "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
        "\n",
        "    x = layers.Conv2D(filters1, (3,3), strides=strides,\n",
        "                      kernel_initializer='he_normal',\n",
        "                      name=conv_name_base + '2a')(input_tensor)\n",
        "    x = layers.BatchNormalization(axis=3, name=bn_name_base + '2a')(x)\n",
        "    x = layers.Activation('relu')(x)\n",
        "\n",
        "    x = layers.Conv2D(filters2, kernel_size, padding='same',\n",
        "                      kernel_initializer='he_normal',\n",
        "                      name=conv_name_base + '2b')(x)\n",
        "    x = layers.BatchNormalization(axis=3, name=bn_name_base + '2b')(x)\n",
        "    #x = layers.Activation('relu')(x)\n",
        "\n",
        "    \"\"\" x = layers.Conv2D(filters3, (1, 1),\n",
        "                      kernel_initializer='he_normal',\n",
        "                      name=conv_name_base + '2c')(x)\n",
        "    x = layers.BatchNormalization(axis=bn_axis, name=bn_name_base + '2c')(x)\n",
        "    \"\"\"\n",
        "    shortcut = layers.Conv2D(filters2, (3, 3), strides=strides,\n",
        "                             kernel_initializer='he_normal',\n",
        "                             name=conv_name_base + '1')(input_tensor)\n",
        "    shortcut = layers.BatchNormalization(\n",
        "        axis=3, name=bn_name_base + '1')(shortcut)\n",
        "\n",
        "    x = layers.add([x, shortcut])\n",
        "    x = layers.Activation('relu')(x)\n",
        "    return x\n",
        "\n",
        "\n",
        "def ResNet34(include_top=True,\n",
        "             weights='imagenet',\n",
        "             input_tensor=None,\n",
        "             input_shape=None,\n",
        "             pooling=None,\n",
        "             classes=1000,\n",
        "             **kwargs):\n",
        "  \n",
        "   \n",
        "\n",
        "    if not (weights in {'imagenet', None} or os.path.exists(weights)):\n",
        "        raise ValueError('The `weights` argument should be either '\n",
        "                         '`None` (random initialization), `imagenet` '\n",
        "                         '(pre-training on ImageNet), '\n",
        "                         'or the path to the weights file to be loaded.')\n",
        "\n",
        "    if weights == 'imagenet' and include_top and classes != 1000:\n",
        "        raise ValueError('If using `weights` as `\"imagenet\"` with `include_top`'\n",
        "                         ' as true, `classes` should be 1000')\n",
        "\n",
        "    # Determine proper input shape\n",
        "    input_shape = _obtain_input_shape(input_shape,\n",
        "                                      default_size=224,\n",
        "                                      min_size=34,\n",
        "                                      data_format=tf.keras.backend.image_data_format(),\n",
        "                                      require_flatten=include_top,\n",
        "                                      weights=weights)\n",
        "    print(input_shape)\n",
        "    if input_tensor is None:\n",
        "        img_input = layers.Input(shape=input_shape)\n",
        "    else:\n",
        "        if not backend.is_keras_tensor(input_tensor):\n",
        "            img_input = layers.Input(tensor=input_tensor, shape=input_shape)\n",
        "        else:\n",
        "            img_input = input_tensor\n",
        "    if tf.keras.backend.image_data_format() == 'channels_last':\n",
        "        bn_axis = 3\n",
        "    else:\n",
        "        bn_axis = 1\n",
        "    \n",
        "    x = layers.ZeroPadding2D(padding=(3, 3), name='conv1_pad')(img_input)\n",
        "    x = layers.Conv2D(64, (7, 7),\n",
        "                      strides=(2, 2),\n",
        "                      padding='valid',\n",
        "                      kernel_initializer='he_normal',\n",
        "                      name='conv1')(x)\n",
        "    x = layers.BatchNormalization(axis=3, name='bn_conv1')(x)\n",
        "    x = layers.Activation('relu')(x)\n",
        "    x = layers.ZeroPadding2D(padding=(1, 1), name='pool1_pad')(x)\n",
        "    x = layers.MaxPooling2D((3, 3), strides=(2, 2))(x)\n",
        "\n",
        "    \n",
        "    x = conv_block(x, 3, [64, 64], stage=2, block='a', strides=(1, 1))\n",
        "    print(backend.int_shape(x))\n",
        "    x = identity_block(x, 3, [64, 64], stage=2, block='b')\n",
        "  \n",
        "    x = identity_block(x, 3, [64, 64], stage=2, block='c')\n",
        "   \n",
        "    x = conv_block(x, 3, [128, 128], stage=3, block='a')\n",
        "    x = identity_block(x, 3, [128, 128], stage=3, block='b')\n",
        "    x = identity_block(x, 3, [128, 128], stage=3, block='c')\n",
        "    x = identity_block(x, 3, [128, 128], stage=3, block='d')\n",
        "   \n",
        "    x = conv_block(x, 3, [256, 256], stage=4, block='a')\n",
        "    x = identity_block(x, 3, [256, 256], stage=4, block='b')\n",
        "    x = identity_block(x, 3, [256, 256], stage=4, block='c')\n",
        "    x = identity_block(x, 3, [256, 256], stage=4, block='d')\n",
        "    x = identity_block(x, 3, [256, 256], stage=4, block='e')\n",
        "    x = identity_block(x, 3, [256, 256], stage=4, block='f')\n",
        "\n",
        "    x = conv_block(x, 3, [512, 512], stage=5, block='a')\n",
        "    x = identity_block(x, 3, [512, 512], stage=5, block='b')\n",
        "    x = identity_block(x, 3, [512, 512], stage=5, block='c')\n",
        "\n",
        "    if include_top:\n",
        "        x = layers.GlobalAveragePooling2D(name='avg_pool')(x)\n",
        "        x = layers.Dense(classes, activation='softmax', name='fc1000')(x)\n",
        "    else:\n",
        "        if pooling == 'avg':\n",
        "            x = layers.GlobalAveragePooling2D()(x)\n",
        "        elif pooling == 'max':\n",
        "            x = layers.GlobalMaxPooling2D()(x)\n",
        "        else:\n",
        "            warnings.warn('The output shape of `ResNet50(include_top=False)` '\n",
        "                          'has been changed since Keras 2.2.0.')\n",
        "    \n",
        "    # Ensure that the model takes into account\n",
        "    # any potential predecessors of `input_tensor`.\n",
        "    if input_tensor is not None:\n",
        "        inputs = keras_utils.get_source_inputs(input_tensor)\n",
        "    else:\n",
        "        inputs = img_input\n",
        "    # Create model.\n",
        "    model = models.Model(inputs, x, name='resnet50')\n",
        "   \n",
        "    # Load weights.\n",
        "    if weights == 'imagenet':\n",
        "        if include_top:\n",
        "            weights_path = keras_utils.get_file(\n",
        "                'resnet50_weights_tf_dim_ordering_tf_kernels.h5',\n",
        "                WEIGHTS_PATH,\n",
        "                cache_subdir='models',\n",
        "                md5_hash='a7b3fe01876f51b976af0dea6bc144eb')\n",
        "        else:\n",
        "            weights_path = keras_utils.get_file(\n",
        "                'resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5',\n",
        "                WEIGHTS_PATH_NO_TOP,\n",
        "                cache_subdir='models',\n",
        "                md5_hash='a268eb855778b3df3c7506639542a6af')\n",
        "        model.load_weights(weights_path)\n",
        "        if backend.backend() == 'theano':\n",
        "            keras_utils.convert_all_kernels_in_model(model)\n",
        "    elif weights is not None:\n",
        "        model.load_weights(weights)\n",
        "\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z8oWYTEYt7OG",
        "colab_type": "code",
        "outputId": "0c2656e0-3b96-4643-df1c-82e3f250ec00",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        }
      },
      "source": [
        "from keras_applications.imagenet_utils import _obtain_input_shape\n",
        "from keras.applications.inception_v3 import preprocess_input\n",
        "from keras_applications.imagenet_utils import decode_predictions\n",
        "img_height,img_width = 224,224\n",
        "num_classes = 7\n",
        "#If imagenet weights are being loaded, \n",
        "#input must have a static square shape (one of (128, 128), (160, 160), (192, 192), or (224, 224))\n",
        "base_model=ResNet34(weights= None, include_top=False, input_shape= (img_height,img_width,3))\n",
        "#base_model = applications.keras_applications.resnet_common.block1"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(224, 224, 3)\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "(None, 54, 54, 64)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:217: UserWarning: The output shape of `ResNet50(include_top=False)` has been changed since Keras 2.2.0.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uWkwdlott8R5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dropout(0.3)(x)\n",
        "predictions = Dense(num_classes, activation= 'softmax')(x)\n",
        "model = Model(inputs = base_model.input, outputs = predictions)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bl3Byzu-t8ki",
        "colab_type": "code",
        "outputId": "2c27ed7f-413b-429b-8cb6-5d3fe8758b5d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "img_width, img_height = 224, 224\n",
        "train_data_dir =( \"/content/drive/My Drive/Skin_cancer_all/skin_cancer\")\n",
        "\n",
        "\n",
        "train_datagen = ImageDataGenerator(rescale=1./255,\n",
        "    validation_split=0.3) # set validation split\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_data_dir,\n",
        "    target_size=(img_width, img_height),\n",
        "    batch_size=32,  \n",
        "    shuffle=True,\n",
        "    class_mode=\"sparse\",\n",
        "    subset='training') # set as training data\n",
        "\n",
        "validation_generator = train_datagen.flow_from_directory(\n",
        "    train_data_dir, # same directory as training data\n",
        "    target_size=(img_width, img_height),\n",
        "    batch_size=32,\n",
        "     shuffle=True,\n",
        "     class_mode=\"sparse\",\n",
        "    subset='validation') # set as validation data"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Found 7014 images belonging to 7 classes.\n",
            "Found 3001 images belonging to 7 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gxJ_f4y_t8yI",
        "colab_type": "code",
        "outputId": "778327b8-3908-4a61-a0ec-55b7cd0d3c03",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 537
        }
      },
      "source": [
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.optimizers import adam\n",
        "nb_epochs = 10\n",
        "nb_train_samples = 777\n",
        "nb_validation_samples = 200\n",
        "\n",
        "model.compile(loss='sparse_categorical_crossentropy',\n",
        "     optimizer='rmsprop',      \n",
        "              metrics=['accuracy'])\n",
        "    # but it used to start model.\n",
        "\n",
        "\n",
        "history=model.fit_generator(train_generator,\n",
        "                    steps_per_epoch=nb_train_samples,\n",
        "                    epochs=nb_epochs\n",
        "                        , validation_data=validation_generator\n",
        "                        , validation_steps=nb_validation_samples)\n",
        "\n"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "776/777 [============================>.] - ETA: 2s - loss: 1.1879 - acc: 0.6508Epoch 1/10\n",
            "777/777 [==============================] - 2778s 4s/step - loss: 1.1876 - acc: 0.6507 - val_loss: 2.1728 - val_acc: 0.4075\n",
            "Epoch 2/10\n",
            "776/777 [============================>.] - ETA: 0s - loss: 1.0202 - acc: 0.6739Epoch 1/10\n",
            "777/777 [==============================] - 377s 485ms/step - loss: 1.0195 - acc: 0.6740 - val_loss: 1.5559 - val_acc: 0.4919\n",
            "Epoch 3/10\n",
            "776/777 [============================>.] - ETA: 0s - loss: 1.0268 - acc: 0.6705Epoch 1/10\n",
            "777/777 [==============================] - 168s 216ms/step - loss: 1.0270 - acc: 0.6704 - val_loss: 5.0216 - val_acc: 0.4081\n",
            "Epoch 4/10\n",
            "776/777 [============================>.] - ETA: 0s - loss: 0.9970 - acc: 0.6901Epoch 1/10\n",
            "777/777 [==============================] - 168s 216ms/step - loss: 0.9963 - acc: 0.6902 - val_loss: 1.2701 - val_acc: 0.5063\n",
            "Epoch 5/10\n",
            "776/777 [============================>.] - ETA: 0s - loss: 0.9771 - acc: 0.6786Epoch 1/10\n",
            "777/777 [==============================] - 170s 218ms/step - loss: 0.9777 - acc: 0.6782 - val_loss: 1.2374 - val_acc: 0.5169\n",
            "Epoch 6/10\n",
            "776/777 [============================>.] - ETA: 0s - loss: 0.9082 - acc: 0.7002Epoch 1/10\n",
            "777/777 [==============================] - 171s 221ms/step - loss: 0.9088 - acc: 0.6998 - val_loss: 1.4936 - val_acc: 0.4300\n",
            "Epoch 7/10\n",
            "776/777 [============================>.] - ETA: 0s - loss: 0.9905 - acc: 0.7016Epoch 1/10\n",
            "777/777 [==============================] - 171s 220ms/step - loss: 0.9908 - acc: 0.7013 - val_loss: 2.5817 - val_acc: 0.5312\n",
            "Epoch 8/10\n",
            "776/777 [============================>.] - ETA: 0s - loss: 0.9807 - acc: 0.6961Epoch 1/10\n",
            "777/777 [==============================] - 171s 221ms/step - loss: 0.9811 - acc: 0.6957 - val_loss: 1.4752 - val_acc: 0.4137\n",
            "Epoch 9/10\n",
            "776/777 [============================>.] - ETA: 0s - loss: 0.9121 - acc: 0.7008Epoch 1/10\n",
            "777/777 [==============================] - 171s 221ms/step - loss: 0.9120 - acc: 0.7007 - val_loss: 3.6248 - val_acc: 0.4869\n",
            "Epoch 10/10\n",
            "776/777 [============================>.] - ETA: 0s - loss: 0.9964 - acc: 0.7090Epoch 1/10\n",
            "777/777 [==============================] - 171s 221ms/step - loss: 0.9963 - acc: 0.7090 - val_loss: 8.3436 - val_acc: 0.4081\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZEzeKkgIxQoH",
        "colab_type": "code",
        "outputId": "77267863-b7c4-40ad-8f2b-d8274d002c60",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "print(history.history)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'loss': [1.034258842085692, 0.939156984346741, 0.8844303687881481, 0.8516570129760664, 0.78591804242827, 0.713281703502949, 0.5171341520380789, 0.358884005162721, 0.3054488049523439, 0.2456635578979919], 'acc': [0.6786093, 0.71368855, 0.7318287, 0.7414213, 0.76796854, 0.80657285, 0.86387885, 0.9178313, 0.9490891, 0.9640317], 'val_loss': [1.743596945989877, 0.7515653432528488, 2.1829235553964974, 0.8079613352196757, 2.275887858807691, 1.4543981612241696, 2.3923986782444326, 1.7672924049687417, 3.5852286861966607, 9.118125342008392], 'val_acc': [0.661, 0.7335, 0.5085, 0.7395, 0.706, 0.739, 0.743, 0.729, 0.744, 0.7185]}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AlkrJaUJxWgA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save_weights( 'skin_cancer_all_model_resnet34_weights_10_epoch.h5')\n",
        "model.save('skin_cancer_all_model_structure_resnet34_10_epoch.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H0od9TBWE1fZ",
        "colab_type": "code",
        "outputId": "acc77462-c28d-4d78-d83d-03475a023ece",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 277
        }
      },
      "source": [
        "nb_epochs = 5\n",
        "nb_train_samples = 333\n",
        "nb_validation_samples = 90\n",
        "history=model.fit_generator(train_generator,\n",
        "                    steps_per_epoch=nb_train_samples,\n",
        "                    epochs=nb_epochs\n",
        "                        , validation_data=validation_generator\n",
        "                        , validation_steps=nb_validation_samples)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "332/333 [============================>.] - ETA: 0s - loss: 0.1605 - acc: 0.9474Epoch 1/5\n",
            "333/333 [==============================] - 191s 573ms/step - loss: 0.1603 - acc: 0.9475 - val_loss: 1.7368 - val_acc: 0.7024\n",
            "Epoch 2/5\n",
            "332/333 [============================>.] - ETA: 0s - loss: 0.1678 - acc: 0.9470Epoch 1/5\n",
            "333/333 [==============================] - 158s 475ms/step - loss: 0.1675 - acc: 0.9470 - val_loss: 2.0587 - val_acc: 0.7333\n",
            "Epoch 3/5\n",
            "332/333 [============================>.] - ETA: 0s - loss: 0.1315 - acc: 0.9540Epoch 1/5\n",
            "333/333 [==============================] - 157s 471ms/step - loss: 0.1316 - acc: 0.9539 - val_loss: 2.4619 - val_acc: 0.7465\n",
            "Epoch 4/5\n",
            "332/333 [============================>.] - ETA: 0s - loss: 0.1426 - acc: 0.9575Epoch 1/5\n",
            "333/333 [==============================] - 158s 473ms/step - loss: 0.1427 - acc: 0.9576 - val_loss: 2.0216 - val_acc: 0.7167\n",
            "Epoch 5/5\n",
            "332/333 [============================>.] - ETA: 0s - loss: 0.1288 - acc: 0.9607Epoch 1/5\n",
            "333/333 [==============================] - 157s 471ms/step - loss: 0.1284 - acc: 0.9608 - val_loss: 2.2517 - val_acc: 0.7212\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vnj1e-_cx049",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save_weights('skin_cancer_all_model_resnet34_weights_26_epoch_edited_batch_size_32_val_loss_better_val_acc_72_acc_96.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JvEe9eZ54Kkh",
        "colab_type": "code",
        "outputId": "30f8a44f-9c08-4944-ba74-6b9478dd949b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "print(history.history)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'loss': [0.15825039863878715, 0.15805367393137035, 0.13192461966422764, 0.14135423072614653, 0.12378698257853821], 'acc': [0.94747263, 0.9470367, 0.9538853, 0.9575729, 0.9607714], 'val_loss': [1.7368041541841295, 2.0587466067738003, 2.461896982457903, 2.0216374188661574, 2.2516932911343046], 'val_acc': [0.70243055, 0.73333335, 0.7465278, 0.71666664, 0.72118056]}\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}